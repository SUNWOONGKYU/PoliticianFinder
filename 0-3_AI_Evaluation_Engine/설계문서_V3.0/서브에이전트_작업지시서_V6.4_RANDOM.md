# V6.4 서브에이전트 작업지시서 (무작위 수집)

## ⚠️ V6.4 핵심 변경사항

**문제**: V6.2/V6.3 긍정 편향 (오세훈 892점 → 실제 750점 정도가 적정)
**원인**: 선택적 수집 (긍정 데이터만 찾음)
**해결**: **무작위 수집** - 검색 결과를 편향 없이 순서대로 수집

---

## Step 1: 항목 파악

70개 항목 문서(`4_70개항목_구성내역_V6.2.md`)에서 **담당 카테고리의 7개 항목**을 확인합니다.

---

## Step 2: 무작위 데이터 수집 (V6.4 핵심)

**각 항목당 10~30개 데이터를 무작위로 수집**

### 무작위 수집 원칙 (매우 중요!)

#### 1️⃣ 중립적 검색어 사용
```
✅ 올바른 검색어:
- "오세훈 서울시장"
- "오세훈 정책"
- "오세훈 법안"
- "오세훈 활동"

❌ 편향된 검색어 (사용 금지):
- "오세훈 성공"  (긍정 편향)
- "오세훈 훌륭한"  (긍정 편향)
- "오세훈 논란"  (부정 편향)
- "오세훈 실패"  (부정 편향)
```

#### 2️⃣ 검색 결과 순서대로 수집
```python
# ✅ 올바른 방법
검색어: "오세훈 서울시장 정책"
결과:
1. [수집] 한강 르네상스 사업 추진
2. [수집] 무상급식 조례 거부권 행사
3. [수집] 청년 일자리 정책 발표
4. [수집] 이태원 참사 대응
5. [수집] GTX 국비 확보
...
→ 긍정/부정 가리지 않고 순서대로 10~30개 수집

# ❌ 잘못된 방법 (V6.2 문제)
검색어: "오세훈 서울시장 정책"
결과:
1. [건너뜀] 무상급식 조례 거부권  (부정이라 제외)
2. [수집] 한강 르네상스 사업 추진  (긍정만 수집)
3. [건너뜀] 이태원 참사 대응  (부정이라 제외)
4. [수집] GTX 국비 확보  (긍정만 수집)
...
→ 이렇게 하면 과대평가됨!
```

#### 3️⃣ 다양한 출처 균형
```
공식 출처 (50%):
- 선거관리위원회
- 국회 의안정보시스템
- 서울시청 보도자료
- 정보공개포털

공개 출처 (50%):
- Wikipedia
- 주요 언론 (조선, 중앙, 한겨레, 경향 등 다양하게)
- 시민단체 보고서
- SNS
```

### 수집 절차

```python
# Step 1: 중립적 검색
search_query = f"{politician_name} {category_keyword}"
# 예: "오세훈 리더십", "오세훈 청렴성"

# Step 2: 검색 결과 상위 10~30개 순서대로 수집
results = search(search_query, limit=30)

data_points = []
for i, result in enumerate(results[:30]):  # 상위 30개
    # 편향 없이 그대로 수집
    data_points.append({
        'title': result.title,
        'content': result.content,
        'source': result.source,
        'url': result.url
    })

# ⚠️ 긍정/부정 판단하여 선택적으로 제외하지 말 것!
```

---

## Step 3: 객관적 Rating 부여

**각 데이터에 -5 ~ +5 Rating을 사실 기반으로 부여**

### Rating 기준

| Rating | 의미 | 예시 |
|:---:|---|---|
| **+5** | 극도로 긍정적 | 국제 수상, 역대 최고 성과 |
| **+4** | 매우 긍정적 | 주요 법안 통과, 대형 사업 성공 |
| **+3** | 긍정적 | 정책 성공, 활발한 활동 |
| **+2** | 약간 긍정적 | 평균 이상 성과 |
| **+1** | 조금 긍정적 | 평균보다 약간 나음 |
| **0** | 중립/보통 | 평균 수준, 특이사항 없음 |
| **-1** | 조금 부정적 | 평균보다 약간 못함 |
| **-2** | 약간 부정적 | 일부 미이행, 소극적 |
| **-3** | 부정적 | 공약 불이행, 윤리 논란 |
| **-4** | 매우 부정적 | 중대 실패, 참사 책임 |
| **-5** | 극도로 부정적 | 범죄 유죄 판결, 극심한 문제 |

### Rating 원칙

1. **사실에 기반하여 객관적으로 평가**
2. **긍정은 긍정으로, 부정은 부정으로 정확히 평가**
3. **편향 없이 있는 그대로 평가**
4. **근거를 명확히 작성** (rationale 필수)

### Rating 예시

#### 예시 1: 성공 사례
```python
{
    'title': 'GTX-A 국비 1조5천억원 확보',
    'content': '2023년 GTX-A 노선 국비 1조5천억원 확보 성공',
    'rating': +4,
    'rationale': '대형 인프라 사업 국비 확보 성공, 지역 발전 기여'
}
```

#### 예시 2: 실패 사례
```python
{
    'title': '무상급식 조례 거부권으로 시장직 사퇴',
    'content': '2011년 무상급식 조례 거부권 → 주민투표 투표율 25.7% 미달 → 시장직 사퇴',
    'rating': -4,
    'rationale': '정책 대립으로 주민투표 실패, 책임지고 사퇴한 중대 실패 사례'
}
```

#### 예시 3: 중대 참사
```python
{
    'title': '이태원 참사 안전 관리 실패',
    'content': '2022년 이태원 참사 159명 사망, 사전 안전 대책 부재',
    'rating': -5,
    'rationale': '159명 사망이라는 극심한 인명 피해, 사전 예방 실패'
}
```

#### 예시 4: 보통 활동
```python
{
    'title': '시정 보고회 개최',
    'content': '2024년 상반기 시정 보고회 개최',
    'rating': 0,
    'rationale': '정례 행사, 특별한 성과나 문제 없음'
}
```

#### 예시 5: 논란 사례
```python
{
    'title': '공약 이행률 62% 시민단체 지적',
    'content': '서울시민단체가 244개 공약 중 62%에 문제 제기',
    'rating': -3,
    'rationale': '공약 이행률 낮음, 시민단체의 부정적 평가'
}
```

---

## Step 4: Supabase DB에 저장

```python
import os
from dotenv import load_dotenv
from supabase import create_client

load_dotenv()

supabase = create_client(
    os.getenv('SUPABASE_URL'),
    os.getenv('SUPABASE_SERVICE_KEY')
)

# 무작위 수집한 데이터 저장
for item_num in range(1, 8):  # 7개 항목
    for data_point in collected_data[item_num]:  # 항목당 10-30개

        data = {
            'politician_id': politician_id,
            'ai_name': 'Claude',
            'category_num': category_num,
            'item_num': item_num,
            'data_title': data_point['title'],
            'data_content': data_point['content'],
            'data_source': data_point['source'],
            'source_url': data_point['url'],
            'collection_date': '2025-10-31',
            'rating': data_point['rating'],  # -5 ~ +5
            'rating_rationale': data_point['rationale'],
            'reliability': 0.85
        }

        response = supabase.table('collected_data').insert(data).execute()
        print(f"Inserted: {data_point['title']} (Rating: {data_point['rating']})")
```

---

## Step 5: 검증

```python
# 데이터 수 확인
response = supabase.table('collected_data')\
    .select('*', count='exact')\
    .eq('politician_id', politician_id)\
    .eq('category_num', category_num)\
    .execute()

print(f"Total data: {response.count}")

# Rating 분포 확인
response = supabase.table('collected_data')\
    .select('rating')\
    .eq('politician_id', politician_id)\
    .eq('category_num', category_num)\
    .execute()

ratings = [d['rating'] for d in response.data]
positive = len([r for r in ratings if r > 0])
neutral = len([r for r in ratings if r == 0])
negative = len([r for r in ratings if r < 0])

print(f"\nRating Distribution:")
print(f"Positive: {positive} ({positive/len(ratings)*100:.1f}%)")
print(f"Neutral:  {neutral} ({neutral/len(ratings)*100:.1f}%)")
print(f"Negative: {negative} ({negative/len(ratings)*100:.1f}%)")
print(f"Average:  {sum(ratings)/len(ratings):.2f}")

# ✅ 무작위 수집이면 분포가 자연스럽게 나타남
# 예상: 긍정 50-70%, 중립 10-20%, 부정 20-40%
```

---

## V6.4 체크리스트

작업 완료 전 반드시 확인:

- [ ] 중립적 검색어 사용 (긍정/부정 키워드 사용 안 함)
- [ ] 검색 결과 순서대로 수집 (선택적 제외 안 함)
- [ ] 긍정/부정 사실 그대로 Rating 부여
- [ ] 각 항목당 10~30개 데이터 수집
- [ ] 다양한 출처 균형 (공식 50% + 공개 50%)
- [ ] Rating rationale 모두 작성
- [ ] Supabase DB 저장 완료
- [ ] Rating 분포 확인 (자연스러운 분포인지)

---

## V6.4 핵심 원칙

### ✅ DO (해야 할 것)
1. **무작위 수집**: 검색 결과 순서대로
2. **중립적 검색어**: 편향 없는 키워드
3. **객관적 Rating**: 사실 기반 평가
4. **있는 그대로**: 긍정은 긍정, 부정은 부정

### ❌ DON'T (하지 말아야 할 것)
1. **선택적 수집**: 긍정만 수집, 부정 제외
2. **편향된 검색어**: "성공", "훌륭한", "논란", "실패"
3. **왜곡된 평가**: 부정 사건을 긍정으로 해석
4. **의도적 조작**: 점수 조작, 데이터 취사선택

---

**V6.4 핵심 메시지**:
무작위로 수집하면 자연스럽게 균형 잡힌 평가가 나옵니다.
의도적으로 긍정/부정을 찾지 말고, 있는 그대로 수집하고 평가하세요.

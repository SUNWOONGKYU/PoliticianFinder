# 서브 에이전트 작업 지시서 V6.2 (DB 직접 저장)

**프레임워크 버전**: V6.2
**평가 방식**: Rating 기반 (-5 ~ +5)
**작업 방식**: 카테고리별 병렬 처리
**최종 산출물**: PostgreSQL DB에 직접 저장
**작성일**: 2025-10-31

---

## 📋 작업 개요

당신은 **정치인 평가 서브 에이전트**입니다.

### 입력 정보 (메인 에이전트로부터 받음)
1. **정치인 이름** (예: 오세훈)
2. **정치인 ID** (UUID, DB politicians 테이블에서 조회)
3. **카테고리 번호** (1~10)
4. **카테고리 이름** (예: 전문성)

### 작업 목표
해당 카테고리의 **7개 항목**을 평가하여 **PostgreSQL DB에 직접 저장**

---

## 📚 필수 참조 문서

### 1. 평가 항목 상세
**파일**: `설계문서_V3.0/4_70개항목_구성내역_V6.2.md`
- 당신이 담당한 카테고리의 7개 항목 확인
- 항목명, 측정 방법, 데이터 출처

### 2. Rating 척도
**파일**: `설계문서_V3.0/1_점수계산_알고리즘_V6.2.md`
- Rating -5 ~ +5 기준
- 점수 계산 공식

### 3. DB 스키마
**파일**: `설계문서_V3.0/schema_v6.2.sql`
- 테이블: `collected_data`
- 트리거: 자동 점수 계산

---

## 🎯 작업 단계

### Step 1: 항목 파악

`4_70개항목_구성내역_V6.2.md`에서 당신의 카테고리 섹션을 찾습니다.

**예시**: 카테고리 1 (전문성)
```
## 분야 1: 전문성 (7개: 공식 4, 공개 3)
**1-1. 최종 학력 수준**
**1-2. 직무 관련 자격증 보유 개수**
...
**1-7. Google Scholar 피인용 수**
```

---

### Step 2: 데이터 수집

**각 항목당 10~30개 데이터 수집**

#### 수집 규칙
- 목표: 항목당 최소 10개
- 재시도: 10개 미만 시 3회 추가 수집
- 출처 다양성: 공식 + 공개 데이터 균형

#### 데이터 출처

**공식 (Official)**
- 선거관리위원회
- 국회 의안정보시스템
- 정보공개포털
- 재산공개시스템
- 법원 판결문

**공개 (Public)**
- Wikipedia
- Google Scholar
- 언론 기사
- SNS (공식 계정)
- 시민단체 보고서

---

### Step 3: Rating 부여

**각 데이터에 -5 ~ +5 Rating**

| Rating | 평가 | 예시 |
|:---:|---|---|
| **+5** | 매우 좋음 | 국제 수상, 획기적 성과 |
| **+4** | 좋음 | 주요 법안 통과 |
| **+3** | 양호 | 활발한 활동 |
| **+2** | 약간 좋음 | 평균 이상 |
| **+1** | 조금 좋음 | 평균 근처 |
| **0** | 보통 | 평균 |
| **-1** | 조금 나쁨 | 소극적 |
| **-2** | 약간 나쁨 | 미이행 일부 |
| **-3** | 나쁨 | 윤리 논란 |
| **-4** | 매우 나쁨 | 법 위반 |
| **-5** | 극도로 나쁨 | 범죄 유죄 판결 |

#### Rating 원칙
1. 객관적 사실 기반
2. 출처 신뢰도 고려
3. 맥락 고려
4. 일관성 유지
5. 근거 명시 (rationale 필수)

---

### Step 4: PostgreSQL DB에 저장

#### DB 연결

```python
import psycopg2
from psycopg2 import sql
import os
from dotenv import load_dotenv

load_dotenv()

# Supabase PostgreSQL 연결
conn = psycopg2.connect(
    host=os.getenv('SUPABASE_HOST'),
    port=os.getenv('SUPABASE_PORT', 5432),
    database=os.getenv('SUPABASE_DB'),
    user=os.getenv('SUPABASE_USER'),
    password=os.getenv('SUPABASE_PASSWORD')
)
```

#### 데이터 삽입

**테이블**: `collected_data`

```python
cursor = conn.cursor()

for item_num in range(1, 8):  # 7개 항목
    for data_point in data_points:  # 각 항목당 10-30개
        cursor.execute("""
            INSERT INTO collected_data (
                politician_id,
                ai_name,
                category_num,
                item_num,
                data_title,
                data_content,
                data_source,
                source_url,
                collection_date,
                rating,
                rating_rationale,
                reliability
            ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
        """, (
            politician_id,           # UUID (입력받음)
            'Claude',                # AI 이름
            category_num,            # 1~10 (입력받음)
            item_num,                # 1~7
            data_point['title'],     # 데이터 제목
            data_point['content'],   # 데이터 내용
            data_point['source'],    # 출처명
            data_point['url'],       # 출처 URL
            data_point['date'],      # 데이터 발생 일자
            data_point['rating'],    # -5 ~ +5
            data_point['rationale'], # Rating 이유
            data_point['reliability'] # 0.0 ~ 1.0
        ))

conn.commit()
```

#### 자동 점수 계산

DB에 데이터가 INSERT되면 **트리거가 자동 실행**:
1. `collected_data` 삽입 → `trigger_calculate_item_score()` 실행
2. `ai_item_scores` 테이블에 Item Score 자동 생성
3. `trigger_calculate_category_score()` 실행
4. `ai_category_scores` 테이블에 Category Score 자동 생성
5. `trigger_calculate_final_score()` 실행 (10개 카테고리 완료 시)
6. `ai_final_scores` 테이블에 최종 점수 + 등급 자동 생성

---

### Step 5: 작업 완료 보고

```python
# 작업 완료 확인
cursor.execute("""
    SELECT
        category_num,
        item_num,
        COUNT(*) as data_count,
        AVG(rating) as avg_rating
    FROM collected_data
    WHERE politician_id = %s AND category_num = %s
    GROUP BY category_num, item_num
    ORDER BY item_num
""", (politician_id, category_num))

results = cursor.fetchall()

# 메인 에이전트에게 보고
print(f"✅ 카테고리 {category_num} ({category_name}) 완료")
print(f"- 정치인: {politician_name}")
print(f"- 총 데이터: {sum(r[2] for r in results)}개")
print(f"- 평균 Rating: {sum(r[3] for r in results) / len(results):.2f}")
print(f"- 항목별 데이터 수: {[r[2] for r in results]}")
```

---

## ⚠️ 주의사항

### 1. 데이터 품질

✅ **해야 할 것**
- 최소 2개 이상 독립적 출처로 교차 검증
- 출처 URL 정확히 기록
- Rating 이유 구체적으로 명시
- 객관적 사실 기반

❌ **하지 말 것**
- 추측 기반 Rating
- 출처 불명확한 정보
- 주관적 편향
- 데이터 조작

### 2. 데이터 수집 실패 시

10개 미만 시:
1. 1차 재시도: 다른 검색어
2. 2차 재시도: 다른 출처
3. 3차 재시도: 관련 키워드 확장

3회 실패 후 10개 미만:
- 현재 데이터로 진행
- 메인 에이전트에게 경고 보고

### 3. DB 충돌 방지

10개 서브 에이전트가 동시에 DB에 쓰므로:
- **transaction 사용** (`conn.commit()` 적절히)
- **에러 처리** (`try-except` 사용)
- **재시도 로직** (connection timeout 대비)

```python
try:
    cursor.execute(...)
    conn.commit()
except psycopg2.Error as e:
    conn.rollback()
    print(f"DB Error: {e}")
    # 재시도 로직
```

### 4. 평가 중립성

- 정치적 중립
- 사실 기반
- 일관성
- 투명성

---

## 📊 품질 체크리스트

작업 완료 전 확인:

- [ ] 7개 항목 모두 평가 완료
- [ ] 각 항목당 최소 10개 데이터 수집
- [ ] 모든 데이터에 Rating 부여
- [ ] 모든 Rating에 rationale 작성
- [ ] 출처 URL 정확히 기록
- [ ] DB 삽입 완료 (`collected_data` 테이블)
- [ ] 트리거 실행 확인 (`ai_item_scores`, `ai_category_scores`)
- [ ] 에러 없이 commit 성공

---

## 🔄 병렬 처리 플로우

```
메인 에이전트
  │
  ├─ 정치인 정보 조회 (politicians 테이블)
  │  └─ politician_id (UUID) 획득
  │
  ├─ 10개 서브 에이전트 병렬 실행
  │   ├─ Sub-Agent 1 → Category 1 (전문성) → collected_data 삽입
  │   ├─ Sub-Agent 2 → Category 2 (리더십) → collected_data 삽입
  │   ├─ Sub-Agent 3 → Category 3 (비전) → collected_data 삽입
  │   ├─ Sub-Agent 4 → Category 4 (청렴성) → collected_data 삽입
  │   ├─ Sub-Agent 5 → Category 5 (윤리성) → collected_data 삽입
  │   ├─ Sub-Agent 6 → Category 6 (책임감) → collected_data 삽입
  │   ├─ Sub-Agent 7 → Category 7 (투명성) → collected_data 삽입
  │   ├─ Sub-Agent 8 → Category 8 (소통능력) → collected_data 삽입
  │   ├─ Sub-Agent 9 → Category 9 (대응성) → collected_data 삽입
  │   └─ Sub-Agent 10 → Category 10 (공익추구) → collected_data 삽입
  │
  └─ 모든 서브 에이전트 완료 대기
      │
      └─ DB 트리거 자동 실행
          ├─ ai_item_scores (70개 항목 점수)
          ├─ ai_category_scores (10개 분야 점수)
          └─ ai_final_scores (최종 점수 + 등급)
```

---

## 💻 Python 코드 예시 (전체)

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
서브 에이전트 - 카테고리별 평가 및 DB 저장
"""

import psycopg2
from psycopg2 import sql
import os
from dotenv import load_dotenv
from datetime import datetime

load_dotenv()

def evaluate_category(politician_id, politician_name, category_num, category_name):
    """
    특정 카테고리 평가 및 DB 저장
    """
    # DB 연결
    conn = psycopg2.connect(
        host=os.getenv('SUPABASE_HOST'),
        port=os.getenv('SUPABASE_PORT', 5432),
        database=os.getenv('SUPABASE_DB'),
        user=os.getenv('SUPABASE_USER'),
        password=os.getenv('SUPABASE_PASSWORD')
    )
    cursor = conn.cursor()

    try:
        # Step 1: 항목 파악 (4_70개항목_구성내역_V6.2.md 참조)
        items = get_items_for_category(category_num)  # 7개 항목

        total_data_count = 0

        # Step 2-3: 각 항목별 데이터 수집 + Rating 부여
        for item_num, item_info in enumerate(items, 1):
            print(f"  항목 {item_num}/{len(items)}: {item_info['name']}")

            # 데이터 수집 (WebFetch, WebSearch 사용)
            data_points = collect_data_for_item(
                politician_name,
                item_info,
                target_count=15  # 10-30개 목표
            )

            # Step 4: DB 저장
            for dp in data_points:
                cursor.execute("""
                    INSERT INTO collected_data (
                        politician_id, ai_name, category_num, item_num,
                        data_title, data_content, data_source, source_url,
                        collection_date, rating, rating_rationale, reliability
                    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                """, (
                    politician_id,
                    'Claude',
                    category_num,
                    item_num,
                    dp['title'],
                    dp['content'],
                    dp['source'],
                    dp['url'],
                    dp['date'],
                    dp['rating'],
                    dp['rationale'],
                    dp['reliability']
                ))

            total_data_count += len(data_points)
            conn.commit()  # 항목별 commit

        # Step 5: 작업 완료 보고
        cursor.execute("""
            SELECT AVG(rating)
            FROM collected_data
            WHERE politician_id = %s AND category_num = %s
        """, (politician_id, category_num))

        avg_rating = cursor.fetchone()[0]

        print(f"\n✅ 카테고리 {category_num} ({category_name}) 완료")
        print(f"- 총 데이터: {total_data_count}개")
        print(f"- 평균 Rating: {avg_rating:.2f}")

        return True

    except Exception as e:
        conn.rollback()
        print(f"❌ 에러 발생: {e}")
        return False

    finally:
        cursor.close()
        conn.close()

def get_items_for_category(category_num):
    """
    카테고리 번호로부터 7개 항목 정보 가져오기
    (4_70개항목_구성내역_V6.2.md 파싱)
    """
    # TODO: 실제 구현
    pass

def collect_data_for_item(politician_name, item_info, target_count=15):
    """
    특정 항목에 대한 데이터 수집 + Rating 부여
    (WebFetch, WebSearch 사용)
    """
    # TODO: 실제 구현
    pass

if __name__ == '__main__':
    # 메인 에이전트로부터 받은 정보
    evaluate_category(
        politician_id='uuid-here',
        politician_name='오세훈',
        category_num=1,
        category_name='전문성'
    )
```

---

**작성일**: 2025-10-31
**버전**: V6.2
**작성자**: Claude Code
**목적**: 서브 에이전트 DB 직접 저장 방식 표준화

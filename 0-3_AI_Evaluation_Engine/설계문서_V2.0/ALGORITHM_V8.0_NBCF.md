# 정치인 평가 알고리즘 Version 8.0

**Official Name**: Bayesian Prior with Negativity Bias Correction Factor (NBCF)
**Korean Name**: 부정 편향 보정 계수 기반 베이지안 평가 알고리즘
**Version**: 8.0
**Date**: 2025-10-30
**Author**: Politician Finder AI Team

---

## 🎯 핵심 개념

### 문제 정의
AI가 수집하는 데이터는 언론 보도와 공개 기록에 의존하며, **언론은 긍정보다 부정을 2-3배 더 많이 보도**한다 (Negativity Bias). 이로 인해 실제보다 낮은 점수가 산출된다.

### 해결 방법
**부정 편향 보정 계수 (Negativity Bias Correction Factor, NBCF)**를 도입하여:
1. 데이터 점수 범위를 **-3 ~ +7**로 비대칭 설정 (부정 제한, 긍정 확대)
2. 보정 계수 **λ = 3/7**을 적용하여 Prior 7.0 중심 분포 구현

---

## 📐 수학적 정의

### 1. 핵심 상수

```python
PRIOR = 7.0                # 민주적 정당성 기준점
NBCF = 3.0 / 7.0          # λ = 0.4286 (부정 편향 보정 계수)
DATA_RANGE = [-3, +7]     # 비대칭 증거 점수 범위
ITEM_RANGE = [4.0, 10.0]  # 항목 점수 범위
FINAL_RANGE = [400, 1000] # 최종 점수 범위
```

### 2. 점수 계산 공식

#### Level 1: 데이터 등급 분류 (Evidence Grade Classification)
```
G_i ∈ {-3, -2, -1, 0, +1, +2, +3, +4, +5, +6, +7}, i = 1, 2, ..., N
```
- AI가 수집한 각 데이터의 **등급 분류** (점수 매기기 아님!)
- AI의 역할: 데이터를 보고 "좋음 5등급", "나쁨 2등급" 등으로 **분류**
- 등급 → 점수 자동 변환: 좋음 5등급 = +5점, 나쁨 2등급 = -2점

#### Level 2: 항목 점수 (Item Score)
```python
# 등급을 점수로 변환
scores = [grade_to_score(G_i) for G_i in grades]

# 평균 계산
평균 = Σ(scores) / N

# NBCF 적용
deviation = 평균 × NBCF
          = 평균 × (3/7)

# 최종 항목 점수
Item_Score = PRIOR + deviation
           = 7.0 + (평균 × 3/7)
```

**grade_to_score 함수**:
```python
def grade_to_score(grade_text):
    """등급 텍스트를 점수로 변환"""
    # "좋음 5등급" → +5
    # "나쁨 2등급" → -2
    # "중립" → 0
    return score
```

**범위 보장**:
```
최소: 평균 = -3 → 7.0 + (-3 × 3/7) = 7.0 - 1.29 = 5.71
최대: 평균 = +7 → 7.0 + (7 × 3/7) = 7.0 + 3.0 = 10.0
```

#### Level 3: 분야 점수 (Category Score)
```python
Category_Score = (1/7) × Σ(Item_Score_j), j = 1 to 7
```
- 각 분야의 7개 항목 점수의 산술 평균
- 범위: [5.71, 10.0]

#### Level 4: 최종 점수 (Final Score)
```python
Final_Score = Σ(Category_Score_k) × 10, k = 1 to 10
```
- 10개 분야 점수의 합계 × 10
- 범위: [571, 1000] (실제로는 400-1000 설계)

---

## 🎲 데이터 등급 분류 기준

### AI의 역할: 등급 분류 (점수 매기기 아님!)

AI는 수집한 데이터를 보고 **어느 등급에 해당하는지 판단**합니다.

```
【긍정 데이터 분류】
"좋음 7등급" → +7점 (탁월한 성과, 수상, 혁신 사례 등)
"좋음 6등급" → +6점 (뛰어난 성과, 전문가 극찬)
"좋음 5등급" → +5점 (우수한 성과, 언론 호평)
"좋음 4등급" → +4점 (좋은 성과, 긍정 평가)
"좋음 3등급" → +3점 (긍정적 기록)
"좋음 2등급" → +2점 (약간 긍정적)
"좋음 1등급" → +1점 (미미한 긍정)

【중립 데이터 분류】
"중립" → 0점 (특별한 평가 없음, 중립적 사실 기록)

【부정 데이터 분류】
"나쁨 1등급" → -1점 (미미한 부정, 경미한 비판)
"나쁨 2등급" → -2점 (부정적, 비판 기사, 불만)
"나쁨 3등급" → -3점 (심각한 문제, 감사 지적, 징계, 처벌)
```

### 분류 원칙
1. **데이터 수집**: 출처가 명확한 데이터만 (추측/소문 금지)
2. **등급 분류**: 데이터가 어느 등급인지만 판단
3. **점수 변환**: 시스템이 자동으로 등급 → 점수 변환
4. **명확성**: "좋음 5등급"과 "좋음 6등급"은 명확히 구분 가능

---

## 🧮 계산 예시

### 예시 1: 우수한 항목

**수집 데이터 (10개)**:
```
+5, +6, +4, +7, +5, +3, +6, +4, +5, +6
```

**계산**:
```python
N = 10
합계 = 5+6+4+7+5+3+6+4+5+6 = 51
평균 = 51 / 10 = 5.1

deviation = 5.1 × (3/7) = 2.186

Item_Score = 7.0 + 2.186 = 9.186 ≈ 9.19점
```

### 예시 2: 보통 항목

**수집 데이터 (10개)**:
```
+1, 0, +2, -1, +1, 0, +2, +1, 0, +1
```

**계산**:
```python
N = 10
합계 = 1+0+2+(-1)+1+0+2+1+0+1 = 7
평균 = 7 / 10 = 0.7

deviation = 0.7 × (3/7) = 0.3

Item_Score = 7.0 + 0.3 = 7.3점
```

### 예시 3: 문제 있는 항목

**수집 데이터 (10개)**:
```
-2, -1, -3, -2, -1, 0, -2, -1, -2, -1
```

**계산**:
```python
N = 10
합계 = -2-1-3-2-1+0-2-1-2-1 = -15
평균 = -15 / 10 = -1.5

deviation = -1.5 × (3/7) = -0.643

Item_Score = 7.0 - 0.643 = 6.357 ≈ 6.36점
```

---

## 📊 통계적 특성

### 1. Prior 7.0의 의미
- **민주적 정당성**: 선거에서 당선된 정치인은 기본 70점 실력 가정
- **중립 기준점**: 특별한 증거가 없으면 7.0점
- **베이지안 사전확률**: 데이터 수집 전 초기 믿음

### 2. NBCF (λ = 3/7)의 효과

| 데이터 평균 | deviation | Item Score | 의미 |
|-----------|-----------|------------|------|
| -3.0 | -1.29 | 5.71 | 최악 |
| -2.0 | -0.86 | 6.14 | 상당히 부족 |
| -1.0 | -0.43 | 6.57 | 약간 부족 |
| **0.0** | **0.00** | **7.00** | **보통 (Prior)** |
| +1.0 | +0.43 | 7.43 | 약간 양호 |
| +2.0 | +0.86 | 7.86 | 양호 |
| +3.0 | +1.29 | 8.29 | 우수 |
| +4.0 | +1.71 | 8.71 | 매우 우수 |
| +5.0 | +2.14 | 9.14 | 뛰어남 |
| +6.0 | +2.57 | 9.57 | 최우수 |
| **+7.0** | **+3.00** | **10.00** | **완벽** |

### 3. 비대칭성의 이유

**데이터 범위**:
- 부정: -3 ~ 0 (폭 3)
- 긍정: 0 ~ +7 (폭 7)
- **비율 3:7 = Negativity Bias 역보정**

**최종 점수 범위**:
- 이론적 최소: 5.71 × 7 × 10 = 400점 (사실상 불가능)
- 이론적 최대: 10.0 × 7 × 10 = 700점 (분야별)
- 실제 예상: 600-800점 (대부분의 정치인)

---

## 🔬 이론적 근거

### 1. Negativity Bias (부정 편향)

**학술 근거**:
- **Soroka et al. (2019)**: 17개국 연구, 정치 뉴스의 65%가 부정적 프레임
- **Trussler & Soroka (2014)**: 헤드라인 1개당 부정 단어 추가 시 클릭률 2.3% 상승
- **Nature (2023)**: 부정 뉴스가 긍정 뉴스보다 심리적으로 2배 강한 영향

**우리의 대응**:
```
언론의 부정 편향 (2:1) → 데이터 범위 비대칭 (3:7) → 상쇄
```

### 2. Bayesian Prior

**통계학적 정당성**:
```
사후확률 = (우도 × 사전확률) / 정규화 상수

P(실력|데이터) = P(데이터|실력) × P(실력) / P(데이터)

여기서 P(실력) = Prior 7.0
```

**의미**:
- 데이터 없이도 기본 점수 제공
- 소수 데이터에 과도하게 반응하지 않음
- 민주적 정당성 반영

### 3. Linear Normalization

**공식**:
```
normalized = value × (target_range / source_range)
          = average × (3 / 7)
```

**특성**:
- **Data Independence**: 데이터 개수와 무관
- **Scale Invariance**: 비율 관계 보존
- **Range Guaranteed**: 항상 [5.71, 10.0] 범위

---

## 🆚 이전 버전과 비교

### Version 6.0 (Bayesian Weighted Average)
```python
# 기존 방식
Item_Score = (평균 × N + 7.0 × 10) / (N + 10)

문제점:
- N=10: 평균 0 → 점수 5.83
- N=100: 평균 0 → 점수 6.70
- 데이터 개수에 따라 점수 변동!
```

### Version 8.0 (NBCF)
```python
# 새 방식
Item_Score = 7.0 + (평균 × 3/7)

장점:
- N=10: 평균 0 → 점수 7.00
- N=100: 평균 0 → 점수 7.00
- 데이터 개수와 무관!
```

### 비교표

| 항목 | V6.0 | V8.0 (NBCF) |
|------|------|-------------|
| 데이터 범위 | -10 ~ +10 | -3 ~ +7 |
| 보정 방식 | Weighted Average | Linear Scaling |
| N 의존성 | 있음 | 없음 |
| Prior 영향 | N 증가 시 감소 | 항상 일정 |
| 부정 편향 대응 | 없음 | 있음 (비대칭) |
| 계산 복잡도 | 중간 | 낮음 |
| 투명성 | 중간 | 높음 |

---

## 🎓 학술적 기여

### 1. 새로운 용어 정의

**Negativity Bias Correction Factor (NBCF)**
- 영문: Negativity Bias Correction Factor
- 한글: 부정 편향 보정 계수
- 기호: λ (lambda)
- 값: 3/7 ≈ 0.4286

**특징**:
- 기존 문헌에 없는 신규 용어
- 언론 부정 편향을 수학적으로 보정
- 모든 평가 대상에 동일 적용 = 공정성

### 2. 방법론적 혁신

**Asymmetric Evidence Range Method**
- 대칭 범위 대신 비대칭 범위 사용
- 실증적 편향(Negativity Bias)을 구조적으로 보정
- Prior-Centered Scaling 구현

### 3. 응용 가능성

- 정치인 평가
- 기업 평가 (ESG, CSR)
- 학술 평가 (Impact Factor 보정)
- 제품 리뷰 분석 (별점 보정)
- 모든 "편향된 정보원"에 적용 가능

---

## ⚖️ 윤리적 고려사항

### 1. 공정성 (Fairness)
- ✅ 모든 정치인에 동일 방법 적용
- ✅ 투명한 계산 과정
- ✅ 재현 가능한 결과

### 2. 투명성 (Transparency)
- ✅ 공개된 알고리즘
- ✅ 명확한 수식
- ✅ 이해 가능한 로직

### 3. 책임성 (Accountability)
- ✅ 데이터 출처 명시
- ✅ 한계 인정 (AI 환각 가능성)
- ✅ 이의 제기 가능

### 4. 한계 인정

**알고리즘의 한계**:
1. NBCF (3/7) 값은 경험적 설정
2. 언론 부정 편향 비율이 정확히 7:3은 아님
3. AI 환각(hallucination) 가능성 존재
4. 최근 사건에 편향될 수 있음

**완화 방안**:
1. 5개 AI 엔진 병렬 사용 (미래 계획)
2. 출처 검증 강화
3. 정기적 알고리즘 검증
4. 사용자 피드백 반영

---

## 📝 구현 요구사항

### 1. 데이터 수집
- 항목당 최소 10개, 목표 20개 데이터
- 출처가 명확한 데이터만
- 정량 데이터 우선, 정성 데이터 보조

### 2. 평가 프롬프트 (등급 분류)
```python
"""
**중요**: AI는 점수를 매기는 것이 아니라 **등급을 분류**합니다.

수집한 데이터를 보고 어느 등급에 해당하는지 판단하세요:

【데이터가 긍정적이면】→ 좋음 1~7등급 중 선택
【데이터가 중립적이면】→ 중립
【데이터가 부정적이면】→ 나쁨 1~3등급 중 선택

**분류 예시**:
- "대통령 표창 수상"
  → 판단: 탁월한 성과
  → 등급: "좋음 7등급"
  → 시스템 변환: +7점

- "예산 10% 증액"
  → 판단: 긍정적 기록
  → 등급: "좋음 3등급"
  → 시스템 변환: +3점

- "회의 참석 (특별한 평가 없음)"
  → 판단: 중립적 사실
  → 등급: "중립"
  → 시스템 변환: 0점

- "언론 비판 기사 1건"
  → 판단: 부정적 보도
  → 등급: "나쁨 2등급"
  → 시스템 변환: -2점

- "검찰 수사 개시"
  → 판단: 심각한 문제
  → 등급: "나쁨 3등급"
  → 시스템 변환: -3점

**AI의 출력 형식**:
{
  "title": "데이터 요약",
  "content": "데이터 내용",
  "grade": "좋음 5등급",  // 등급만 출력!
  "source": "출처"
}
"""
```

### 3. 계산 함수
```python
def grade_to_score(grade_text):
    """등급 텍스트를 점수로 변환"""
    grade_map = {
        "좋음 7등급": +7, "좋음 6등급": +6, "좋음 5등급": +5,
        "좋음 4등급": +4, "좋음 3등급": +3, "좋음 2등급": +2,
        "좋음 1등급": +1,
        "중립": 0,
        "나쁨 1등급": -1, "나쁨 2등급": -2, "나쁨 3등급": -3
    }
    return grade_map.get(grade_text, 0)


def calculate_item_score(grades):
    """NBCF 기반 항목 점수 계산

    Args:
        grades: 등급 텍스트 리스트 ["좋음 5등급", "나쁨 2등급", ...]
    """
    if len(grades) == 0:
        return 7.0  # Prior

    # 등급을 점수로 변환
    scores = [grade_to_score(g) for g in grades]

    # 평균 계산
    average = sum(scores) / len(scores)

    # NBCF 적용
    deviation = average * (3.0 / 7.0)
    item_score = 7.0 + deviation

    return max(4.0, min(10.0, item_score))
```

---

## 🔮 향후 개선 방향

### 1. 단기 (1-3개월)
- [ ] 10명 이상 정치인 평가로 실증 검증
- [ ] NBCF 값 (3/7) 최적화 연구
- [ ] 여론조사 지지율과 상관관계 분석

### 2. 중기 (3-6개월)
- [ ] 5개 AI 엔진 병렬 평가 구현
- [ ] 실시간 데이터 수집 자동화
- [ ] 시계열 분석 (점수 변화 추적)

### 3. 장기 (6-12개월)
- [ ] Empirical Bayes로 Prior 동적 조정
- [ ] 출처별 신뢰도 가중치 도입
- [ ] 분야별 가중치 사용자 설정 가능

---

## 📚 참고 문헌

### Negativity Bias
1. Soroka, S., Fournier, P., & Nir, L. (2019). "Cross-national evidence of a negativity bias in psychophysiological reactions to news." *PNAS*, 116(38), 18888-18892.

2. Trussler, M., & Soroka, S. (2014). "Consumer demand for cynical and negative news frames." *International Journal of Press/Politics*, 19(3), 360-379.

### Bayesian Statistics
3. Gelman, A., et al. (2013). *Bayesian Data Analysis* (3rd ed.). CRC Press.

4. Kruschke, J. K. (2014). *Doing Bayesian Data Analysis* (2nd ed.). Academic Press.

### Bias Correction
5. Heckman, J. J. (1979). "Sample selection bias as a specification error." *Econometrica*, 47(1), 153-161.

6. Little, R. J., & Rubin, D. B. (2019). *Statistical Analysis with Missing Data* (3rd ed.). Wiley.

---

## 📄 라이선스

본 알고리즘은 **Politician Finder AI** 프로젝트의 일부입니다.

- 학술 연구 목적: 자유 사용 가능 (출처 명시)
- 상업적 사용: 사전 승인 필요

---

## 📞 연락처

**프로젝트**: Politician Finder AI
**버전**: 8.0 (NBCF)
**최종 수정**: 2025-10-30
**작성자**: AI Evaluation Team

---

**문서 종료**

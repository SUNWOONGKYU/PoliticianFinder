
================================================================================
ğŸš€ 95% í† í° ì ˆê° í…ŒìŠ¤íŠ¸
================================================================================
í…ŒìŠ¤íŠ¸ ëŒ€ìƒ: 023139c6
ë°©ë²•: Prompt Caching + Category Integration
ëª©í‘œ: 95% í† í° ì ˆê°
================================================================================

================================================================================
ğŸš€ 95% í† í° ì ˆê° í…ŒìŠ¤íŠ¸ ì‹œì‘
================================================================================
ì •ì¹˜ì¸ ID: 023139c6
ë°©ë²•: Prompt Caching (4 breakpoints) + Category Integration
================================================================================

ğŸ“¥ 1ë‹¨ê³„: ë°ì´í„° ë¡œë“œ
  DBì—ì„œ 1000ê°œ í•­ëª© ë¡œë“œ

ğŸ—œï¸ 2ë‹¨ê³„: ë°ì´í„° ì¤€ë¹„

  ğŸ“¦ ë°ì´í„° ì¤€ë¹„ ì¤‘...
  ì›ë³¸: 1000ê°œ í•­ëª©
  ì¤‘ë³µ ì œê±° í›„: 1000ê°œ í•­ëª©
  150ê°œë¡œ ì œí•œ: 150ê°œ í•­ëª©
  ì••ì¶• ì™„ë£Œ
  ìµœì¢…: 150ê°œ ë°ì´í„°

ğŸ“Š 3ë‹¨ê³„: 3ê°œ AI ë³‘ë ¬ í‰ê°€

  ğŸ“Š ChatGPT í‰ê°€ ì‹œì‘
    âŒ ì˜¤ë¥˜: Error code: 400 - {'error': {'message': "Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}

  ğŸ“Š Grok í‰ê°€ ì‹œì‘

  ğŸ“Š Claude í‰ê°€ ì‹œì‘ (Prompt Caching)
    âŒ ì˜¤ë¥˜: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'max_tokens: 16000 > 8192, which is the maximum allowed number of output tokens for claude-3-5-haiku-20241022'}, 'request_id': 'req_011CViHeDnfQr7JU96FvprYy'}
    âŒ ì˜¤ë¥˜: 'choices'

ğŸ“ˆ 4ë‹¨ê³„: Pooling ì ìˆ˜ ê³„ì‚°

================================================================================
âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!
================================================================================
ì†Œìš” ì‹œê°„: 3.1ì´ˆ (0.1ë¶„)
ì •ì¹˜ì¸: ì†¡ì„ì¤€
ë°ì´í„° ìˆ˜: 150ê°œ

ğŸ“Š í† í° ì‚¬ìš©ëŸ‰:
  Claude:
    Input: 0
    Output: 0
    Cache Creation: 0
    Cache Read: 0
  ChatGPT:
    Input: 0
    Output: 0
  Grok:
    Input: 0
    Output: 0

  ì´í•©:
    Total Input: 0
    Total Output: 0
    Total Cache: 0
    Grand Total: 0

ğŸ“Š Pooling ì ìˆ˜:
  ì „ë¬¸ì„±     : 0.00ì 
  ë¦¬ë”ì‹­     : 0.00ì 
  ë¹„ì „      : 0.00ì 
  ì²­ë ´ë„     : 0.00ì 
  ìœ¤ë¦¬ì„±     : 0.00ì 
  ì±…ì„ê°     : 0.00ì 
  íˆ¬ëª…ì„±     : 0.00ì 
  ì†Œí†µëŠ¥ë ¥    : 0.00ì 
  ëŒ€ì‘ì„±     : 0.00ì 
  ê³µìµì„±     : 0.00ì 
Traceback (most recent call last):
  File "C:\Development_PoliticianFinder_com\Developement_Real_PoliticianFinder\0-3_AI_Evaluation_Engine\pooling_95percent_savings_test.py", line 516, in <module>
    asyncio.run(main())
    ~~~~~~~~~~~^^^^^^^^
  File "C:\Python313\Lib\asyncio\runners.py", line 195, in run
    return runner.run(main)
           ~~~~~~~~~~^^^^^^
  File "C:\Python313\Lib\asyncio\runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
  File "C:\Python313\Lib\asyncio\base_events.py", line 725, in run_until_complete
    return future.result()
           ~~~~~~~~~~~~~^^
  File "C:\Development_PoliticianFinder_com\Developement_Real_PoliticianFinder\0-3_AI_Evaluation_Engine\pooling_95percent_savings_test.py", line 503, in main
    result = await evaluator.test_95percent_savings(TEST_POLITICIAN['id'])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Development_PoliticianFinder_com\Developement_Real_PoliticianFinder\0-3_AI_Evaluation_Engine\pooling_95percent_savings_test.py", line 449, in test_95percent_savings
    avg_score = sum(pooling_scores.values()) / len(pooling_scores)
                ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~
ZeroDivisionError: division by zero

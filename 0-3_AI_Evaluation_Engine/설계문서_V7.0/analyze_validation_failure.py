#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""ê²€ì¦ ì‹¤íŒ¨ ì›ì¸ ë¶„ì„"""

import os
import sys
import io
import requests
from supabase import create_client
from dotenv import load_dotenv

# UTF-8 ì¶œë ¥
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

load_dotenv()

supabase = create_client(
    os.getenv('SUPABASE_URL'),
    os.getenv('SUPABASE_SERVICE_ROLE_KEY')
)

politician_id = 'd0a5d6e1'

print('=' * 80)
print('ê²€ì¦ ì‹¤íŒ¨ ì›ì¸ ë¶„ì„')
print('=' * 80)

# Gemini ë°ì´í„° ìƒ˜í”Œ (10ê°œ)
print('\n[1] Gemini URL ìƒ˜í”Œ (10ê°œ)')
print('-' * 80)
result = supabase.table('collected_data_v30').select('source_url, title, source_name, data_type, published_date')\
    .eq('politician_id', politician_id)\
    .eq('collector_ai', 'Gemini')\
    .limit(10)\
    .execute()

gemini_urls = []
for idx, item in enumerate(result.data, 1):
    url = item['source_url']
    gemini_urls.append(url)
    print(f"\n{idx}. {item['title'][:50]}...")
    print(f"   Source: {item.get('source_name', 'N/A')} ({item['data_type']})")
    print(f"   Date: {item.get('published_date', 'N/A')}")
    print(f"   URL: {url}")

    # URL ì‹¤ì œ ì ‘ê·¼ í…ŒìŠ¤íŠ¸
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.head(url, headers=headers, timeout=10, allow_redirects=True)
        if response.status_code < 400:
            print(f"   âœ… ì ‘ê·¼ ê°€ëŠ¥ (status: {response.status_code})")
        else:
            print(f"   âŒ ì ‘ê·¼ ë¶ˆê°€ (status: {response.status_code})")
    except requests.exceptions.Timeout:
        print(f"   â±ï¸ Timeout (10ì´ˆ)")
    except requests.exceptions.ConnectionError:
        print(f"   ğŸ”Œ Connection Error")
    except Exception as e:
        print(f"   âŒ Error: {type(e).__name__}")

# Perplexity ë°ì´í„° ìƒ˜í”Œ (10ê°œ)
print('\n\n[2] Perplexity URL ìƒ˜í”Œ (10ê°œ)')
print('-' * 80)
result = supabase.table('collected_data_v30').select('source_url, title, source_name, data_type, published_date')\
    .eq('politician_id', politician_id)\
    .eq('collector_ai', 'Perplexity')\
    .limit(10)\
    .execute()

perplexity_urls = []
for idx, item in enumerate(result.data, 1):
    url = item['source_url']
    perplexity_urls.append(url)
    print(f"\n{idx}. {item['title'][:50]}...")
    print(f"   Source: {item.get('source_name', 'N/A')} ({item['data_type']})")
    print(f"   Date: {item.get('published_date', 'N/A')}")
    print(f"   URL: {url}")

    # URL ì‹¤ì œ ì ‘ê·¼ í…ŒìŠ¤íŠ¸
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.head(url, headers=headers, timeout=10, allow_redirects=True)
        if response.status_code < 400:
            print(f"   âœ… ì ‘ê·¼ ê°€ëŠ¥ (status: {response.status_code})")
        else:
            print(f"   âŒ ì ‘ê·¼ ë¶ˆê°€ (status: {response.status_code})")
    except requests.exceptions.Timeout:
        print(f"   â±ï¸ Timeout (10ì´ˆ)")
    except requests.exceptions.ConnectionError:
        print(f"   ğŸ”Œ Connection Error")
    except Exception as e:
        print(f"   âŒ Error: {type(e).__name__}")

# í†µê³„
print('\n\n[3] AIë³„ ì „ì²´ í˜„í™©')
print('-' * 80)
for ai in ['Gemini', 'Perplexity']:
    result = supabase.table('collected_data_v30').select('*', count='exact')\
        .eq('politician_id', politician_id)\
        .eq('collector_ai', ai)\
        .execute()
    print(f'{ai}: {result.count}ê°œ')

print('\n' + '=' * 80)

# 프롬프트 최적화 전략 V40

**작성일**: 2026-02-02
**버전**: V40
**목적**: 4개 AI 평가 시스템의 토큰/비용/시간 절감 (공정성 유지)

---

## 목차

1. [프롬프트 설계 원칙](#1-프롬프트-설계-원칙)
2. [카테고리별 프롬프트 구조](#2-카테고리별-프롬프트-구조)
3. [토큰 최적화](#3-토큰-최적화)
4. [캐싱 전략](#4-캐싱-전략)
5. [AI별 프롬프트 차이](#5-ai별-프롬프트-차이)

---

## 1. 프롬프트 설계 원칙

### 1.1 핵심 원칙

**간결성**:
- 불필요한 설명 제거
- 표 형식 축약
- 핵심만 전달

**명확한 출력 형식**:
- JSON 구조 명시
- 필드명 명확
- 예시 제공

**등급 기준 명시**:
- V40 등급 체계 (+4 ~ -4)
- 점수 변환 규칙
- 판단 기준

### 1.2 공정성 유지

**4개 AI 동일 프롬프트**:
- 내용 완전 동일
- 길이 동일
- 순서 동일

**캐싱의 영향**:
- 캐싱은 전송만 최적화
- 프롬프트 내용 불변
- 평가 결과 동일

---

## 2. 카테고리별 프롬프트 구조

### 2.1 공통 구조

```python
# 레벨 1: 시스템 프롬프트 (모든 평가 공통)
SYSTEM_PROMPT = """등급(점수): +4(+8)탁월 | +3(+6)우수 | +2(+4)양호 | +1(+2)보통
           -1(-2)미흡 | -2(-4)부족 | -3(-6)심각 | -4(-8)최악

판단: 긍정(성과/업적)→+4~+1 | 부정(논란/비판)→-1~-4

JSON: {"evaluations":[{"id":"UUID","rating":"+4~-4","rationale":"근거"}]}"""

# 레벨 2: 정치인별 카테고리별 프롬프트
def get_politician_category_prompt(politician_id, politician_name, category_name):
    profile = format_politician_profile(politician_id, politician_name)
    cat_kor = CATEGORY_MAP.get(category_name.lower())

    return f"""{profile}
카테고리: {cat_kor}
아래 데이터를 객관적으로 평가하세요."""

# 레벨 3: 배치 데이터 (매번 변경)
def format_batch_data(items):
    items_text = ""
    for i, item in enumerate(items, 1):
        items_text += f"""
[{i}]
ID: {item['id']}
제목: {item['title']}
내용: {item['content'][:200]}
출처: {item['source_name']}
날짜: {item['published_date']}
"""
    return items_text
```

### 2.2 전체 프롬프트 구성

```python
def build_evaluation_prompt(politician_id, politician_name, category_name, items):
    """전체 평가 프롬프트 (4개 AI 공통)"""
    system = SYSTEM_PROMPT
    politician = get_politician_category_prompt(politician_id, politician_name, category_name)
    batch = format_batch_data(items)

    return f"""{system}

{politician}

데이터:
{batch}"""
```

---

## 3. 토큰 최적화

### 3.1 현재 프롬프트 분석

**Before (기존 프롬프트)**:
```
당신은 정치인 평가 전문가입니다.

{profile_info}  # 150 tokens

**평가 카테고리**: {cat_kor}

**등급 체계** (+4 ~ -4) - V40 기준 (8단계):
| 등급 | 판단 기준 | 점수 |
|------|-----------|------|
| +4 | 탁월함 - 해당 분야 모범 사례 | +8 |
| +3 | 우수함 - 긍정적 평가 | +6 |
| +2 | 양호함 - 기본 충족 | +4 |
| +1 | 보통 긍정 - 평균 이상 | +2 |
| -1 | 미흡함 - 개선 필요 | -2 |
| -2 | 부족함 - 문제 있음 | -4 |
| -3 | 매우 부족 - 심각한 문제 | -6 |
| -4 | 극히 부족 - 정치인 부적합 | -8 |

**평가 기준**:
- 긍정적 내용 (성과, 업적, 칭찬) → +4~+1
- 부정적 내용 (논란, 비판, 문제) → -1~-4

{items_text}  # 2,500 tokens

JSON 형식으로 반환:
```json
{
  "evaluations": [
    {
      "id": "데이터 ID 값",
      "rating": "+4~-4",
      "rationale": "평가 근거"
    }
  ]
}
```

총 토큰: ~3,350 tokens
```

**After (최적화 프롬프트)**:
```
{profile_info}  # 150 tokens

카테고리: {cat_kor}

등급: +4(탁월,+8) +3(우수,+6) +2(양호,+4) +1(보통,+2) -1(미흡,-2) -2(부족,-4) -3(심각,-6) -4(최악,-8)
판단: 긍정(성과/업적)→+4~+1 | 부정(논란/비판)→-1~-4

데이터:
{items_text}  # 2,500 tokens

JSON: {"evaluations":[{"id":"UUID","rating":"+4~-4","rationale":"근거"}]}

총 토큰: ~2,910 tokens (13% 절감)
```

### 3.2 토큰 절감 효과

| 구성 요소 | Before | After | 절감 |
|-----------|--------|-------|------|
| 역할 정의 | 20 | 0 | 100% |
| 프로필 | 150 | 150 | 0% |
| 카테고리 | 30 | 10 | 67% |
| 등급 체계 표 | 350 | 120 | 66% |
| 평가 기준 | 100 | 50 | 50% |
| JSON 형식 | 200 | 80 | 60% |
| 배치 데이터 | 2,500 | 2,500 | 0% |
| **합계** | **3,350** | **2,910** | **13%** |

### 3.3 배치 크기 조정

**현재 (10개 배치)**:
```
카테고리당 100개 = 10회 호출
각 호출: 3,350 tokens
총: 3,350 × 10 = 33,500 tokens
```

**최적화 (50개 배치)**:
```
카테고리당 100개 = 2회 호출
각 호출: 13,350 tokens (850 고정 + 12,500 데이터)
총: 13,350 × 2 = 26,700 tokens

절감: (33,500 - 26,700) / 33,500 = 20.3%
```

**이유**:
- 고정 부분 (850 tokens) 반복: 10회 → 2회 (80% 감소)
- 프롬프트 오버헤드: 25.4% → 6.4%

---

## 4. 캐싱 전략

### 4.1 AI별 캐싱 기능

| AI | 캐싱 유형 | 최소 토큰 | TTL | 할인율 | 코드 수정 |
|----|----------|---------|-----|--------|----------|
| **Claude** | ❌ 불가 (Subscription) | - | - | - | 불필요 |
| **ChatGPT** | ✅ Automatic | 1024 | 5분~24시간 | 50% | 불필요 |
| **Gemini** | ✅ Explicit | 2048 | 60분 | 75% | 필요 |
| **Grok** | ✅ Automatic | 1024 | 자동 | 90% | 불필요 |

### 4.2 캐시 레벨 구조

```
레벨 1: 시스템 프롬프트 (전체 공통)
└─> 등급 체계 + 평가 기준 + JSON 형식
    캐시 키: "v40_system_prompt"
    재사용: 모든 평가 (4,000+ 회)

레벨 2: 정치인별 카테고리별
└─> 레벨 1 + 정치인 프로필 + 카테고리명
    캐시 키: "v40_{politician_id}_{category}"
    재사용: 10개 배치 (카테고리당)

레벨 3: 배치별
└─> 레벨 2 + 평가 데이터
    캐시: 불가 (매번 변경)
```

### 4.3 ChatGPT 자동 캐싱

```python
from openai import OpenAI

def call_chatgpt_with_caching(politician_id, politician_name, category_name, items):
    """ChatGPT Extended Caching (24시간)"""
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

    system_prompt = SYSTEM_PROMPT
    politician_prompt = get_politician_category_prompt(
        politician_id, politician_name, category_name
    )
    items_text = format_batch_data(items)

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        prompt_cache_retention="24h",  # ✅ 24시간 캐싱
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"{politician_prompt}\n\n데이터:\n{items_text}"}
        ],
        max_tokens=4096,
        temperature=0.7
    )

    return response.choices[0].message.content
```

**절감 효과**:
- Cache Write: 800 × 1.0 = 800 tokens (1회)
- Cache Hit: 800 × 0.1 = 80 tokens (9회)
- 총 캐시 비용: 800 + 80×9 = 1,520 tokens
- 원래 비용: 800 × 10 = 8,000 tokens
- **절감: 81%**

### 4.4 Gemini Explicit 캐싱

```python
from google import genai
from google.genai import types

def create_gemini_cache(politician_id, politician_name, category_name):
    """Gemini 캐시 생성 (카테고리별 1회)"""
    client = genai.Client(api_key=os.getenv('GEMINI_API_KEY'))

    politician_prompt = get_politician_category_prompt(
        politician_id, politician_name, category_name
    )

    cached_content = f"""{SYSTEM_PROMPT}

{politician_prompt}"""

    # 캐시 생성 (2048+ tokens)
    cache = client.caches.create(
        model='gemini-2.0-flash',
        contents=[types.Content(parts=[types.Part(text=cached_content)])],
        ttl='3600s'  # 60분
    )

    return cache.name

def call_gemini_with_cache(cache_name, items):
    """Gemini 캐시 사용"""
    client = genai.Client(api_key=os.getenv('GEMINI_API_KEY'))

    items_text = format_batch_data(items)

    response = client.models.generate_content(
        model='gemini-2.0-flash',
        contents=f"데이터:\n{items_text}",
        cached_content=cache_name  # ✅ 캐시 참조
    )

    return response.text
```

**절감 효과**:
- Cache Write: 800 × 1.0 = 800 tokens (1회)
- Cache Hit: 800 × 0.25 = 200 tokens (9회)
- 총 캐시 비용: 800 + 200×9 = 2,600 tokens
- 원래 비용: 800 × 10 = 8,000 tokens
- **절감: 67.5%**

### 4.5 Grok 자동 캐싱

```python
from openai import OpenAI

def call_grok_with_caching(politician_id, politician_name, category_name, items):
    """Grok 자동 캐싱"""
    client = OpenAI(
        api_key=os.getenv("XAI_API_KEY"),
        base_url="https://api.x.ai/v1"
    )

    system_prompt = SYSTEM_PROMPT
    politician_prompt = get_politician_category_prompt(
        politician_id, politician_name, category_name
    )
    items_text = format_batch_data(items)

    response = client.chat.completions.create(
        model="grok-4-fast",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"{politician_prompt}\n\n데이터:\n{items_text}"}
        ],
        max_tokens=4096,
        temperature=0.7
    )

    # 캐시 사용량 확인
    if hasattr(response.usage, 'cached_prompt_tokens'):
        print(f"  ✅ Cached: {response.usage.cached_prompt_tokens} tokens")

    return response.choices[0].message.content
```

**절감 효과**:
- Cached Input: $0.02/1M (90% 절감)
- 캐시 히트율: 90%+ (파트너 평균)

### 4.6 Claude (Subscription Mode)

**현황**:
- API 미사용 (Claude Code CLI)
- Subscription Mode (무제한)
- 캐싱 적용 불가

**최적화 전략**:
- 50개 배치 적용 (프롬프트 오버헤드 감소)
- 병렬 세션 실행 (카테고리 동시 처리)
- 비용: $0 (subscription)

---

## 5. AI별 프롬프트 차이

### 5.1 공통 프롬프트 관리

```python
# prompts.py (중앙 관리)

SYSTEM_PROMPT = """등급(점수): +4(+8)탁월 | +3(+6)우수 | +2(+4)양호 | +1(+2)보통
           -1(-2)미흡 | -2(-4)부족 | -3(-6)심각 | -4(-8)최악

판단: 긍정(성과/업적)→+4~+1 | 부정(논란/비판)→-1~-4

JSON: {"evaluations":[{"id":"UUID","rating":"+4~-4","rationale":"근거"}]}"""

def get_politician_category_prompt(politician_id, politician_name, category_name):
    """정치인별 카테고리별 프롬프트 (모든 AI 공통)"""
    profile_info = format_politician_profile(politician_id, politician_name)
    cat_kor = CATEGORY_MAP.get(category_name.lower(), category_name)

    return f"""{profile_info}

카테고리: {cat_kor}

아래 데이터를 객관적으로 평가하세요."""

def build_evaluation_prompt(politician_id, politician_name, category_name, items):
    """전체 평가 프롬프트 (4개 AI 공통)"""
    politician_prompt = get_politician_category_prompt(
        politician_id, politician_name, category_name
    )
    items_text = format_batch_data(items)

    return f"""{SYSTEM_PROMPT}

{politician_prompt}

데이터:
{items_text}"""
```

### 5.2 AI별 호출 방법

**ChatGPT (메시지 분리)**:
```python
messages = [
    {"role": "system", "content": SYSTEM_PROMPT},
    {"role": "user", "content": f"{politician_prompt}\n\n데이터:\n{items_text}"}
]
```

**Gemini (단일 프롬프트)**:
```python
full_prompt = build_evaluation_prompt(politician_id, politician_name, category_name, items)
```

**Grok (메시지 분리)**:
```python
messages = [
    {"role": "system", "content": SYSTEM_PROMPT},
    {"role": "user", "content": f"{politician_prompt}\n\n데이터:\n{items_text}"}
]
```

**Claude (단일 프롬프트)**:
```python
full_prompt = build_evaluation_prompt(politician_id, politician_name, category_name, items)
```

### 5.3 공정성 검증

```python
def test_prompt_equality():
    """4개 AI 프롬프트 동일성 검증"""
    politician_id = "62e7b453"
    politician_name = "오세훈"
    category_name = "expertise"
    items = [...]  # 테스트 데이터

    # 각 AI용 프롬프트 생성
    prompt_chatgpt = build_evaluation_prompt(
        politician_id, politician_name, category_name, items
    )
    prompt_gemini = build_evaluation_prompt(
        politician_id, politician_name, category_name, items
    )
    prompt_grok = build_evaluation_prompt(
        politician_id, politician_name, category_name, items
    )
    prompt_claude = build_evaluation_prompt(
        politician_id, politician_name, category_name, items
    )

    # 동일성 검증
    assert prompt_chatgpt == prompt_gemini, "ChatGPT ≠ Gemini"
    assert prompt_gemini == prompt_grok, "Gemini ≠ Grok"
    assert prompt_grok == prompt_claude, "Grok ≠ Claude"

    print("✅ 프롬프트 동일성 검증 통과")
    print(f"  프롬프트 길이: {len(prompt_chatgpt)} 문자")
```

---

## 6. 종합 비용/시간 분석

### 6.1 정치인 1명당 (10 카테고리 × 100개 데이터)

**현재 (10개 배치, 캐싱 없음)**:
```
각 AI당:
- API 호출: 100회
- 입력 토큰: 335,000 tokens
- 출력 토큰: 50,000 tokens

ChatGPT: $0.50
Gemini: $0 (무료)
Grok: $1.00
Claude: $0 (subscription)

총 비용: $1.50
총 시간: 90분
```

**최적화 (50개 배치 + 캐싱)**:
```
각 AI당:
- API 호출: 20회
- 입력 토큰: 267,000 tokens (캐싱 전)
- 캐시 할인: 121,000 tokens 절감
- 실제 비용: 715,000 tokens (4개 AI 합계)

ChatGPT: $0.30 (40% 절감)
Gemini: $0 (무료)
Grok: $0.75 (25% 절감)
Claude: $0 (subscription)

총 비용: $1.05 (30% 절감)
총 시간: 54분 (40% 절감)
```

### 6.2 정치인 100명당

**현재**:
```
비용: $150
시간: 149시간
```

**최적화**:
```
비용: $105 (30% 절감)
시간: 89시간 (40% 절감)
```

---

## 7. 구현 가이드

### 7.1 즉시 적용 가능 (Phase 1)

**작업**:
1. `prompts.py` 생성 (프롬프트 템플릿 중앙화)
2. `evaluate_v40.py` 수정 (ChatGPT Extended Caching)
3. 배치 크기 50개로 변경

**예상 시간**: 1-2시간

**효과**:
- ChatGPT: 40% 비용 절감
- Grok: 25% 비용 절감
- 시간: 40% 단축

### 7.2 단계별 적용

**Step 1: 백업**
```bash
cp evaluate_v40.py evaluate_v40_backup.py
```

**Step 2: prompts.py 생성**
```bash
touch prompts.py
# 위 공통 프롬프트 코드 복사
```

**Step 3: evaluate_v40.py 수정**
```python
from prompts import SYSTEM_PROMPT, get_politician_category_prompt, build_evaluation_prompt

# 배치 크기 변경
batch_size = 50  # 10에서 50으로

# 캐싱 함수 적용
if ai_name == "ChatGPT":
    return call_chatgpt_with_caching(...)
elif ai_name == "Gemini":
    return call_gemini_with_cache(...)
elif ai_name == "Grok":
    return call_grok_with_caching(...)
```

**Step 4: 테스트**
```bash
python evaluate_v40.py \
  --politician_id=62e7b453 \
  --politician_name="오세훈" \
  --category=expertise \
  --ai=ChatGPT
```

**Step 5: 전체 적용**
```bash
python evaluate_v40.py \
  --politician_id=62e7b453 \
  --politician_name="오세훈" \
  --parallel
```

---

## 8. 최종 권장안

### 8.1 AI별 최적화 전략

| AI | 캐싱 방법 | 구현 복잡도 | 절감률 | 권장 사항 |
|----|----------|-----------|--------|---------|
| **Claude** | 불가 | - | 0% | 배치 50개 + 병렬 세션 |
| **ChatGPT** | 자동 + Extended | 낮음 ✅ | **75-81%** | Extended Caching 적용 |
| **Gemini** | Explicit | 중간 | **65-75%** | Explicit Caching 적용 |
| **Grok** | 자동 | 낮음 ✅ | **75%** | 코드 변경 불필요 |

### 8.2 최적화 요약

| 항목 | 현재 | 최적화 | 절감 |
|------|------|--------|------|
| **프롬프트 토큰** | 850 | 420 | 50% |
| **배치 크기** | 10개 | 50개 | 5배 |
| **API 호출** (100명) | 30,000 | 6,000 | 80% |
| **입력 토큰** (100명) | 100.5M | 71.5M | 29% |
| **비용** (100명) | $150 | $105 | 30% |
| **시간** (100명) | 149시간 | 89시간 | 40% |

### 8.3 체크리스트

평가 실행 전 확인:

- [ ] 4개 AI 모두 동일한 `SYSTEM_PROMPT` 사용
- [ ] 4개 AI 모두 동일한 프롬프트 템플릿 사용
- [ ] 배치 크기 50개 적용
- [ ] 캐싱 설정 확인 (ChatGPT, Gemini, Grok)
- [ ] 프롬프트 검증 테스트 통과

---

## 참고 문서

### 공식 문서

- [Prompt caching - Claude API Docs](https://docs.claude.com/en/docs/build-with-claude/prompt-caching)
- [Prompt caching | OpenAI API](https://platform.openai.com/docs/guides/prompt-caching)
- [Context caching | Gemini API](https://ai.google.dev/gemini-api/docs/caching)
- [Consumption and Rate Limits | xAI](https://docs.x.ai/docs/key-information/consumption-and-rate-limits)

### 추가 자료

- [Gemini 2.5 Implicit Caching](https://developers.googleblog.com/en/gemini-2-5-models-now-support-implicit-caching/)
- [Prompt Caching in the API | OpenAI](https://openai.com/index/api-prompt-caching/)
- [ngrok: How prompt caching works](https://ngrok.com/blog/prompt-caching/)

---

**최종 작성일**: 2026-02-02
**버전**: V40
**작성자**: Claude Code
**적용 대상**: V40 평가 시스템 (evaluate_v40.py)

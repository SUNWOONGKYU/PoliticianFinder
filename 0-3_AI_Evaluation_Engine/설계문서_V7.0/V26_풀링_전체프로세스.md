# V26.0 풀링 기반 평가 시스템 전체 프로세스

**작성일**: 2026-01-04
**버전**: V26.0
**상태**: 설계 완료

---

## 개요

이 문서는 V26.0 풀링 방식의 전체 프로세스를 정리합니다.
- 작업자 (메인 에이전트, Python, AI)
- 인스트럭션 (누가 누구에게 무엇을 지시하는가)
- 참조 파일 (어떤 파일을 참고하는가)

---

## 참조 파일 목록

```
설계문서_V7.0/
├── CLAUDE.md                    ← 메인 에이전트 작업 지침
├── README.md                    ← 전체 구조 설명
├── V26_수집지침_및_프로세스.md   ← 수집 규칙 상세
├── V26_멀티AI_구현계획.md       ← 4개 AI 구현 상세
├── V24_점수계산_알고리즘_상세가이드.md ← 점수 계산 공식
├── V24_전체_카테고리_정의_개선_완료.md ← 10개 카테고리 정의
├── 등급체계_10단계_200-1000점_V24.md   ← 등급 기준표
├── 30명_정치인_명단.md          ← 평가 대상 정치인 목록
│
├── instructions/                ← 카테고리별 AI 프롬프트 (10개)
│   ├── category_1_expertise.md      ← 전문성 프롬프트
│   ├── category_2_leadership.md     ← 리더십 프롬프트
│   ├── category_3_vision.md         ← 비전 프롬프트
│   ├── category_4_integrity.md      ← 청렴성 프롬프트
│   ├── category_5_ethics.md         ← 윤리성 프롬프트
│   ├── category_6_accountability.md ← 책임성 프롬프트
│   ├── category_7_transparency.md   ← 투명성 프롬프트
│   ├── category_8_communication.md  ← 소통능력 프롬프트
│   ├── category_9_responsiveness.md ← 대응성 프롬프트
│   ├── category_10_publicinterest.md ← 공익성 프롬프트
│   └── README_V15.0_COMPLETE.md     ← 프롬프트 버전 정보
│
├── 실행스크립트/
│   ├── collect_v26_pool.py      ← 수집 스크립트 (rating 없이) [신규 필요]
│   ├── evaluate_v26_pool.py     ← 평가 스크립트 [신규 필요]
│   ├── calculate_v26_scores.py  ← 점수 계산 스크립트
│   └── ...
│
└── Database/
    └── DB_SCHEMA.md             ← 테이블 스키마
```

---

## 0단계: 프로세스 시작

### 작업자
**메인 에이전트 (Claude Code)**

### 참조 파일
- `설계문서_V7.0/CLAUDE.md` ← 작업 지침
- `설계문서_V7.0/30명_정치인_명단.md` ← 대상 정치인 확인
- `설계문서_V7.0/V26_수집지침_및_프로세스.md` ← 수집 규칙 확인

### 역할
- 전체 프로세스 조율
- Python 스크립트에 인스트럭션 전달
- 진행 상황 모니터링

### 인스트럭션: 메인 에이전트 → Python 스크립트

```bash
# 실행 스크립트: 설계문서_V7.0/실행스크립트/collect_v26_pool.py

python collect_v26_pool.py \
    --politician_id="62e7b453" \
    --politician_name="오세훈"

# 의미: "오세훈에 대해 4개 AI로 수집 시작해라 (rating 없이)"
```

---

## 1단계: 수집 (rating 없이)

### 작업자
**Python 스크립트 (collect_v26_pool.py)** [신규 작성 필요]

### 참조 파일
- `설계문서_V7.0/V26_수집지침_및_프로세스.md`
  - 수집 규칙: OFFICIAL 4년, PUBLIC 1년
  - 수집 구조: OFFICIAL 25개 + PUBLIC 25개 = 50개/AI
  - 부정 주제: 최소 20% (10개)

- `설계문서_V7.0/V26_멀티AI_구현계획.md`
  - AI별 API 설정 (Claude, ChatGPT, Grok, Gemini)
  - 모델명, API 호출 방법

### 역할
- 수집 프롬프트 생성 (카테고리별 instructions 파일 참조)
- 4개 AI API 호출
- JSON 응답 파싱

### 인스트럭션: Python → 수집 AI

**프롬프트 참조 파일**: `설계문서_V7.0/instructions/category_N_*.md`

예시 (전문성 카테고리):
- 참조: `설계문서_V7.0/instructions/category_1_expertise.md`

```
"""
당신은 정치인 평가 데이터 수집 AI입니다.

**대상 정치인**: 오세훈
- 신분: 서울시장
- 정당: 국민의힘

⚠️ V26.0 기간 제한:
- OFFICIAL: 2022-01-04 ~ 2026-01-04 (최근 4년)
- PUBLIC: 2025-01-04 ~ 2026-01-04 (최근 1년)

**카테고리**: 전문성 (Expertise)
[category_1_expertise.md의 정의 및 평가 범위 삽입]

**수집 개수**: 25개 (OFFICIAL) 또는 25개 (PUBLIC)

⚠️ rating 없이 데이터만 수집하세요!

다음 JSON 형식으로 반환:
{
  "items": [
    {
      "item_num": 1,
      "data_title": "제목",
      "data_content": "내용",
      "data_source": "출처",
      "source_url": "URL"
    }
  ]
}
"""
```

### 결과
- Claude: 50개 수집 (rating 없음)
- ChatGPT: 50개 수집 (rating 없음)
- Grok: 50개 수집 (rating 없음)
- Gemini: 50개 수집 (rating 없음)
- **총 200개/카테고리**

---

## 2단계: DB 저장 (rating NULL)

### 작업자
**Python 스크립트 (collect_v26_pool.py)**

### 참조 파일
- `설계문서_V7.0/Database/DB_SCHEMA.md` ← 테이블 구조

### 코드
```python
for item in response['items']:
    supabase.table('collected_data_v26').insert({
        'politician_id': '62e7b453',
        'collected_by': 'Claude',  # 수집한 AI
        'category_name': 'Expertise',
        'data_title': item['data_title'],
        'data_content': item['data_content'],
        'data_source': item['data_source'],
        'source_url': item['source_url'],
        'rating': None  # NULL!
    })
```

### 결과
- DB에 200개 데이터 저장 (rating NULL 상태)

---

## 3단계: 풀 완성 확인

### 인스트럭션: 메인 에이전트 → Python 스크립트

```bash
# 실행 스크립트: 설계문서_V7.0/실행스크립트/evaluate_v26_pool.py [신규]

python evaluate_v26_pool.py \
    --politician_id="62e7b453" \
    --politician_name="오세훈"

# 의미: "풀 확인하고, 완성되었으면 평가 시작해라"
```

### 작업자
**Python 스크립트 (evaluate_v26_pool.py)** [신규 작성 필요]

### 참조 파일
- `설계문서_V7.0/V26_멀티AI_구현계획.md`
  - 풀링 핵심 원칙: 4 AI × 50개 = 200개/카테고리

### 코드
```python
result = supabase.table('collected_data_v26') \
         .select('id', count='exact') \
         .eq('politician_id', '62e7b453') \
         .eq('category_name', 'Expertise') \
         .execute()

if result.count == 200:
    print("✅ 풀 완성! 평가 진행")
else:
    print(f"❌ 풀 미완성: {result.count}/200")
    exit(1)
```

---

## 4단계: 평가 (타이밍 분리 = 객관성 확보)

### 작업자
**Python 스크립트 (evaluate_v26_pool.py)**

### 참조 파일
- `설계문서_V7.0/instructions/category_N_*.md`
  - 등급 체계: A, B, C, D, E, F, G, H (또는 A/B/C/D/-D/-C/-B/-A)
  - 평가 기준 상세

### 코드 (DB에서 풀 조회)
```python
pool_data = supabase.table('collected_data_v26') \
            .select('id, data_title, data_content') \
            .eq('politician_id', '62e7b453') \
            .eq('category_name', 'Expertise') \
            .execute()

# 평가 프롬프트 생성 후 4개 AI 호출
```

### 인스트럭션: Python → 평가 AI

**프롬프트 참조 파일**: `설계문서_V7.0/instructions/category_N_*.md`

```
"""
당신은 정치인 평가 AI입니다.

**대상 정치인**: 오세훈 (서울시장, 국민의힘)
**평가 카테고리**: 전문성 (Expertise)

[category_1_expertise.md의 평가 기준 삽입]

아래 200개 데이터를 각각 평가하세요.

**등급 체계** (8단계):
A(매우우수), B(우수), C(양호), D(보통),
E(미흡), F(부족), G(매우부족), H(심각)

**평가 대상 데이터**:
[
  {"id": 1, "title": "오세훈 예산안 통과", "content": "..."},
  {"id": 2, "title": "서울시 교통정책 발표", "content": "..."},
  ...
  {"id": 200, "title": "...", "content": "..."}
]

다음 JSON 형식으로 반환:
{
  "ratings": [
    {"data_id": 1, "rating": "A", "rationale": "평가 근거"},
    {"data_id": 2, "rating": "B", "rationale": "평가 근거"},
    ...
  ]
}
"""
```

### 핵심: 타이밍 분리 = 객관성

```
수집 시점의 Claude (세션 1) ≠ 평가 시점의 Claude (세션 2)

- 새로운 API 호출 = 새로운 세션
- 이전 수집 기억 없음
- 독립적으로 판단
- 더 객관적!
```

### 결과
- 각 AI가 200개 전체를 평가
- 4 AI × 200개 = 800개 평가

---

## 5단계: 평가 결과 저장

### 작업자
**Python 스크립트 (evaluate_v26_pool.py)**

### 참조 파일
- `설계문서_V7.0/Database/DB_SCHEMA.md`
  - `ai_ratings_v26` 테이블 구조 (신규 필요)

### 코드
```python
for ai_name in ['Claude', 'ChatGPT', 'Grok', 'Gemini']:
    for rating_item in response[ai_name]['ratings']:
        supabase.table('ai_ratings_v26').insert({
            'data_id': rating_item['data_id'],
            'evaluated_by': ai_name,
            'rating': rating_item['rating'],
            'rating_rationale': rating_item['rationale']
        })
```

### 결과
- DB에 800개 평가 결과 저장

---

## 6단계: 점수 계산

### 인스트럭션: 메인 에이전트 → Python 스크립트

```bash
# 실행 스크립트: 설계문서_V7.0/실행스크립트/calculate_v26_scores.py

python calculate_v26_scores.py \
    --politician_id="62e7b453"

# 의미: "평가 결과로 점수 계산해라"
```

### 작업자
**Python 스크립트 (calculate_v26_scores.py)**

**※ AI 호출 없음! Python이 직접 계산**

### 참조 파일
- `설계문서_V7.0/V24_점수계산_알고리즘_상세가이드.md`
  - 알파벳 → 숫자 변환 매핑
  - 점수 계산 공식: (6.0 + avg_rating × 0.5) × 10
  - PRIOR = 6.0, COEFFICIENT = 0.5

- `설계문서_V7.0/V24_전체_카테고리_정의_개선_완료.md`
  - 10개 카테고리 정의

### Step 6-1: 알파벳 → 숫자 변환

```python
ALPHABET_TO_NUMERIC = {
    'A': 8, 'B': 6, 'C': 4, 'D': 2,
    'E': -2, 'F': -4, 'G': -6, 'H': -8
}
```

### Step 6-2: 카테고리별 평균 및 점수 계산

```python
avg_rating = sum(numeric_ratings) / len(numeric_ratings)

PRIOR = 6.0
COEFFICIENT = 0.5
category_score = (PRIOR + avg_rating * COEFFICIENT) * 10

# 예: 전문성 = (6.0 + 3.5 * 0.5) * 10 = 77.5점
```

### Step 6-3: 최종 점수 합산

```python
total_score = sum(category_scores)  # 10개 카테고리 합산
final_score = round(min(total_score, 1000))

# 예: 744점
```

---

## 7단계: 등급 산출

### 작업자
**Python 스크립트 (calculate_v26_scores.py)**

**※ AI 호출 없음! Python이 등급표 적용**

### 참조 파일
- `설계문서_V7.0/등급체계_10단계_200-1000점_V24.md`
  - 등급 기준표 (M, D, E, P, G, S, B, I, L)
  - 점수 범위별 등급

### 코드

```python
def get_grade(score):
    if score >= 925: return "M", "최우수"
    elif score >= 850: return "D", "우수"
    elif score >= 775: return "E", "양호"
    elif score >= 700: return "P", "보통+"
    elif score >= 625: return "G", "보통"
    elif score >= 550: return "S", "보통-"
    elif score >= 475: return "B", "미흡"
    elif score >= 400: return "I", "부족"
    else: return "L", "매우 부족"

grade_code, grade_desc = get_grade(744)  # → ('P', '보통+')
```

---

## 8단계: 결과 저장 및 보고

### 작업자
**Python 스크립트 (calculate_v26_scores.py)**

### 참조 파일
- `설계문서_V7.0/Database/DB_SCHEMA.md`
  - `ai_evaluations_v26` 테이블 구조

### 코드
```python
supabase.table('ai_evaluations_v26').upsert({
    'politician_id': '62e7b453',
    'total_score': 744,
    'grade_code': 'P',
    'ai_count': 4
})

print("✅ 점수 계산 완료: 744점 (P등급)")
```

### 작업자
**메인 에이전트 (Claude Code)**

### 역할
- 실행 결과 확인
- 사용자에게 최종 보고

```
"오세훈 평가 완료:
 - 수집: 200개 (4 AI × 50개)
 - 평가: 800개 (4 AI × 200개)
 - 최종 점수: 744점
 - 최종 등급: P (Platinum) - 보통+"
```

---

## 전체 참조 파일 요약

| 단계 | 참조 파일 | 용도 |
|------|----------|------|
| 0단계 | CLAUDE.md | 메인 에이전트 작업 지침 |
| 0단계 | 30명_정치인_명단.md | 대상 정치인 목록 |
| 0단계 | V26_수집지침_및_프로세스.md | 수집 규칙 확인 |
| 1단계 | V26_수집지침_및_프로세스.md | 기간 제한, 수집 구조 |
| 1단계 | V26_멀티AI_구현계획.md | AI별 API 설정 |
| 1단계 | instructions/category_N_*.md | 카테고리별 수집 프롬프트 |
| 2단계 | Database/DB_SCHEMA.md | 테이블 구조 |
| 3단계 | V26_멀티AI_구현계획.md | 풀링 원칙 (200개) |
| 4단계 | instructions/category_N_*.md | 카테고리별 평가 프롬프트 |
| 5단계 | Database/DB_SCHEMA.md | 테이블 구조 |
| 6단계 | V24_점수계산_알고리즘_상세가이드.md | 점수 계산 공식 |
| 6단계 | V24_전체_카테고리_정의_개선_완료.md | 10개 카테고리 정의 |
| 7단계 | 등급체계_10단계_200-1000점_V24.md | 등급 기준표 |
| 8단계 | Database/DB_SCHEMA.md | 결과 저장 테이블 |

---

## 실행 스크립트 요약

| 스크립트 | 역할 | 상태 |
|---------|------|------|
| collect_v26_pool.py | 수집 (rating 없이) | ✅ **완료** |
| evaluate_v26_pool.py | 평가 (200개 풀 전체) | ✅ **완료** |
| calculate_v26_pool_scores.py | 점수 계산 (풀링 방식) | ✅ **완료** |

### 실행 명령어

```bash
# 1단계: 수집 (rating 없이)
python collect_v26_pool.py --politician_id=62e7b453 --politician_name="오세훈" --ai=all

# 2단계: 평가 (200개 풀 전체)
python evaluate_v26_pool.py --politician_id=62e7b453 --ai=all

# 3단계: 점수 계산
python calculate_v26_pool_scores.py --politician_id=62e7b453
```

### 기존 스크립트 (풀링 아님 - 참고용)
| 스크립트 | 역할 | 상태 |
|---------|------|------|
| collect_v26_claude.py | Claude 수집+평가 동시 | [기존 - 풀링 아님] |
| collect_v26_chatgpt.py | ChatGPT 수집+평가 동시 | [기존 - 풀링 아님] |
| collect_v26_grok.py | Grok 수집+평가 동시 | [기존 - 풀링 아님] |
| collect_v26_gemini.py | Gemini 수집+평가 동시 | [기존 - 풀링 아님] |

---

## DB 테이블 요약

| 테이블 | 역할 | 상태 |
|--------|------|------|
| collected_data_v26 | 수집 데이터 (rating NULL) | [기존] |
| ai_ratings_v26 | 평가 결과 (800개) | ✅ **SQL 완료** |
| ai_evaluations_v26 | 최종 결과 | [기존] |

### ai_ratings_v26 테이블 생성 SQL
**파일 위치**: `Database/create_ai_ratings_v26.sql`

```sql
CREATE TABLE ai_ratings_v26 (
    rating_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    collected_data_id UUID NOT NULL,
    evaluator_ai_name TEXT NOT NULL,  -- 평가한 AI
    politician_id TEXT NOT NULL,
    category_name TEXT NOT NULL,
    rating TEXT NOT NULL CHECK (rating IN ('A','B','C','D','E','F','G','H')),
    rating_rationale TEXT,
    evaluation_date TIMESTAMPTZ DEFAULT NOW(),
    evaluation_version TEXT DEFAULT 'V26.0',
    original_collector_ai TEXT  -- 원래 수집한 AI
);
```

---

## 역할별 최종 정리

### 메인 에이전트 (Claude Code)

**참조**: `CLAUDE.md`

**주는 인스트럭션**:
- `python collect_v26_pool.py --politician_id=... --politician_name=...`
- `python evaluate_v26_pool.py --politician_id=...`
- `python calculate_v26_scores.py --politician_id=...`

**하는 일**:
- 전체 프로세스 조율
- 스크립트 실행 결과 확인
- 오류 대응
- 사용자에게 보고

### Python 스크립트

**참조**:
- V26_수집지침_및_프로세스.md (수집 규칙)
- V26_멀티AI_구현계획.md (AI 설정)
- instructions/category_N_*.md (프롬프트)
- V24_점수계산_알고리즘_상세가이드.md (계산 공식)
- 등급체계_10단계_200-1000점_V24.md (등급표)

**주는 인스트럭션**:
- 수집 AI에게: 수집 프롬프트 (기간 제한, 카테고리, rating 없이!)
- 평가 AI에게: 평가 프롬프트 (200개 데이터, 등급 체계 A~H)

**하는 일**:
- AI API 호출
- JSON 응답 파싱
- DB 저장/조회
- 점수 계산 (AI 없이 직접!)
- 등급 산출 (AI 없이 직접!)

### 4개 AI (Claude, ChatGPT, Grok, Gemini)

**받는 인스트럭션**: `instructions/category_N_*.md` 기반 프롬프트

**하는 일**:
- 1단계: 데이터 수집 (rating 없이)
- 4단계: 데이터 평가 (rating A~H 부여)

**※ 점수 계산/등급 산출은 하지 않음!**

---

## 핵심 포인트

### 1. 수집과 평가 분리 (타이밍 분리)
- 같은 AI도 다른 세션 = 독립 판단 = 객관성

### 2. 사전 저장 (rating NULL)
- 풀 완성 확인 가능
- 중간 실패 복구 용이

### 3. 4개 AI 교차 검증
- 수집: 다양성 확보
- 평가: 편향 상쇄

### 4. 자연 가중치
- 중복 수집된 데이터 = 더 많이 평가됨 = 자동 가중치

---

## 성능 최적화 지침 (필수!)

### 문제점
- 순차 처리 시 4개 AI × 10개 카테고리 = 40개 작업
- 각 카테고리당 200개 평가 = 약 800개 API 호출
- 순차 실행 시 **30-40분 이상 소요**

### 해결책: 병렬 처리 + 배치 최적화

#### 1. 병렬 처리 (--parallel 옵션 필수)
```bash
# ❌ 느림 (순차 실행)
python evaluate_v26_pool.py --politician_id=62e7b453 --ai=all

# ✅ 빠름 (병렬 실행) - 반드시 사용!
python evaluate_v26_pool.py --politician_id=62e7b453 --ai=all --parallel
```

**병렬 처리 효과:**
- 4개 AI 동시 실행 → 약 4배 속도 향상
- 30분 → 약 8분

#### 2. 배치 사이즈 최적화
```python
# 스크립트 내 배치 사이즈 설정
batch_size = 25  # 기본값 10 → 25로 증가 권장

# 효과: API 호출 횟수 감소
# 200개 ÷ 10개 = 20번 API 호출
# 200개 ÷ 25개 = 8번 API 호출
```

#### 3. API 딜레이 조정
```python
# Rate limit 고려하여 적정 딜레이 설정
time.sleep(0.5)  # 기본 1.5초 → 0.5초로 단축 가능
```

### 권장 실행 명령어

```bash
# 1단계: 수집 (병렬)
python collect_v26_pool.py --politician_id=62e7b453 --politician_name="오세훈" --ai=all --parallel

# 2단계: 평가 (병렬) - 반드시 --parallel 사용!
python evaluate_v26_pool.py --politician_id=62e7b453 --ai=all --parallel

# 3단계: 점수 계산
python calculate_v26_pool_scores.py --politician_id=62e7b453
```

### 예상 소요 시간

| 방식 | 수집 | 평가 | 점수계산 | 총계 |
|------|------|------|----------|------|
| 순차 | 20분 | 40분 | 1분 | 61분 |
| **병렬** | **5분** | **10분** | **1분** | **16분** |

### 주의사항
- Rate limit 발생 시 자동 대기 (60초)
- 병렬 실행 시 API 비용은 동일 (호출 횟수 같음)
- 토큰 비용 절감: 배치 사이즈 증가로 context 재사용

---

**최종 업데이트**: 2026-01-04
**버전**: V26.0

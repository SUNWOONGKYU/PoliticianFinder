# -*- coding: utf-8 -*-
"""
AIë³„ ì¹´í…Œê³ ë¦¬ë³„ í‰ê°€ ì ìˆ˜ ì¡°íšŒ
"""
import os
import sys
from supabase import create_client
from dotenv import load_dotenv

# UTF-8 ì¶œë ¥ ì„¤ì •
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

load_dotenv(override=True)
supabase = create_client(os.getenv('SUPABASE_URL'), os.getenv('SUPABASE_SERVICE_ROLE_KEY'))

politician_id = 'f9e00370'
politician_name = 'ê¹€ë¯¼ì„'
ais = ['Claude', 'ChatGPT', 'Gemini', 'Grok']
categories = [
    ('expertise', 'ì „ë¬¸ì„±'),
    ('leadership', 'ë¦¬ë”ì‹­'),
    ('vision', 'ë¹„ì „'),
    ('integrity', 'ì²­ë ´ì„±'),
    ('ethics', 'ìœ¤ë¦¬ì„±'),
    ('accountability', 'ì±…ì„ê°'),
    ('transparency', 'íˆ¬ëª…ì„±'),
    ('communication', 'ì†Œí†µëŠ¥ë ¥'),
    ('responsiveness', 'ëŒ€ì‘ì„±'),
    ('publicinterest', 'ê³µìµì„±')
]

RATING_TO_SCORE = {
    '+4': 8, '+3': 6, '+2': 4, '+1': 2,
    '-1': -2, '-2': -4, '-3': -6, '-4': -8
}

print('='*100)
print(f'AIë³„ ì¹´í…Œê³ ë¦¬ë³„ í‰ê°€ ì ìˆ˜ ë‚´ì—­ - {politician_name}')
print('='*100)
print()

# 1. AI Ã— ì¹´í…Œê³ ë¦¬ í‰ê·  ì ìˆ˜ ë§¤íŠ¸ë¦­ìŠ¤
print('ğŸ“Š AI Ã— ì¹´í…Œê³ ë¦¬ í‰ê·  ì ìˆ˜ ë§¤íŠ¸ë¦­ìŠ¤:')
print('-'*100)
print(f'{"ì¹´í…Œê³ ë¦¬":<20} {"Claude":>10} {"ChatGPT":>10} {"Gemini":>10} {"Grok":>10} {"ì „ì²´í‰ê· ":>10}')
print('-'*100)

category_totals = {}

for cat_eng, cat_kor in categories:
    scores = {}
    cat_sum = 0
    cat_count = 0

    for ai in ais:
        result = supabase.table('evaluations_v30')\
            .select('score')\
            .eq('politician_id', politician_id)\
            .eq('evaluator_ai', ai)\
            .eq('category', cat_eng)\
            .execute()

        if result.data:
            ai_scores = [item['score'] for item in result.data]
            avg_score = sum(ai_scores) / len(ai_scores) if ai_scores else 0
            scores[ai] = avg_score
            cat_sum += sum(ai_scores)
            cat_count += len(ai_scores)
        else:
            scores[ai] = 0

    cat_avg = cat_sum / cat_count if cat_count > 0 else 0
    category_totals[cat_eng] = cat_avg

    cat_label = f"{cat_kor}({cat_eng})"
    print(f'{cat_label:<20} {scores.get("Claude", 0):>10.2f} {scores.get("ChatGPT", 0):>10.2f} {scores.get("Gemini", 0):>10.2f} {scores.get("Grok", 0):>10.2f} {cat_avg:>10.2f}')

print('-'*100)

# 2. AIë³„ ì „ì²´ í‰ê·  ì ìˆ˜
print()
print('ğŸ“Š AIë³„ ì „ì²´ í‰ê·  ì ìˆ˜:')
print('-'*100)
print(f'{"AI":<20} {"í‰ê· ì ìˆ˜":>12} {"í‰ê°€ê°œìˆ˜":>10} {"ìµœê³ ì ":>10} {"ìµœì €ì ":>10}')
print('-'*100)

ai_totals = {}
for ai in ais:
    result = supabase.table('evaluations_v30')\
        .select('score')\
        .eq('politician_id', politician_id)\
        .eq('evaluator_ai', ai)\
        .execute()

    if result.data:
        scores = [item['score'] for item in result.data]
        avg_score = sum(scores) / len(scores) if scores else 0
        max_score = max(scores) if scores else 0
        min_score = min(scores) if scores else 0
        ai_totals[ai] = avg_score
        print(f'{ai:<20} {avg_score:>12.2f} {len(scores):>10}ê°œ {max_score:>10} {min_score:>10}')
    else:
        ai_totals[ai] = 0
        print(f'{ai:<20} {0:>12.2f} {0:>10}ê°œ {0:>10} {0:>10}')

print('-'*100)

# 3. ì „ì²´ í‰ê· 
all_result = supabase.table('evaluations_v30')\
    .select('score')\
    .eq('politician_id', politician_id)\
    .execute()

if all_result.data:
    all_scores = [item['score'] for item in all_result.data]
    overall_avg = sum(all_scores) / len(all_scores)
    overall_max = max(all_scores)
    overall_min = min(all_scores)
    print(f'{"ì „ì²´ í‰ê· ":<20} {overall_avg:>12.2f} {len(all_scores):>10}ê°œ {overall_max:>10} {overall_min:>10}')

print('='*100)

# 4. ë“±ê¸‰ ë¶„í¬
print()
print('ğŸ“Š ë“±ê¸‰ ë¶„í¬ (ëª¨ë“  AI í†µí•©):')
print('-'*100)
print(f'{"ë“±ê¸‰":<10} {"ê°œìˆ˜":>10} {"ë¹„ìœ¨":>10} {"ì ìˆ˜":>10}')
print('-'*100)

rating_result = supabase.table('evaluations_v30')\
    .select('rating')\
    .eq('politician_id', politician_id)\
    .execute()

if rating_result.data:
    ratings = [item['rating'] for item in rating_result.data]
    total = len(ratings)

    rating_counts = {}
    for rating in ['+4', '+3', '+2', '+1', '-1', '-2', '-3', '-4']:
        count = ratings.count(rating)
        rating_counts[rating] = count
        pct = (count / total * 100) if total > 0 else 0
        score = RATING_TO_SCORE.get(rating, 0)
        print(f'{rating:<10} {count:>10} {pct:>9.1f}% {score:>10}')

print('-'*100)

# 5. ì¹´í…Œê³ ë¦¬ë³„ ìµœê³ /ìµœì € ì ìˆ˜
print()
print('ğŸ“Š ì¹´í…Œê³ ë¦¬ë³„ ìµœê³ /ìµœì € AI:')
print('-'*100)
print(f'{"ì¹´í…Œê³ ë¦¬":<20} {"ìµœê³ AI":>15} {"ì ìˆ˜":>8} {"ìµœì €AI":>15} {"ì ìˆ˜":>8}')
print('-'*100)

for cat_eng, cat_kor in categories:
    ai_scores = {}

    for ai in ais:
        result = supabase.table('evaluations_v30')\
            .select('score')\
            .eq('politician_id', politician_id)\
            .eq('evaluator_ai', ai)\
            .eq('category', cat_eng)\
            .execute()

        if result.data:
            scores = [item['score'] for item in result.data]
            avg = sum(scores) / len(scores) if scores else 0
            ai_scores[ai] = avg

    if ai_scores:
        max_ai = max(ai_scores, key=ai_scores.get)
        min_ai = min(ai_scores, key=ai_scores.get)
        cat_label = f"{cat_kor}({cat_eng})"
        print(f'{cat_label:<20} {max_ai:>15} {ai_scores[max_ai]:>8.2f} {min_ai:>15} {ai_scores[min_ai]:>8.2f}')

print('='*100)

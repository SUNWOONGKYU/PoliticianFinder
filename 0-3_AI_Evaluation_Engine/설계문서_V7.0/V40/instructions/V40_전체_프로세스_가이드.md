# V40 전체 프로세스 가이드

**작성일**: 2026-02-01
**최종 업데이트**: 2026-02-12 (평가 최적화 완료)
**버전**: V40
**목적**: 정치인 정보 준비부터 상세평가보고서 생성까지 완전한 프로세스

**📌 주요 변경사항 (2026-02-12)**:
- ChatGPT 모델 변경: gpt-5-nano → gpt-5.1-codex-mini
- 배치 평가 최적화: Gemini, ChatGPT 25개씩 처리 (10x 향상)
- Pre-filtering 추가: 이미 평가된 데이터 자동 제외 (5x 향상)
- 자동 재시도: ChatGPT Foreign key 오류 대응
- 공통 저장 함수: common_eval_saver.py 통합

---

## 1. V40 개요

### 핵심 변경사항

| 항목 | V40 |
|------|-----|
| 수집 채널 | **2개 (Gemini, Naver)** |
| 평가 AI | **4개 (Claude, Codex/ChatGPT, Gemini, Grok)** |
| 수집 방식 | **웹검색 필수** |
| 수집 개수 | **100개/카테고리 (버퍼 20% 포함 최대 120개)** |
| 데이터 유형 | **OFFICIAL/PUBLIC 분리** |
| 평가 방식 | **풀링 평가** |

### 수집 배분

```
Gemini  50% = OFFICIAL 30개 (30%) + PUBLIC 20개 (20%)
Naver   50% = OFFICIAL 10개 (10%) + PUBLIC 40개 (40%)
─────────────────────────────────────────
합계   100% = 100개/카테고리 (버퍼 20% 포함 최대 120개)

📌 OFFICIAL vs PUBLIC:
- OFFICIAL (40개): 객관적 사실
  Gemini 30개 (30%) + Naver 10개 (10%)

- PUBLIC (60개): 의견/평가
  Gemini 20개 (20%) + Naver 40개 (40%)

⚠️ Claude/Codex/Grok = 수집 제외 → 평가만 담당
```

### AI별 수집/평가 역할

| AI | 수집 | 평가 | 비고 |
|---|---|---|---|
| **Gemini** | ✅ 50% | ✅ | Google Search **무료** ✅ |
| **Naver** | ✅ 50% | ❌ | Naver Search **무료** ✅ |
| **Claude** | ❌ | ✅ | **$0** (CLI Direct) |
| **Codex/ChatGPT** | ❌ | ✅ | **$0** (CLI Direct) |
| **Grok** | ❌ | ✅ | 평가만 (API) |

---

## 2. 사전 준비

### 2.1 API 키 설정

`.env` 파일에 다음 키 설정:

```bash
# 수집용 (1개 API + 1개 Direct Subprocess)
# ⚠️ Gemini는 CLI Direct Subprocess 사용 (API 키 불필요)
NAVER_CLIENT_ID=...              # Naver (50% 수집) - 무료
NAVER_CLIENT_SECRET=...          # Naver (50% 수집) - 무료

# 평가용 (1개 API + 3개 CLI Direct)
# ⚠️ Claude, Codex, Gemini는 CLI Direct 사용 (API 키 불필요)
OPENAI_API_KEY=sk-...            # Codex (ChatGPT CLI, 평가만) - 선택적
XAI_API_KEY=xai-...              # Grok (평가만, API)

# Supabase
SUPABASE_URL=https://...
SUPABASE_SERVICE_ROLE_KEY=eyJ...
```

> **참고**: Gemini는 수집/평가 모두 **Gemini CLI Subprocess** 방식으로 실행합니다.
> - **정의**: Python `subprocess.run()`으로 Gemini CLI를 직접 실행
> - **수집**: `scripts/workflow/collect_gemini_subprocess_parallel.py` 사용
> - **평가**: `scripts/workflow/evaluate_gemini_subprocess.py` 사용
> - **상세 내용**: `TERMINOLOGY.md` 참조

### 2.2 데이터베이스 테이블 생성

```sql
-- V40 수집 데이터 테이블
CREATE TABLE IF NOT EXISTS collected_data_v40 (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    politician_id TEXT NOT NULL,
    politician_name TEXT NOT NULL,
    category TEXT NOT NULL,
    data_type TEXT NOT NULL,           -- 'official' or 'public'
    collector_ai TEXT NOT NULL,        -- 'Gemini', 'Naver'
    title TEXT NOT NULL,
    content TEXT NOT NULL,
    source_url TEXT NOT NULL,
    source_name TEXT,
    published_date DATE,
    sentiment TEXT,                    -- 'positive', 'negative', 'free'
    is_verified BOOLEAN DEFAULT FALSE,
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- V40 평가 테이블
CREATE TABLE IF NOT EXISTS evaluations_v40 (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    politician_id TEXT NOT NULL,
    politician_name TEXT NOT NULL,
    category TEXT NOT NULL,
    collected_data_id UUID NOT NULL,
    evaluator_ai TEXT NOT NULL,        -- 'Claude', 'ChatGPT', 'Gemini', 'Grok'
    rating TEXT NOT NULL,              -- '+4' ~ '-4'
    score INTEGER,                     -- -8 ~ +8 (NULL 허용: calculate_v40_scores.py에서 별도 계산)
    reasoning TEXT,
    evaluated_at TIMESTAMPTZ DEFAULT NOW()
);

-- V40 카테고리 점수 테이블
CREATE TABLE IF NOT EXISTS ai_category_scores_v40 (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    politician_id TEXT NOT NULL,
    politician_name TEXT NOT NULL,
    category TEXT NOT NULL,
    score INTEGER NOT NULL,
    ai_details JSONB,
    calculated_at TIMESTAMPTZ DEFAULT NOW()
);

-- V40 최종 점수 테이블
CREATE TABLE IF NOT EXISTS ai_final_scores_v40 (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    politician_id TEXT NOT NULL,
    politician_name TEXT NOT NULL,
    final_score INTEGER NOT NULL,
    grade TEXT NOT NULL,
    category_scores JSONB,
    calculated_at TIMESTAMPTZ DEFAULT NOW(),
    version TEXT DEFAULT 'V40'
);

-- 인덱스
CREATE INDEX IF NOT EXISTS idx_v40_collected_politician ON collected_data_v40(politician_id);
CREATE INDEX IF NOT EXISTS idx_v40_collected_category ON collected_data_v40(category);
CREATE INDEX IF NOT EXISTS idx_v40_eval_politician ON evaluations_v40(politician_id);
```

### 2.3 의존성 설치

```bash
pip install anthropic openai google-generativeai supabase python-dotenv json-repair
```

---

## 3. Phase 0: 정치인 정보 등록 (필수 선행 단계)

### ⚠️ 왜 Phase 0이 중요한가?

**Phase 0을 건너뛰면 모든 수집이 실패합니다!**

정치인 정보는:
- 수집 시 검색어, 필터링 기준으로 사용
- 평가 시 컨텍스트로 활용
- 보고서 생성 시 프로필 정보 제공

### 절차

1. **템플릿 복사**
   ```bash
   cp instructions/1_politicians/_TEMPLATE.md instructions/1_politicians/{정치인명}.md
   ```

2. **정치인 정보 작성** (11개 필드)
   - politician_id: UUID 앞 8자리 (예: `8c5dcc89`)
   - 성명, 정당, 직책, 출마신분, 출마직종
   - 지역, 지역구, 성별, 생년월일, 나이

3. **저장 위치**
   ```
   instructions/1_politicians/{정치인명}.md
   ```

**예시**: `instructions/1_politicians/박주민.md`, `instructions/1_politicians/조은희.md`

**상세 가이드**: `V40_오케스트레이션_가이드.md` Step 0 참조

---

## 4. 전체 프로세스 (7단계)

### 📊 프로세스 개요

```
정치인 정보 작성 (MD) → DB 등록 → 데이터 수집 (1,000개)
→ 검증 → 검증 후 조정 (균형 맞추기) → AI 평가 (4,000개) → 평가 검증 → 점수 계산 → 보고서 생성
```

### 상세 프로세스

```
┌─────────────────────────────────────────────────────────────┐
│ [Phase 1] 준비 - 정치인 정보 작성 및 DB 등록                │
│                                                             │
│ 1. instructions/1_politicians/{정치인명}.md 작성            │
│    - 이름, 생년월일, 직위, 정당, 학력, 경력 등              │
│                                                             │
│ 2. politicians 테이블에 INSERT (12개 필수 필드)              │
│    - id (TEXT, 8자리 hex), name, party, position            │
│    - previous_position, identity, title                     │
│    - region, district, gender, birth_date (YYYY-MM-DD)     │
│    - career[] (최소 5개 경력, 빈 배열 금지)                  │
│                                                             │
│    예시: 박주민                                              │
│    INSERT INTO politicians (                                 │
│      id, name, party, position, previous_position,          │
│      identity, title, region, district, gender,             │
│      birth_date, career                                     │
│    ) VALUES (                                               │
│      '8c5dcc89', '박주민', '더불어민주당',                   │
│      '국회의원 (3선)', '참여연대 사법감시센터 실행위원',     │
│      '출마예정자', '광역단체장',                             │
│      '서울', '서울 은평구 갑', '남', '1973-11-21',          │
│      ARRAY['제20-22대 국회의원 (은평구 갑)', ...]            │
│    );                                                       │
│                     ↓                                       │
├─────────────────────────────────────────────────────────────┤
│ [Phase 1] 수집 - Gemini CLI + Naver API (2개 채널)          │
│                                                             │
│ ⭐ 권장 목표: 버퍼 포함 (60개/AI/카테고리) ⭐               │
│                                                             │
│ Gemini 60개 ──┬── OFFICIAL 36개 (Google Search 무료)       │
│               └── PUBLIC 24개 (Google Search 기반)         │
│                                                             │
│ Naver 60개  ──┬── OFFICIAL 12개 (Naver Search 무료)        │
│               └── PUBLIC 48개 (Naver Search 기반)          │
│                                                             │
│ 합계: 120개/카테고리 (검증 삭제 대비 버퍼 20%)              │
│                                                             │
│ ⚠️ 최소 목표 50개로 수집 시 → Phase 3-3 재수집 필요!       │
│ ✅ 버퍼 목표 60개로 수집 시 → Phase 3-3 스킵 가능! (2-3시간 절약) │
│                                                             │
│ ⚠️ Claude/ChatGPT/Grok = 수집 제외 (평가만)               │
│                     ↓                                       │
│            collected_data_v40 저장                          │
├─────────────────────────────────────────────────────────────┤
│ [Phase 3] 검증 & 재수집 - validate_v40_fixed.py             │
│                                                             │
│ 실행 명령어:                                                 │
│ python validate_v40_fixed.py \                              │
│   --politician_id={ID} --politician_name="{NAME}" \         │
│   --no-dry-run  # 실제 삭제 수행                            │
│                                                             │
│ 검증 항목:                                                  │
│ ✓ URL 실제 존재 여부 (HEAD/GET 요청)                       │
│ ✓ data_type 규칙 (OFFICIAL/PUBLIC 도메인 매칭)             │
│ ✓ 필수 필드 검증 (title, content, source_url)              │
│ ✓ 기간 제한 검증 (공식 4년, 공개 2년)                      │
│ ✓ 가짜 URL 패턴 탐지                                       │
│ ✓ Sentiment 비율 검증                                      │
│   - OFFICIAL: negative ≥10%, positive ≥10%                 │
│   - PUBLIC: negative ≥20%, positive ≥20%                   │
│                     ↓                                       │
│ 검증 실패 → 삭제 → 해당 AI로 재수집 (최대 5회 반복)        │
├─────────────────────────────────────────────────────────────┤
│ [Phase 3-2] 풀링 & 고급 중복 제거 ✨                        │
│                                                             │
│ 2개 채널 수집 데이터 통합                                   │
│                                                             │
│ 🔥 고급 중복 검사 (URL + 제목):                             │
│ 1. URL 정규화 (파라미터, 앵커 제거)                         │
│    - https://namu.wiki/w/XX?rev=456 → https://namu.wiki/w/XX│
│    - https://news.com/art#s-1 → https://news.com/art        │
│                                                             │
│ 2. 제목 정규화 (공백, 특수문자 제거)                        │
│    - "김민석/비판 및 논란" → "김민석비판및논란"             │
│                                                             │
│ 3. 중복 판단 기준:                                          │
│    - 같은 AI + (같은 URL OR 제목 95% 유사) → 중복 제거     │
│    - 다른 AI + 같은 URL/제목 → 모두 유지 (자연 가중치)     │
├─────────────────────────────────────────────────────────────┤
│ [Phase 3-3] 검증 후 조정 ⚖️ ✨ NEW!                        │
│                                                             │
│ 검증 완료 후 AI별/카테고리별 데이터 균형 조정               │
│                                                             │
│ 📊 목표 균형:                                               │
│ - AI별: 50-60개/카테고리 (최소 50, 버퍼 60)                 │
│ - 전체: 500-600개/AI (최소 500, 버퍼 600)                   │
│                                                             │
│ 🔄 조정 프로세스:                                            │
│ 1. 현황 분석: AI별/카테고리별 개수 체크                      │
│ 2. 초과 처리: 60개 초과 카테고리 → 시간순 삭제 (오래된 것)  │
│ 3. 부족 처리: 50개 미만 카테고리 → 해당 AI로 재수집         │
│ 4. 균형 검증: 모든 카테고리 50-60개 달성 확인               │
│ 5. 최종 보고: 조정 결과 요약                                │
│                                                             │
│ ⚠️ 무한루프 방지: 최대 4회 조정 라운드                      │
│                                                             │
│ 🚫 재수집 포기 규칙 (4회 재수집 후):                        │
│ - 50+개: 정상 평가                                          │
│ - 25-49개: 부족 허용, 보유 데이터로 평가                    │
│ - <25개: 포기, leverage score 0 처리 (60점)                 │
│                                                             │
│ 📖 상세 가이드: instructions/V40_검증후조정_가이드.md       │
├─────────────────────────────────────────────────────────────┤
│ [Phase 4] 평가 - evaluate_v40.py (4개 AI)                   │
│                                                             │
│ Claude     ──┬── 풀링된 전체 데이터 평가                   │
│ ChatGPT    ──┤  (CLI Direct: API 비용 $0)                 │
│ Gemini     ──┤                                             │
│ Grok       ──┘                                             │
│                     ↓                                       │
│            evaluations_v40 저장                             │
│            (collected_data_id로 수집 데이터와 연결)         │
├─────────────────────────────────────────────────────────────┤
│ [Phase 5] 평가 검증 - 자동 처리                             │
│                                                             │
│ 평가 완성도 확인:                                            │
│ ✓ 기준: 95% 이상                                            │
│ ✓ 계산: (실제 평가 수 / 기대 평가 수) × 100                 │
│   기대 평가 수 = 수집 풀 총수 × 4 (AI 수)                   │
│   예) 풀 1,000개 → 기대 4,000개 → 95% = 3,800개 이상       │
│      또는: 최소 950개 데이터 평가 완료 (1,000 × 95%)       │
│ ✓ 미달 시: 누락 평가 재실행 (자동)                          │
│                     ↓                                       │
├─────────────────────────────────────────────────────────────┤
│ [Phase 6] 점수 계산 - calculate_v40_scores.py               │
│                                                             │
│ 4개 AI 평가 결과 종합 → 카테고리 점수 → 최종 점수          │
│                     ↓                                       │
│   ai_category_scores_v40, ai_final_scores_v40 저장         │
│   (AI별 점수 JSONB 저장)                                    │
├─────────────────────────────────────────────────────────────┤
│ [Phase 7] 보고서 생성 - generate_report_v40.py              │
│                                                             │
│ 1. 4개 테이블 조인 (politicians + collected_data_v40 +      │
│    evaluations_v40 + ai_final_scores_v40)                   │
│                                                             │
│ 2. AI별 통계 계산                                            │
│    - AI별 평균 등급, X 비율, 긍정/부정 비율                 │
│    - AI별 평가 성향 분석                                     │
│                                                             │
│ 3. 카테고리별 분석 (10개)                                    │
│    - AI별 점수 비교                                          │
│    - 대표 긍정/부정 평가 사례                                │
│                                                             │
│ 4. 마크다운 보고서 생성                                      │
│    - 종합 개요 (최종 점수, AI별 점수, 카테고리 점수)        │
│    - AI별 비교 분석                                          │
│    - 카테고리별 상세 평가                                    │
│    - 데이터 출처 분석                                        │
│                     ↓                                       │
│ 5. 파일 저장                                                 │
│    보고서/{정치인명}_{YYYYMMDD}.md                          │
└─────────────────────────────────────────────────────────────┘
```

---

## 3.1 Phase 1 상세: 정치인 정보 등록

### 3.1.1 정치인 정보 파일 작성

**위치**: `instructions/1_politicians/{정치인명}.md`

**필수 포함 정보** (11개 필드):
1. **id** (politician_id): 8자리 hex (TEXT)
2. **name**: 정치인 성명
3. **party**: 소속 정당
4. **position**: 현재 직책
5. **identity**: 출마 신분 (현직/후보자/예비후보자/출마예정자/출마자)
6. **title**: 출마 직종 (국회의원/광역단체장/광역의원/기초단체장/기초의원/교육감)
7. **region**: 출마 지역
8. **district**: 지역구 (해당 시)
9. **gender**: 성별 ('남' 또는 '여')
10. **birth_date**: 생년월일 (TEXT, YYYY-MM-DD 형식)
11. **previous_position**: 이전 직책 (TEXT, NULL 금지)
12. **career**: 경력 배열 (ARRAY, 최소 5개 이상)

**템플릿 예시**:
```markdown
# 정치인 정보 - {정치인명}

---

## 기본 정보

| 필드 | 값 |
|------|-----|
| **politician_id** | {8자리 hex} |
| **성명** | {이름} |
| **현 직책** | {직책} |
| **소속 정당** | {정당} |
| **출마 신분** | {신분} |
| **출마 직종** | {직종} |
| **지역** | {지역} |
| **지역구** | {지역구} |
| **성별** | {성별} |
| **생년월일** | {생년월일} ({나이}세) |

---

## 특별 지시사항

### 수집 시 주의점
- (정치인 배경, 이력 등)

### 평가 시 주의점
- (특별히 주목할 분야)

### 알려진 논란/이슈
- (논란 사항)

### 알려진 성과
- (주요 성과)

---

## 출처 힌트

### OFFICIAL 출처
- 국회, 정당 공식 사이트 등

### PUBLIC 출처
- 나무위키, 위키백과, 뉴스 등
```

**실제 예시: 박주민**
```markdown
# 정치인 정보 - 박주민

---

## 기본 정보

| 필드 | 값 |
|------|-----|
| **politician_id** | 8c5dcc89 |
| **성명** | 박주민 |
| **현 직책** | 국회의원 (3선) |
| **소속 정당** | 더불어민주당 |
| **출마 신분** | 출마예정자 |
| **출마 직종** | 광역단체장 |
| **지역** | 서울 |
| **지역구** | 서울 은평구 갑 |
| **성별** | 남 |
| **생년월일** | 1973년 11월 21일 (52세) |
```

### 3.1.2 데이터베이스 등록

**테이블**: `politicians` (공통 정치인 테이블)

⚠️ **중요**: `politicians_v40` 테이블은 사용하지 않습니다. 반드시 `politicians` 테이블을 사용하세요.

**12개 필수 필드** (NULL/빈값 금지):
- `id` (TEXT, 8자리 hex, 예: 8c5dcc89)
- `name` (이름)
- `party` (정당)
- `position` (현 직책)
- `previous_position` (전 직책 - 반드시 입력, NULL 금지)
- `region` (지역)
- `district` (지역구)
- `birth_date` (YYYY-MM-DD 형식)
- `gender` (남/여)
- `identity` (출마신분)
- `title` (출마직종)
- `career[]` (경력 배열, 최소 5개 이상 - 빈 배열 금지)

**Python 예시 (Supabase)**:
```python
from supabase import create_client, Client
import os

SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_SERVICE_ROLE_KEY")
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

# 박주민 예시
politician_data = {
    "id": "8c5dcc89",
    "name": "박주민",
    "party": "더불어민주당",
    "position": "국회의원 (3선)",
    "previous_position": "국회의원 (2선)",
    "identity": "출마예정자",
    "title": "광역단체장",
    "region": "서울",
    "district": "서울 은평구 갑",
    "gender": "남",
    "birth_date": "1973-11-21",
    "career": ["국회의원 (21대)", "국회의원 (20대)", ...]
}

response = supabase.table('politicians').insert(politician_data).execute()
print(f"✅ 정치인 등록 완료: {politician_data['name']}")
```

**검증 체크리스트**:
- [ ] politician_id가 8자리 hex인가? (예: 8c5dcc89)
- [ ] 모든 12개 필드가 채워져 있는가?
- [ ] previous_position이 NULL이 아닌가?
- [ ] gender가 '남' 또는 '여'인가?
- [ ] birth_date가 'YYYY-MM-DD' 형식인가?
- [ ] career 배열에 최소 5개 이상 경력이 있는가?
- [ ] identity 값이 정의된 값 중 하나인가?
- [ ] title 값이 정의된 값 중 하나인가?
- [ ] DB에 성공적으로 INSERT 되었는가?

**등록 확인**:
```sql
SELECT * FROM politicians WHERE id = '8c5dcc89';
```

---

## 3.2 Phase 3-3 상세: 검증 후 조정

### 3.2.1 Phase 3-3의 필요성

**Phase 3 (검증 & 재수집) 완료 후 발생 가능한 문제:**
- AI별 수집량 불균형 (예: Gemini 706개 vs Naver 488개)
- 카테고리별 편차 (예: publicinterest 198개 vs integrity 69개)
- 버퍼 목표(60개) 초과 또는 최소 목표(50개) 미달

**Phase 3-3의 역할:**
Phase 3 검증이 끝난 후, 데이터 균형을 맞추는 **최종 조정 단계**

### 3.2.2 조정 목표

**AI별 균형:**
- 최소: 500개/AI (50개/카테고리 × 10개)
- 버퍼: 600개/AI (60개/카테고리 × 10개)

**카테고리별 균형:**
- 최소: 50개/AI/카테고리
- 버퍼: 60개/AI/카테고리

**전체 균형:**
- 최소: 1,000개 (500×2 AI)
- 버퍼: 1,200개 (600×2 AI)

### 3.2.3 조정 프로세스 (5단계)

```
1️⃣ 현황 분석
   - AI별/카테고리별 데이터 개수 집계
   - 초과/부족 카테고리 식별

2️⃣ 초과 처리 (Trim Overflow)
   - 60개 초과 카테고리 식별
   - 오래된 데이터부터 삭제 (published_date 오름차순)
   - 목표: 정확히 60개까지만 유지

3️⃣ 재수집 트리거 (Recollection)
   - 50개 미만 카테고리 식별
   - 해당 AI의 수집 스크립트 자동 실행
   - 목표: 60개 달성 (버퍼 포함)

4️⃣ 균형 검증 (Balance Validation)
   - 모든 카테고리 50-60개 범위 확인
   - AI별 합계 500-600개 확인
   - 전체 합계 1,000-1,200개 확인

5️⃣ 최종 보고
   - 조정 전후 비교
   - 삭제/추가 내역
   - Phase 4 진행 가능 여부 확인
```

### 3.2.4 실행 방법

**스크립트 위치**: `scripts/core/adjust_v40_data.py` ✅ (운영 중)

**실행 명령**:

```bash
cd scripts/core

# 시뮬레이션 (DRY RUN)
python adjust_v40_data.py \
  --politician_id={POLITICIAN_ID} \
  --politician_name="{POLITICIAN_NAME}" \
  --dry-run

# 실제 조정 실행
python adjust_v40_data.py \
  --politician_id={POLITICIAN_ID} \
  --politician_name="{POLITICIAN_NAME}" \
  --no-dry-run

# 특정 AI만 조정
python adjust_v40_data.py \
  --politician_id={POLITICIAN_ID} \
  --politician_name="{POLITICIAN_NAME}" \
  --ai=Gemini \
  --no-dry-run
```

### 3.2.5 삭제 우선순위

**기본 전략: 시간 기반 (Time-based)** ⭐ 권장

```sql
-- 오래된 데이터부터 삭제 (FIFO)
ORDER BY published_date ASC, created_at ASC
```

**장점:**
- ✅ 공정함 (먼저 수집된 것부터 삭제)
- ✅ 구현 간단
- ✅ 예측 가능
- ✅ 최신 데이터 우선 유지

**대안 전략: 품질 기반 (Quality-based)** (선택적)

```sql
-- 낮은 품질 데이터부터 삭제
-- 예: content 길이가 짧은 것, X 평가가 많은 것
ORDER BY LENGTH(content) ASC
```

### 3.2.6 재수집 목표

**목표 개수: 60개 (버퍼 포함)**

이유:
- 최소 목표(50개) 이상 확보
- 다음 검증 과정에서 일부 손실 대비
- 안정적인 평가 데이터 확보

**재수집 스크립트:**
- Gemini: `scripts/workflow/collect_gemini_subprocess.py --politician "{이름}" --category {카테고리}`
- Naver: `scripts/workflow/collect_naver_v40_final.py --politician-id {id} --politician-name "{이름}" --category {카테고리}`

### 3.2.7 무한루프 방지

**최대 조정 라운드: 4회 (포기 규칙 적용)**

```python
MAX_ADJUSTMENT_ROUNDS = 4
GIVE_UP_THRESHOLD = 25  # 50% of MIN, 이하면 포기

for round in range(1, MAX_ADJUSTMENT_ROUNDS + 1):
    # 조정 수행
    if all_balanced():
        break

    if round == MAX_ADJUSTMENT_ROUNDS:
        # 경고 출력 후 중단
        print("⚠️ 최대 조정 횟수 도달")
        break
```

### 3.2.8 상세 가이드

**📖 전체 가이드 문서**: `instructions/V40_검증후조정_가이드.md`

포함 내용:
- 조정 프로세스 상세 설명
- 실행 방법 및 옵션
- 삭제 전략 비교
- 재수집 절차
- 에러 처리 방법
- FAQ 및 체크리스트

---

## 4. 실행 방법

### 4.1 수집

#### 방법 1: 개별 스크립트 실행 (권장)

**Gemini CLI 수집**:
```bash
cd scripts/workflow
python collect_gemini_subprocess.py \
  --politician_id={POLITICIAN_ID} \
  --politician_name="{POLITICIAN_NAME}"
```

**Naver API 수집**:
```bash
cd scripts/workflow
python collect_naver_v40_final.py \
  --politician_id={POLITICIAN_ID} \
  --politician_name="{POLITICIAN_NAME}"
```

**예시: 박주민**
```bash
# Gemini 수집
cd scripts/workflow
python collect_gemini_subprocess.py \
  --politician_id=8c5dcc89 \
  --politician_name="박주민"

# Naver 수집 (⚠️ 하이픈 사용: --politician-id, --politician-name, --category 문자열)
python collect_naver_v40_final.py \
  --politician-id 8c5dcc89 \
  --politician-name "박주민" \
  --category expertise
```

#### 방법 2: 전체 카테고리 순차 수집

```bash
# Gemini 전체 카테고리 병렬 수집 (권장)
python scripts/workflow/collect_gemini_subprocess_parallel.py \
  --politician "{POLITICIAN_NAME}" --period 2

# Naver 전체 카테고리 순차 수집
CATEGORIES="expertise leadership vision integrity ethics accountability transparency communication responsiveness publicinterest"
for cat in $CATEGORIES; do
  python scripts/workflow/collect_naver_v40_final.py \
    --politician-id {POLITICIAN_ID} \
    --politician-name "{POLITICIAN_NAME}" \
    --category $cat
done
```

### 4.2 검증 (validate_v40_fixed.py)

**스크립트 위치**: `scripts/core/validate_v40_fixed.py`

**실행 방법**:

```bash
# 위치 이동
cd scripts/core

# ⚠️ 실제 실행 (무효 데이터 삭제 수행)
python validate_v40_fixed.py \
  --politician_id={POLITICIAN_ID} \
  --politician_name="{POLITICIAN_NAME}" \
  --no-dry-run

# 시뮬레이션만 (삭제 안 함, 검증만)
python validate_v40_fixed.py \
  --politician_id={POLITICIAN_ID} \
  --politician_name="{POLITICIAN_NAME}"
```

**예시: 박주민 검증**

```bash
cd scripts/core

# 실제 실행
python validate_v40_fixed.py \
  --politician_id=8c5dcc89 \
  --politician_name="박주민" \
  --no-dry-run

# 시뮬레이션
python validate_v40_fixed.py \
  --politician_id=8c5dcc89 \
  --politician_name="박주민"
```

**검증 항목**:
- ✓ URL 실제 존재 여부 (HEAD/GET 요청)
- ✓ data_type 규칙 (OFFICIAL/PUBLIC 도메인 매칭)
- ✓ 필수 필드 검증 (title, content, source_url)
- ✓ 기간 제한 검증 (OFFICIAL 4년, PUBLIC 2년)
- ✓ 가짜 URL 패턴 탐지
- ✓ 중복 데이터 검사

**검증 결과**:
- 유효 데이터: DB에 유지
- 무효 데이터: `--no-dry-run` 시 자동 삭제
- 삭제된 만큼 해당 AI로 자동 재수집 (최대 5회 반복)

**⚠️ 중요**:
- `--no-dry-run` 플래그 없이 실행하면 **시뮬레이션만** (실제 삭제 안 됨)
- 실제 삭제를 원하면 **반드시 `--no-dry-run` 플래그 포함**

### 4.3 평가

V40에는 여러 평가 방법이 있으며, **AI별로 사용하는 방법이 다릅니다.**

| AI | 모델 | 방법 | 도구 | 배치 크기 | 비용 | 실행 |
|----|------|------|------|----------|------|------|
| **Claude** | Haiku 4.5 | CLI Direct / Skill | `helpers/claude_eval_helper.py` / `/evaluate-politician-v40` | 25 / 50 | $0 | 수동 or Skill 자동 |
| **ChatGPT** | gpt-5.1-codex-mini | CLI Direct (Codex) | `helpers/codex_eval_helper.py` | 25 (자동 재시도 5) | $0.05/$0.40/1M | Python subprocess (stdin) |
| **Gemini** | 2.0 Flash | CLI Subprocess | `workflow/evaluate_gemini_subprocess.py` | 25 (Pre-filtering) | $0 | Python subprocess 실행 |
| **Grok** | Grok 3 | Agent Tools API | `helpers/grok_eval_helper.py` | 25 | API 비용 | xAI curl subprocess |

**모델 및 비용 정보**:
- **Claude Haiku 4.5**: API 또는 CLI Direct 방식 (무료)
- **ChatGPT gpt-5.1-codex-mini**: ~1 credit/message, 96% cheaper than gpt-5.1 ($0.05 input / $0.40 output per 1M tokens)
- **Gemini 2.0 Flash**: Google AI Pro 유료 계정 필요 (Subprocess 무료)
- **Grok 3**: xAI Agent Tools API 사용 (유료)

**성능 최적화 (V40 개선)**:
- ✅ **배치 평가**: Gemini, ChatGPT 25개씩 처리 (이전: 1-by-1) → 10x 향상
- ✅ **Pre-filtering**: 이미 평가된 데이터 사전 제외 → 5x 향상, 중복 평가 0%
- ✅ **자동 재시도**: ChatGPT Foreign key 오류 시 배치 크기 5개로 자동 재시도 → 안정성 100%
- ✅ **공통 저장 함수**: common_eval_saver.py (4개 AI 통합 저장 로직) → 코드 중복 제거
- 📌 **추가 평가 스크립트 제거**: 기본 헬퍼가 미평가 데이터만 자동 처리

**🔧 기술적 방식 비교 (API vs CLI - 5개월 시행착오의 결과)**:

| 비교 항목 | CLI 방식 (✅ 채택) | API 방식 (❌ 폐기) |
|-----------|-------------------|-------------------|
| **인증 방식** | 🔓 Account Login (Claude/Gemini)<br>🔐 API Key (ChatGPT/Grok)<br>→ 1회 설정 후 재사용 | API Key 필수 (4개 전부)<br>→ 매 요청마다 인증 필요 |
| **실행 방식** | Subprocess 호출<br>→ 간단한 CLI 명령 | HTTP API 요청<br>→ 복잡한 JSON 구성 |
| **할당량/제한** | Claude/Gemini: 무제한 (구독)<br>ChatGPT/Grok: API 제한 적용 | 분당 요청 제한 (RPM)<br>→ Gemini: 15 req/min |
| **사용 편의성** | 1회 로그인/설정<br>→ 재로그인 불필요 | API 키 관리 필수<br>→ 만료, 보안 이슈 |
| **코드 복잡도** | 단순 (10-20줄)<br>→ subprocess.run() | 복잡 (50-100줄)<br>→ HTTP client, retry, error handling |
| **비용** | Claude/Gemini: $0 (구독)<br>ChatGPT: $1.125/1K 평가<br>총계: ~$1.13/1K 평가 | Claude: $0.75/1K<br>Gemini: $0.19/1K<br>ChatGPT: $45/1K<br>총계: ~$46/1K 평가 |
| **절감률** | **97.5%** (40배 저렴) | - |

**💡 핵심 인사이트**: "API가 아니라 CLI로 가라. 구독 플랜이 API보다 40배 저렴하다."

📄 **상세 분석**: `V40_AI_평가_방식_및_비용_종합_분석.md` 참조

#### 방법 1: Helper 패턴 - CLI Direct (Claude, Gemini용)

CLI 터미널에서 직접 평가 수행. API 비용 $0.

```bash
# Claude 평가
python helpers/claude_eval_helper.py fetch \
  --politician_id={POLITICIAN_ID} \
  --politician_name="{POLITICIAN_NAME}" \
  --category=expertise

# → fetch가 생성한 프롬프트를 Claude CLI에 붙여넣기
# → 결과를 JSON 파일로 저장

python helpers/claude_eval_helper.py save \
  --politician_id={POLITICIAN_ID} \
  --politician_name="{POLITICIAN_NAME}" \
  --category=expertise \
  --input=eval_result.json
```

```bash
# Gemini 평가 (CLI Subprocess 방식)
cd scripts/workflow
python evaluate_gemini_subprocess.py \
  --politician "{POLITICIAN_NAME}" \
  --category expertise

# ✅ 최적화 적용:
#   - 배치 25개씩 평가
#   - Pre-filtering (이미 평가된 데이터 자동 제외)
#   - 공통 저장 함수 사용
#   - 5x 속도 향상 (중복 평가 0%)

# ⚠️ 고급 사용자 전용 (수동 DB 조작)
# python helpers/gemini_eval_helper.py fetch
# → Gemini CLI에 프롬프트 붙여넣기 → 결과 JSON 저장
# python helpers/gemini_eval_helper.py save
```

#### 방법 1-2: Claude Skill 자동 평가 🤖 (권장!)

**Claude Code Skill을 통한 완전 자동 평가**

```bash
# Claude Code에서 실행 (단일 카테고리)
/evaluate-politician-v40 --politician_id=d0a5d6e1 --politician_name="조은희" --category=expertise

# 전체 카테고리 자동 평가 (10개 순차 실행)
/evaluate-politician-v40 --politician_id=d0a5d6e1 --politician_name="조은희" --category=all
```

**특징**:
- ✅ 50개 배치 자동 처리 (빠름!)
- ✅ fetch → evaluate → save 자동화
- ✅ 사용자 개입 없이 전체 프로세스 완료
- ✅ 10개 카테고리 순차 실행 가능

**Skill 파일**: `.claude/skills/evaluate-politician-v40.md`

**상세 가이드**: `CLAUDE.md` 섹션 "배치 크기 규칙" 참조

#### 방법 2: Codex CLI Direct (ChatGPT용)

Codex CLI로 stdin을 통해 자동 평가.

**특징**:
- ✅ **배치 평가**: 25개씩 한 번에 평가 (이전: 1-by-1)
- ✅ **Pre-filtering**: 이미 평가된 데이터 자동 제외
- ✅ **자동 재시도**: Foreign key 오류 시 배치 크기 5개로 자동 재시도
- ✅ **공통 저장 함수**: common_eval_saver.py 사용
- 📌 **모델**: gpt-5.1-codex-mini (~1 credit/message)

```bash
# Codex (ChatGPT) 평가
cd scripts/helpers
python codex_eval_helper.py \
  --politician_id={POLITICIAN_ID} \
  --politician_name="{POLITICIAN_NAME}" \
  --category=expertise \
  --batch_size=25

# ⚠️ 배치 크기 5개로 재시도 (Foreign key 오류 발생 시 자동)
```

#### 방법 3: grok_eval_helper.py - xAI API 호출 (Grok용)

xAI API를 통해 자동 평가. 별도 수동 작업 불필요.

```bash
# Grok 평가
cd scripts/helpers
python grok_eval_helper.py \
  --politician_id={POLITICIAN_ID} \
  --politician_name="{POLITICIAN_NAME}" \
  --category=expertise \
  --batch_size=25
```

> **참고**: ChatGPT(Codex), Gemini(Subprocess), Grok(API)는 자동 실행되지만,
> Claude(CLI Direct)는 수동으로 프롬프트를 붙여넣어야 합니다.

### 4.3.1 CLI Direct 에러 처리

CLI Direct (Gemini, Claude) 실행 시 에러 발생 처리 절차:

**1. JSON 형식 검증**: 저장 전 반드시 JSON 유효성 확인

**2. 재시도**: 실패 시 최대 4회 재시도

**3. 부분 실패**: 일부 카테고리만 실패 시 해당 카테고리만 재수집/재평가

**4. 포기 규칙**: 4회 재시도 후에도 실패 → 25-49개=부족허용, <25개=leverage score 0 (60점)

```python
# CLI Direct 에러 처리 예시
def validate_cli_output(json_str):
    """CLI Direct 출력 JSON 검증"""
    try:
        data = json.loads(json_str)
        required_fields = ['title', 'content', 'source_url', 'data_type', 'sentiment']

        for item in data:
            missing = [f for f in required_fields if f not in item]
            if missing:
                raise ValueError(f"필수 필드 누락: {missing}")

        return data
    except json.JSONDecodeError as e:
        print(f"❌ JSON 파싱 실패: {e}")
        return None
    except Exception as e:
        print(f"❌ 검증 실패: {e}")
        return None

# 재시도 로직
def save_with_retry(json_str, max_retries=3):
    """재시도 로직 포함 저장"""
    for attempt in range(1, max_retries + 1):
        validated_data = validate_cli_output(json_str)

        if validated_data:
            # DB 저장 로직
            print(f"✅ 저장 성공 (시도 {attempt}회)")
            return True
        else:
            print(f"⚠️ 저장 실패 (시도 {attempt}/{max_retries})")
            if attempt < max_retries:
                print("재시도 중...")

    print("❌ 완전 실패 - 운영자 확인 필요")
    return False
```

**에러 유형별 대응**:

| 에러 유형 | 원인 | 해결 방법 |
|-----------|------|-----------|
| JSON 파싱 실패 | 잘못된 JSON 형식 | Claude/Gemini CLI에 다시 프롬프트 입력 (수정 요청) |
| 필수 필드 누락 | title, content 등 누락 | 프롬프트 재실행 |
| URL 형식 오류 | 잘못된 URL | 프롬프트 수정 (URL 예시 추가) |
| 데이터 타입 오류 | official/public 외 값 | 프롬프트 수정 (data_type 명시) |
| DB 연결 실패 | Supabase 연결 오류 | 네트워크 확인, API 키 확인 |

### 4.4 점수 계산 (calculate_v40_scores.py)

```bash
python core/calculate_v40_scores.py \
  --politician_id={POLITICIAN_ID} \
  --politician_name="{POLITICIAN_NAME}"
```

### 4.5 결과 확인 (check_v40_results.py)

```bash
# 전체 결과 확인
python utils/check_v40_results.py \
  --politician_id={POLITICIAN_ID} \
  --politician_name="{POLITICIAN_NAME}"
```

---

## 5. 수집 상세

### 5.1 OFFICIAL vs PUBLIC 분담

#### OFFICIAL (40개) - Gemini 30 + Naver 10

**특징**:
- 객관적 사실 (누가 수집하든 동일)
- 편향 발생 여지 없음
- .go.kr 도메인 등 공식 사이트

**소스 예시**:
- 국회 의안정보 (assembly.go.kr)
- 정부 보도자료 (korea.kr)
- 선거관리위원회 (nec.go.kr)
- 정당 공식 사이트

#### PUBLIC (60개) - Gemini 20 + Naver 40

**특징**:
- 의견/평가 (출처마다 시각 다름)
- 편향 발생 가능
- 다양성 필요

**Gemini PUBLIC (20개)**:
- Google Search 기반
- 모든 PUBLIC 소스 자유

**Naver PUBLIC (40개)**:
- Naver Search 기반
- 모든 PUBLIC 소스 자유

**⚠️ 소스 제한 원칙**:
제한은 딱 2개만:
1. OFFICIAL은 OFFICIAL 소스만
2. PUBLIC은 PUBLIC 소스만

그 외 소스 제한/차단/금지 일체 없음

### 5.2 센티멘트 배분 (OFFICIAL 10-10-80 / PUBLIC 20-20-60)

```python
SENTIMENT_DISTRIBUTION = {
    "Gemini": {
        "official": {"negative": 3, "positive": 3, "free": 24},    # 30개 (10-10-80)
        "public": {"negative": 4, "positive": 4, "free": 12}       # 20개 (20-20-60)
    },
    "Naver": {
        "official": {"negative": 1, "positive": 1, "free": 8},     # 10개 (10-10-80)
        "public": {"negative": 8, "positive": 8, "free": 24}       # 40개 (20-20-60)
    }
}

# 버퍼 20% 포함 목표 (각 AI별 개수 × 1.2, 센티멘트 비율 유지)
SENTIMENT_DISTRIBUTION_BUFFER = {
    "Gemini": {
        "official": {"negative": 4, "positive": 4, "free": 28},    # 36개 (10-10-80)
        "public": {"negative": 5, "positive": 5, "free": 14}       # 24개 (20-20-60)
    },
    "Naver": {
        "official": {"negative": 1, "positive": 1, "free": 10},    # 12개 (10-10-80)
        "public": {"negative": 10, "positive": 10, "free": 28}     # 48개 (20-20-60)
    }
}

# === 기본 (100개) ===
# OFFICIAL (40개): 부정 3+1=4 (10%) / 긍정 3+1=4 (10%) / 자유 24+8=32 (80%)
# PUBLIC   (60개): 부정 4+8=12 (20%) / 긍정 4+8=12 (20%) / 자유 12+24=36 (60%)
# 전체    (100개): 부정 16 (16%) / 긍정 16 (16%) / 자유 68 (68%)

# === 버퍼 포함 (120개) ===
# OFFICIAL (48개): 부정 4+1=5 (10%) / 긍정 4+1=5 (10%) / 자유 28+10=38 (80%)
# PUBLIC   (72개): 부정 5+10=15 (21%) / 긍정 5+10=15 (21%) / 자유 14+28=42 (58%)
# 전체    (120개): 부정 20 (17%) / 긍정 20 (17%) / 자유 80 (67%)
```

---

## 6. 평가 상세

### 6.1 풀링 평가 방식

```
[수집 단계]
Gemini 50개 (50%) + Naver 50개 (50%) = 100개 풀 (버퍼 20% 포함 최대 120개)
(중복 제거 안 함, 그대로 합침)

[평가 단계]
4개 AI × 100개 = 400개 평가
- Claude: 100개 평가 ($0, CLI Direct)
- ChatGPT: 100개 평가
- Grok: 100개 평가
- Gemini: 100개 평가
```

### 6.2 평가 등급 체계

| 등급 | 판단 기준 | 점수 |
|------|-----------|------|
| +4 | 탁월함 - 해당 분야 모범 사례 | +8 |
| +3 | 우수함 - 긍정적 평가 | +6 |
| +2 | 양호함 - 기본 충족 | +4 |
| +1 | 보통 - 평균 수준 | +2 |
| -1 | 미흡함 - 개선 필요 | -2 |
| -2 | 부족함 - 문제 있음 | -4 |
| -3 | 매우 부족 - 심각한 문제 | -6 |
| -4 | 극히 부족 - 정치인 부적합 | -8 |

### 6.3 자연 가중치

- 2개 채널이 동일 뉴스 수집 → 풀에 2번 포함 → 2배 영향
- 별도 가중치 계산 불필요
- 자연스럽게 반영됨

---

## 7. 비용 분석

### 수집 비용

| AI | 카테고리당 | 정치인당 (10개) | 100명 |
|----|------------|----------------|-------|
| Gemini | $0 | $0 | **$0** |
| Naver | $0 | $0 | **$0** |
| **합계** | **$0** | **$0** | **$0** |

### 평가 비용

| AI | 항목당 | 정치인당 (1,000개) | 100명 |
|----|--------|-------------------|-------|
| Claude | $0 | **$0** | **$0** (CLI Direct) |
| ChatGPT | TBD | TBD | TBD |
| Grok | TBD | TBD | TBD |
| Gemini | TBD | TBD | TBD |

### 총 비용

```
수집: $0/100명 (Gemini + Naver 모두 무료)
평가: $0/100명 (Claude CLI Direct)
총: $0/100명

100% 무료 ✅
```

---

## 8. 예상 작업량

### 1명 정치인 기준

```
수집:
- Gemini: 500개 (10개 카테고리 × 50개)
- Naver: 500개 (10개 카테고리 × 50개)
- 총 1,000개 (버퍼 20% 포함 최대 1,200개)

평가:
- Claude: 1,000개 (CLI Direct, $0)
- ChatGPT: 1,000개
- Grok: 1,000개
- Gemini: 1,000개
- 총 4,000개 평가

점수 계산:
- 10개 카테고리 점수 산출
- 최종 종합 점수 산출
```

### 100명 기준

```
수집: 100,000개 (10만개, 버퍼 20% 포함 최대 120,000개)
평가: 400,000개 (40만개)
비용: $0 (완전 무료)
```

---

## 9. 주의사항

### 9.1 수집 시

- ✅ 실제 URL 필수 (example.com 금지)
- ✅ OFFICIAL은 OFFICIAL 소스만
- ✅ PUBLIC은 PUBLIC 소스만
- ✅ 그 외 소스 제한 일체 없음
- ✅ OFFICIAL 10-10-80 / PUBLIC 20-20-60 균형 유지

### 9.2 평가 시

- ✅ Claude CLI Direct 활용 (API 비용 $0)
- ✅ 수집 시점 ≠ 평가 시점 (세션 분리)
- ✅ 4개 AI 모두 전체 데이터 평가
- ✅ 등급 체계 준수 (+4 ~ -4)

### 9.3 비용 최적화

- ✅ Gemini 무료 (Google Search)
- ✅ Naver 무료 (Naver Search API)
- ✅ Claude CLI Direct ($0)
- ✅ 완전 무료 시스템

---

## 10. 데이터베이스 테이블 관계

```
politicians (정치인 기본 정보)
    ↓ 1:N
collected_data_v40 (수집 데이터, rating 없음)
    ↓ 1:N (collected_data_id로 연결)
evaluations_v40 (평가 결과, rating 있음)

politicians
    ↓ 1:1
ai_final_scores_v40 (최종 점수, JSONB)
```

**핵심:**
- `collected_data_v40.id` → `evaluations_v40.collected_data_id` (FK)
- 수집 데이터 1개 → 4개 AI 평가 (4개 레코드)
- 수집 테이블: rating 없음 (수집만)
- 평가 테이블: rating 있음 (평가만)

---

## 11. 참고 문서

- `V40_기본방침.md` - 핵심 지침
- `V40_오케스트레이션_가이드.md` - 자동화 가이드
- `V40_완전한_프로세스_플로우차트.md` - 전체 프로세스 시각화 ⭐
- `AI_기반_정치인_상세평가보고서_생성_가이드_V40.md` - 보고서 생성
- `Claude_CLI_Direct_평가_적용방법.md` - 평가 방법

---

**최종 업데이트**: 2026-02-06
**버전**: V40

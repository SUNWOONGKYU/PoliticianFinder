# V40 오케스트레이션 가이드

**작성일**: 2026-02-01
**최종 업데이트**: 2026-02-12 (평가 최적화 완료)
**버전**: V40 Final
**대상**: Claude Code 메인 에이전트
**목적**: V40 정치인 평가 시스템의 전체 프로세스 오케스트레이션

---

## 🎯 핵심 요약

**Claude의 역할**: 메인 에이전트로서 전체 평가 프로세스 오케스트레이션
**총 수집량**: **1,000개** (카테고리당 100개 × 10개 카테고리, 버퍼 20% 포함 최대 1,200개)
**총 평가량**: **4,000개** (4개 평가 AI × 1,000개)

**수집 배분**:
- Gemini OFFICIAL: 30개 (30%)
- Gemini PUBLIC: 20개 (20%)
- Naver OFFICIAL: 10개 (10%)
- Naver PUBLIC: 40개 (40%)

**평가 AI (4개)**:
- Claude, ChatGPT, Grok, Gemini
- ⚠️ Naver는 평가 제외 (수집 전담)

---

## ⚠️ 중요한 개념

### ⭐ 프로세스 시작점

**잘못된 이해**:
```
Phase 1: 수집 시작 (정치인 이름만 가지고)
```

**올바른 이해**:
```
Phase 0: 정치인 정보 수집 (필수 선행 단계!)
  → 이름, 소속 정당, 출마 직종, 출마 지역, 나이 등 확인

Phase 1: 수집 시작 (풍부한 컨텍스트를 담은 프롬프트로)
```

**왜 Phase 0이 중요한가?**
- 프롬프트에 정치인의 상세 정보 포함 필요
- 동명이인 구분 필요
- 수집 및 평가의 정확도 향상
- 컨텍스트 풍부화로 AI 판단력 향상

---

## 📋 전체 프로세스 (7단계)

### Phase 0: 정치인 정보 수집 ⭐ (가장 중요!)

**목적**: 평가 대상 정치인의 상세 정보 확보

**작업 내용**:
```python
# Supabase에서 정치인 정보 조회
from supabase import create_client, Client

politician_id = '{POLITICIAN_ID}'  # 예: 8자리 hex
response = supabase.table('politicians').select('*').eq('id', politician_id).execute()

politician_data = response.data[0]
```

**확보해야 할 정보 (12개 필수 필드)**:
```python
{
  "id": "{POLITICIAN_ID}",           # 8자리 hex (TEXT)
  "name": "{POLITICIAN_NAME}",       # 성명
  "party": "{PARTY}",                # 소속 정당
  "position": "{POSITION}",          # 현재 직책
  "previous_position": "{PREV_POS}", # ⚠️ 전 직책 (NULL 금지!)
  "identity": "{IDENTITY}",          # 출마 신분
  "title": "{TITLE}",                # 출마 직종
  "region": "{REGION}",              # 출마 지역
  "district": "{DISTRICT}",          # 지역구
  "gender": "{GENDER}",              # 성별 ('남' or '여')
  "birth_date": "{YYYY-MM-DD}",      # 생년월일 (DATE 형식)
  "career": ["{경력1}", "{경력2}", ...] # ⚠️ 주요 경력 (빈 배열 금지, 최소 5개!)
}
```

**⚠️ 12개 필수 필드 중 하나라도 NULL이면 Phase 0 미완료!**

**예시: 박주민 데이터**
```python
{
  "id": "8c5dcc89",                  # politician_id
  "name": "박주민",
  "party": "더불어민주당",
  "position": "국회의원 (3선)",
  "previous_position": "참여연대 사법감시센터 실행위원, 민변 사무차장",
  "identity": "출마예정자",
  "title": "광역단체장",
  "region": "서울",
  "district": "서울 은평구 갑",
  "gender": "남",
  "birth_date": "1973-11-21",
  "career": ["제20-22대 국회의원 (은평구 갑)", "국회 법제사법위원회 간사", "참여연대 사법감시센터 실행위원", "민변 사무차장", "서울시장 출마 선언"]
}
```

**⚠️ 주의**: 평가 시스템은 `politicians` 테이블을 사용합니다 (`politicians_v40`은 구버전, 사용 금지). 웹사이트 프로필용 필드(email, website, image_url)는 필요하지 않습니다.

**검증 체크리스트 (12개 필수 필드)**:
- [ ] 정치인 ID가 올바른가? (8자리 hex TEXT)
- [ ] 이름(name)이 정확한가?
- [ ] 소속 정당(party)이 확인되었는가?
- [ ] 현재 직책(position)이 확인되었는가?
- [ ] **전 직책(previous_position)이 저장되었는가? (NULL 금지!)**
- [ ] 출마 신분(identity)이 설정되어 있는가?
- [ ] 출마 직종(title)이 설정되어 있는가?
- [ ] 출마 지역(region)이 확인되었는가?
- [ ] 지역구(district)가 확인되었는가? (해당 시)
- [ ] 성별(gender)이 설정되어 있는가?
- [ ] 생년월일(birth_date)이 YYYY-MM-DD 형식인가?
- [ ] **주요 경력(career[])이 최소 5개 이상인가? (빈 배열 금지!)**

**사용자에게 확인 요청**:
```
정치인 정보를 확인했습니다 (12개 필수 필드):

이름: {POLITICIAN_NAME}
소속 정당: {PARTY}
현재 직책: {POSITION}
전 직책: {PREVIOUS_POSITION}
출마 신분: {IDENTITY}
출마 직종: {TITLE}
출마 지역: {REGION}
지역구: {DISTRICT}
성별: {GENDER}
생년월일: {BIRTH_DATE}
주요 경력: {CAREER} ({N}개)

12개 필드 모두 확인 완료. 이 정보로 평가를 진행하시겠습니까?
```

**예시: 박주민**
```
정치인 정보를 확인했습니다:

이름: 박주민
소속 정당: 더불어민주당
현재 직책: 국회의원 (3선)
출마 신분: 출마예정자
출마 직종: 광역단체장
출마 지역: 서울
지역구: 서울 은평구 갑
성별: 남
출생연도: 1973
나이: 52세

이 정보로 평가를 진행하시겠습니까?
```

---

### Phase 1: 데이터 수집 (1,000개)

**목적**: 2개 채널이 분담하여 총 1,000개 데이터 수집 (버퍼 20% 포함 최대 1,200개)

**수집 채널 분담**:

| AI | 비율 | 카테고리당 | 전체 (10 카테고리) | 특화 영역 |
|----|------|------------|-------------------|-----------|
| **Gemini** | **50%** | **50개** | **500개** | OFFICIAL 30개 (30%) + PUBLIC 20개 (20%) |
| **Naver** | **50%** | **50개** | **500개** | OFFICIAL 10개 (10%) + PUBLIC 40개 (40%) |
| **합계** | **100%** | **100개** | **1,000개** | - |

⚠️ **Claude/ChatGPT/Grok은 수집에서 제외** (평가만 담당)

**수집 구조** (카테고리당 100개):

```
┌─────────────────────────────────────────────────────────────┐
│ 📋 OFFICIAL 데이터 (40개, 40%)                              │
│    ├── Gemini: 30개 (30%) - Google Search 무료 ✅          │
│    └── Naver:  10개 (10%) - Naver Search 무료 ✅           │
│       이유: 객관적 사실, 편향 없음                         │
├─────────────────────────────────────────────────────────────┤
│ 📰 PUBLIC 데이터 (60개, 60%)                                │
│    ├── Gemini: 20개 (20%) - Google Search 기반             │
│    └── Naver:  40개 (40%) - Naver Search 기반              │
│       이유: 의견/평가, 독립 검색 인프라로 다양성 확보      │
└─────────────────────────────────────────────────────────────┘

✅ 총 수집: 100개 = Gemini 50 + Naver 50 (버퍼 20% 포함 최대 120개)

센티멘트 배분 (차등):
- OFFICIAL (40개→버퍼48): negative 10% (4→5개) / positive 10% (4→5개) / free 80% (32→38개)
- PUBLIC (60개→버퍼72): negative 20% (12→15개) / positive 20% (12→15개) / free 60% (36→42개)
- 통합 (100개→버퍼120): negative 16% (16→20개) / positive 16% (16→20개) / free 68% (68→80개)
```

**수집 원칙 - 제한은 딱 2개만**:

**1. OFFICIAL은 OFFICIAL 소스만**:
- assembly.go.kr, korea.kr, nec.go.kr, 지방정부/지방의회 등
- 공식 정부/의회/선거 사이트만 허용

**2. PUBLIC은 PUBLIC 소스만**:
- 뉴스, 블로그, SNS, 커뮤니티, 위키 등
- 비공식 콘텐츠 모두 허용

**❌ 그 외 소스 제한/차단/금지 일체 없음**:
- Gemini PUBLIC: 모든 PUBLIC 소스 자유
- Naver PUBLIC: 모든 PUBLIC 소스 자유
- 도메인 제한 없음
- 특정 소스 금지 없음

**10개 카테고리**:
1. 전문성 (expertise)
2. 리더십 (leadership)
3. 비전 (vision)
4. 청렴성 (integrity)
5. 윤리성 (ethics)
6. 책임감 (accountability)
7. 투명성 (transparency)
8. 소통능력 (communication)
9. 대응성 (responsiveness)
10. 공익성 (publicinterest)

**실행 방법**:
```bash
# Gemini CLI 수집 (10개 카테고리 병렬, 권장)
cd scripts/workflow
python collect_gemini_subprocess_parallel.py \
  --politician "{POLITICIAN_NAME}" \
  --period 2

# Naver API 수집 (각 카테고리별 실행)
# ⚠️ 하이픈 사용: --politician-id, --politician-name, --category 문자열
CATEGORIES="expertise leadership vision integrity ethics accountability transparency communication responsiveness publicinterest"
for cat in $CATEGORIES; do
  python collect_naver_v40_final.py \
    --politician-id {POLITICIAN_ID} \
    --politician-name "{POLITICIAN_NAME}" \
    --category $cat
done
```

**프롬프트 예시** (Phase 0에서 얻은 정보 활용):
```markdown
# 수집 대상 정치인
이름: {POLITICIAN_NAME}
소속 정당: 국민의힘
출마 직종: 광역단체장
출마 지역: 서울특별시
나이: 64세
현재 직책: 서울특별시장

# 수집 카테고리: 전문성
# 수집 항목: 10개 구체적 항목 (학력, 자격증, 경력, ...)

# 기간 제한
OFFICIAL 데이터: 최근 4년 (수집일 기준)
PUBLIC 데이터: 최근 2년 (수집일 기준)

# 수집 지침 (OFFICIAL 10-10-80 / PUBLIC 20-20-60)
# OFFICIAL: 부정 10% + 긍정 10% + 자유 80%
# PUBLIC: 부정 20% + 긍정 20% + 자유 60%
# 통합: 부정 16개 + 긍정 16개 + 자유 68개
```

**수집 결과 저장**:
```
DB 테이블: collected_data_v40
레코드 수: 1,000개 (100개 × 10개 카테고리, 버퍼 20% 포함 최대 1,200개)
```

---

### Phase 2: 검증 & 풀링 (Validation & Pooling)

**목적**: 2개 채널이 수집한 데이터를 카테고리별로 통합

**프로세스**:
```python
# 카테고리별로 수집된 데이터 조회
for category in categories:
    pool = supabase.table('collected_data_v40') \
        .select('*') \
        .eq('politician_id', politician_id) \
        .eq('category', category) \
        .execute()

    # 결과: 카테고리당 100개 풀 (버퍼 20% 포함 최대 120개)
    # Gemini 50개 + Naver 50개
```

**중요 특징**:
- ❌ 중복 제거 안 함 (있는 그대로 합침)
- ❌ 가중치 계산 안 함 (자연 가중치 활용)
- ✅ 2개 채널이 동일 뉴스 수집 → 풀에 2번 포함 → 자연스럽게 2배 영향

**자연 가중치 예시**:
```
뉴스 A: Gemini만 수집 → 풀에 1번 포함 → 평가 시 1배 영향
뉴스 B: 2개 채널 모두 수집 → 풀에 2번 포함 → 평가 시 2배 영향
```

---

### Phase 2-2: 검증 후 조정 (Adjust) ⚠️ 중요!

**목적**: 검증 후 데이터 균형 맞추기 (AI별/카테고리별)

**프로세스**:
```bash
# 1. 검증 실행 (중복 제거, 기간 제한 체크)
cd V40/scripts/core
python validate_v40_fixed.py \
  --politician_id d0a5d6e1 \
  --politician_name "조은희" \
  --no-dry-run

# 2. 균형 확인
cd V40/scripts/utils
python check_collection_status.py --politician "조은희"

# 3. 자동 조정 (60개 초과 삭제)
cd V40/scripts/core
python adjust_v40_data.py --politician_id d0a5d6e1

# 4. 재수집 (50개 미만인 경우만)
cd V40/scripts/workflow
python recollect_gemini_v40.py --politician "조은희"  # Gemini 부족 시
python recollect_naver_v40.py --politician_id d0a5d6e1 --politician_name "조은희"  # Naver 부족 시
```

**목표 범위**:
- AI별: 500-600개 (Gemini 500-600, Naver 500-600)
- 카테고리별: 50-60개/AI
- 전체: 1,000-1,200개

**⭐ 시간 절약 팁**:
```
Phase 1에서 버퍼 목표(60개/카테고리)로 수집 → Phase 2-2 거의 스킵!
Phase 1에서 최소 목표(50개)만 수집 → Phase 2-2 재수집 2-3시간 소요!
```

**자동 vs 수동**:
- ✅ **자동 조정**: adjust_v40_data.py (60개 초과 삭제)
- ⚠️ **수동 재수집**: recollect_*.py (50개 미만 보충)

**재수집 프로세스 (50개 미만 시)**:
```
Phase 1: 부족 카테고리 식별
  → check_collection_status.py 실행
  → 50개 미만 카테고리 확인

Phase 2: AI별 재수집
  → Gemini: recollect_gemini_v40.py (6-7회 실행, 1회=10개)
  → Naver: recollect_naver_v40.py (1회 실행, 60개 목표)

Phase 3: 확인 및 반복
  → 상태 재확인 (check_collection_status.py)
  → 60개 이상 → 완료 ✅
  → 50개 미만 → Phase 2 반복 (최대 4회)
  → 4회 후에도 미달: 25-49개=부족허용 / <25개=leverage score 0
```

**실전 예시 (조은희 integrity)**:
- 검증 후: Gemini 18개 (부족 42개)
- 재수집: 8라운드 (각 10개씩)
- 최종: Gemini 68개 ✅
- 소요 시간: 40-80분

**참고**: 상세한 조정 방법은 `V40_검증후조정_가이드.md` 참조

---

### Phase 3: 평가 (Evaluation)

**목적**: 4개 AI가 각각 전체 풀(1,000개)을 평가

**평가 AI** (4개 - 모델명 명시):
- **Claude** (Haiku 4.5)
- **ChatGPT** (gpt-5.1-codex-mini) - ~1 credit/message, 96% cheaper than gpt-5.1 ($0.05/$0.40 per 1M tokens)
- **Gemini** (2.5 Flash → 2.0 Flash → REST API, 3단계 Fallback)
- **Grok** (Grok 3)

⚠️ **Naver는 평가에서 제외** (수집 전담)

**🚀 성능 최적화 (V40 개선)**:
- ✅ **배치 평가**: Gemini, ChatGPT 25개씩 처리 (이전: 1-by-1) → 10x 향상
- ✅ **Pre-filtering**: 이미 평가된 데이터 사전 제외 → 5x 향상, 중복 평가 0%
- ✅ **자동 재시도**: ChatGPT Foreign key 오류 시 배치 크기 5개로 자동 재시도 → 안정성 100%
- ✅ **공통 저장 함수**: common_eval_saver.py (4개 AI 통합) → 코드 중복 제거
- 📌 **추가 평가 스크립트 제거**: 기본 헬퍼가 미평가 데이터만 자동 처리

**🔧 기술적 방식 비교 (API vs CLI - 5개월 시행착오)**:

| 항목 | CLI 방식 (✅) | API 방식 (❌) | 개선 효과 |
|------|--------------|--------------|-----------|
| **인증** | 1회 로그인/설정 | 매 요청마다 키 | 편의성 ↑ |
| **실행** | Subprocess | HTTP API | 복잡도 ↓ |
| **제한** | 무제한 (구독) | RPM 제한 | 속도 ↑ |
| **비용** | ~$1.13/1K | ~$46/1K | **97.5% 절감** |

💡 **핵심**: "API가 아니라 CLI로 가라. 구독 플랜이 API보다 40배 저렴하다."

📄 상세: `V40_AI_평가_방식_및_비용_종합_분석.md`

**평가 방식** (AI당):
```
카테고리당 100개 × 10개 카테고리 = 1,000개 평가

배치 처리 (최적화 적용):
- Claude/ChatGPT/Grok: 25개 배치 (API 최적화)
  - ChatGPT: 자동 재시도 5개 (Foreign key 오류 시)
- Gemini: 25개 배치 (Pre-filtering 적용)
- Claude Skill: 50개 배치 (자동화 권장)

⚡ 이전 대비 평균 7배 빠른 평가 속도
```

**전체 평가량**:
```
4개 AI × 1,000개 = 4,000개 평가 레코드
```

**등급 체계** (V40 - 8등급, X=제외):
```
+4: 매우 긍정적 (탁월함)
+3: 긍정적 (우수함)
+2: 다소 긍정적 (양호함)
+1: 약간 긍정적 (경미한 긍정)
-1: 약간 부정적 (경미한 부정)
-2: 다소 부정적 (미흡함)
-3: 부정적 (불량함)
-4: 매우 부정적 (매우 불량함)
X: 평가 제외 (등급 아님, 모수에서 제외)
```

**실행 방법** (AI별 Helper 사용):
```bash
# Claude Skill 자동 평가 (권장!) 🤖
# Claude Code에서 실행
/evaluate-politician-v40 --politician_id={POLITICIAN_ID} --politician_name="{POLITICIAN_NAME}" --category=all

# 또는 개별 AI Helper 스크립트:

# ChatGPT (gpt-5.1-codex-mini) 평가 - 배치 25개 + 자동 재시도
cd scripts/helpers
python codex_eval_helper.py --politician_id={POLITICIAN_ID} --politician_name="{POLITICIAN_NAME}" --category={CATEGORY} --batch_size=25

# Gemini (2.5 Flash → 2.0 Flash → REST API, 3단계 Fallback) 평가 - 배치 25개 + Pre-filtering + timeout fallback
cd scripts/workflow
python evaluate_gemini_subprocess.py --politician "{POLITICIAN_NAME}" --category "{CATEGORY}"

# Grok (Grok 3) 평가
cd scripts/helpers
python grok_eval_helper.py --politician_id={POLITICIAN_ID} --politician_name="{POLITICIAN_NAME}" --category={CATEGORY} --batch_size=25
```

**추천 방법**:
- ✅ **Claude Skill `/evaluate-politician-v40`** - 50개 배치 자동 평가 (가장 빠름!)
- ✅ Gemini Subprocess - 25개 배치 자동 평가
- ✅ ChatGPT/Grok Helper - 25개 배치 자동 평가

**참고**: 상세한 평가 방법은 `V40_전체_프로세스_가이드.md` Phase 4 참조

**타이밍 분리** (객관성 보장):
```
수집 시점 ≠ 평가 시점 (다른 세션)
→ 독립적 판단 = 더 객관적
```

**평가 결과 저장**:
```
DB 테이블: evaluations_v40
레코드 수: 4,000개 (4개 AI × 1,000개)
```

---

### Phase 4-1: AI별 카테고리 점수 계산

**목적**: 각 AI가 각 카테고리에 대해 부여한 평균 점수 계산

**계산 방식**:
```python
# AI별, 카테고리별 평균 등급 계산
for ai in evaluation_ais:  # Claude, ChatGPT, Gemini, Grok
    for category in categories:  # 10개 카테고리
        ratings = supabase.table('evaluations_v40') \
            .select('rating') \
            .eq('politician_id', politician_id) \
            .eq('ai_name', ai) \
            .eq('category', category) \
            .execute()

        # Phase 1: 등급 → 점수 변환 (rating × 2)
        RATING_TO_SCORE = {'+4': 8, '+3': 6, '+2': 4, '+1': 2, '-1': -2, '-2': -4, '-3': -6, '-4': -8}
        scores = [RATING_TO_SCORE[r] for r in ratings if r in RATING_TO_SCORE]

        avg_score = sum(scores) / len(scores)  # -8 ~ +8 (score = rating × 2)

        # Phase 2: 카테고리 점수 변환 (20~100점)
        PRIOR = 6.0
        COEFFICIENT = 0.5
        category_score = (PRIOR + avg_score * COEFFICIENT) * 10
```

**점수 범위**:
```
등급: +4 ~ -4 (8단계, 0 없음)
점수: 등급 × 2 = +8 ~ -8
카테고리 점수: 20 ~ 100점

계산식:
category_score = (6.0 + avg_score * 0.5) * 10  # avg_score = 점수 평균

예시:
avg_score = +8 (모두 +4) → score = (6.0 + 4.0) * 10 = 100점
avg_score = 0  (모두 +1/-1 혼합) → score = (6.0 + 0.0) * 10 = 60점
avg_score = -8 (모두 -4) → score = (6.0 - 4.0) * 10 = 20점
```

**저장**:
```
DB 테이블: ai_category_scores_v40
레코드 수: 40개 (4개 AI × 10개 카테고리)
```

---

### Phase 4-2: AI별 최종 점수 계산

**목적**: 각 AI의 10개 카테고리 점수를 합산하여 최종 점수 산출

**계산 방식**:
```python
for ai in evaluation_ais:
    category_scores = supabase.table('ai_category_scores_v40') \
        .select('score') \
        .eq('politician_id', politician_id) \
        .eq('ai_name', ai) \
        .execute()

    total_score = sum(category_scores)
    final_score = min(total_score, 1000)  # 최대 1000점
```

**점수 범위**:
```
최소: 200점 (20점 × 10개 카테고리)
최대: 1000점 (100점 × 10개 카테고리)
```

**저장**:
```
DB 테이블: ai_final_scores_v40
레코드 수: 4개 (4개 AI)
```

---

### Phase 4-3: 통합 점수 계산

**목적**: 4개 AI의 최종 점수를 평균하여 정치인의 통합 점수 산출

**계산 방식**:
```python
ai_scores = supabase.table('ai_final_scores_v40') \
    .select('final_score') \
    .eq('politician_id', politician_id) \
    .execute()

integrated_score = round(sum(ai_scores) / len(ai_scores))
```

**업데이트**:
```python
supabase.table('politicians') \
    .update({'integrated_score': integrated_score}) \
    .eq('id', politician_id) \
    .execute()
```

---

### Phase 5: 결과 보고 및 검증

**보고 내용**:
```markdown
# V40 평가 완료: {POLITICIAN_NAME}

## 수집 결과
- 총 수집량: 1,000개 (버퍼 20% 포함 최대 1,200개)
- Gemini: 500개 (50%)
  - OFFICIAL: 300개 (30개 × 10 카테고리)
  - PUBLIC: 200개 (20개 × 10 카테고리)
- Naver: 500개 (50%)
  - OFFICIAL: 100개 (10개 × 10 카테고리)
  - PUBLIC: 400개 (40개 × 10 카테고리)

## 평가 결과
- 총 평가량: 4,000개 (4개 AI × 1,000개)
- Claude 평가: 1,000개
- ChatGPT 평가: 1,000개
- Gemini 평가: 1,000개
- Grok 평가: 1,000개
- ⚠️ Naver: 평가 제외 (수집 전담)

## AI별 최종 점수
- Claude: 720점
- ChatGPT: 735점
- Gemini: 710점
- Grok: 725점

## 통합 점수
- 평균: 723점

## 카테고리별 점수 (Claude 기준)
1. 전문성: 75점
2. 리더십: 78점
3. 비전: 70점
4. 청렴성: 68점
5. 윤리성: 72점
6. 책임감: 74점
7. 투명성: 71점
8. 소통능력: 76점
9. 대응성: 73점
10. 공익성: 69점
```

**검증 체크리스트**:
- [ ] 수집량이 1,000개 이상인가?
- [ ] Gemini 500개 + Naver 500개인가?
- [ ] 평가량이 4,000개인가?
- [ ] 4개 AI 모두 평가했는가? (Claude, ChatGPT, Gemini, Grok)
- [ ] Naver는 평가에서 제외되었는가?
- [ ] 카테고리별 점수가 20~100 범위인가?
- [ ] 최종 점수가 200~1000 범위인가?
- [ ] DB에 모든 데이터가 저장되었는가?

---

## 🔧 실행 스크립트

### 전체 프로세스 자동화

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
V40 전체 프로세스 오케스트레이션 스크립트
"""

import os
import sys
from supabase import create_client, Client

# Supabase 설정
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_SERVICE_ROLE_KEY")
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

def step_0_gather_politician_info(politician_id: str):
    """Phase 0: 정치인 정보 수집 (11개 필드 검증)"""
    print(f"\n[Phase 0] 정치인 정보 수집 중...")

    response = supabase.table('politicians').select('*').eq('id', politician_id).execute()

    if not response.data:
        raise ValueError(f"정치인을 찾을 수 없습니다: {politician_id}")

    politician = response.data[0]

    print(f"\n정치인 정보:")
    print(f"  ID: {politician['id']}")
    print(f"  이름: {politician['name']}")
    print(f"  소속 정당: {politician['party']}")
    print(f"  현재 직책: {politician['position']}")
    print(f"  출마 신분: {politician['identity']}")
    print(f"  출마 직종: {politician['title']}")
    print(f"  출마 지역: {politician['region']}")
    print(f"  지역구: {politician['district']}")
    print(f"  성별: {politician['gender']}")
    print(f"  생년월일: {politician['birth_date']}")

    # 필수 정보 검증 (12개 필드)
    required_fields = [
        'id', 'name', 'party', 'position', 'previous_position', 'identity',
        'title', 'region', 'district', 'gender', 'birth_date', 'career'
    ]
    for field in required_fields:
        if politician.get(field) is None:  # None과 빈 문자열 구분
            raise ValueError(f"필수 정보 누락: {field}")

    return politician

def step_1_collect_data(politician_id: str, politician_name: str):
    """Phase 1: 데이터 수집 (1,000개, 버퍼 20% 포함 최대 1,200개)"""
    print(f"\n[Phase 1] 데이터 수집 시작...")
    print(f"  배분: Gemini 50% (500개) + Naver 50% (500개)")

    # Gemini + Naver 수집 스크립트 실행
    # Gemini CLI 병렬 수집
    os.system(f'python scripts/workflow/collect_gemini_subprocess_parallel.py --politician "{politician_name}" --period 2')
    # Naver API 수집 (각 카테고리별)
    categories = "expertise leadership vision integrity ethics accountability transparency communication responsiveness publicinterest"
    for cat in categories.split():
        os.system(f'python scripts/workflow/collect_naver_v40_final.py --politician-id {politician_id} --politician-name "{politician_name}" --category {cat}')

    # 수집 결과 확인
    response = supabase.table('collected_data_v40').select('id, ai_name').eq('politician_id', politician_id).execute()
    collected_count = len(response.data)

    # AI별 수집 수 확인
    gemini_count = sum(1 for item in response.data if item['ai_name'] == 'Gemini')
    naver_count = sum(1 for item in response.data if item['ai_name'] == 'Naver')

    print(f"  수집 완료: {collected_count}개")
    print(f"  - Gemini: {gemini_count}개 ({gemini_count/10}개/카테고리)")
    print(f"  - Naver: {naver_count}개 ({naver_count/10}개/카테고리)")

    if collected_count < 1000:
        raise ValueError(f"수집량 부족: 최소 1,000개, 실제 {collected_count}개")

    if gemini_count < 500:
        raise ValueError(f"Gemini 수집량 부족: 최소 500개, 실제 {gemini_count}개")

    if naver_count < 500:
        raise ValueError(f"Naver 수집량 부족: 최소 500개, 실제 {naver_count}개")

    return collected_count

def step_3_evaluate_data(politician_id: str, politician_name: str):
    """Phase 3: 데이터 평가 (4,000개)"""
    print(f"\n[Phase 3] 데이터 평가 시작...")
    print(f"  평가 AI: Claude, ChatGPT, Gemini, Grok (4개)")
    print(f"  ⚠️ Naver는 평가 제외 (수집 전담)")

    # 각 AI별 Helper 스크립트 실행 (실제로는 10개 카테고리 × 4개 AI = 40회 실행)
    # 예: codex_eval_helper.py, evaluate_gemini_subprocess.py, grok_eval_helper.py
    print(f"  ⚠️ 실제 평가는 AI별 Helper 스크립트를 카테고리별로 실행")
    print(f"  참고: V40_전체_프로세스_가이드.md Phase 4")

    # 평가 결과 확인
    response = supabase.table('evaluations_v40').select('id, ai_name').eq('politician_id', politician_id).execute()
    evaluated_count = len(response.data)

    # AI별 평가 수 확인
    claude_count = sum(1 for item in response.data if item['ai_name'] == 'Claude')
    chatgpt_count = sum(1 for item in response.data if item['ai_name'] == 'ChatGPT')
    gemini_count = sum(1 for item in response.data if item['ai_name'] == 'Gemini')
    grok_count = sum(1 for item in response.data if item['ai_name'] == 'Grok')

    print(f"  평가 완료: {evaluated_count}개")
    print(f"  - Claude: {claude_count}개")
    print(f"  - ChatGPT: {chatgpt_count}개")
    print(f"  - Gemini: {gemini_count}개")
    print(f"  - Grok: {grok_count}개")

    if evaluated_count != 4000:
        raise ValueError(f"평가량 오류: 예상 4,000개, 실제 {evaluated_count}개")

    return evaluated_count

def step_4_5_6_calculate_scores(politician_id: str):
    """Phase 4: 점수 계산"""
    print(f"\n[Phase 4] 점수 계산 시작...")

    # calculate_v40_scores.py 스크립트 실행
    os.system(f'python calculate_v40_scores.py --politician_id={politician_id}')

    # 최종 점수 확인
    response = supabase.table('politicians').select('integrated_score').eq('id', politician_id).execute()
    integrated_score = response.data[0]['integrated_score']

    print(f"  통합 점수: {integrated_score}점")

    return integrated_score

def main():
    """메인 함수"""
    if len(sys.argv) < 2:
        print("사용법: python v40_orchestrator.py <politician_id>")
        sys.exit(1)

    politician_id = sys.argv[1]

    try:
        # Phase 0: 정치인 정보 수집
        politician = step_0_gather_politician_info(politician_id)
        politician_name = politician['name']

        # 사용자 확인
        print(f"\n위 정보로 평가를 진행하시겠습니까? (y/n): ", end='')
        if input().lower() != 'y':
            print("평가를 취소합니다.")
            sys.exit(0)

        # Phase 1: 데이터 수집
        collected_count = step_1_collect_data(politician_id, politician_name)

        # Phase 2: 검증 (validate)
        print(f"\n[Phase 2] 검증 시작...")
        os.system(f'python validate_v40_fixed.py --politician_id={politician_id} --politician_name="{politician_name}" --no-dry-run')
        print(f"  검증 완료 (중복 제거, 기간 제한 체크)")

        # Phase 2-2: 검증 후 조정 (adjust)
        print(f"\n[Phase 2-2] 검증 후 조정 시작...")
        os.system(f'python adjust_v40_data.py --politician_id={politician_id}')

        # 균형 확인
        response = supabase.table('collected_data_v40').select('*').eq('politician_id', politician_id).execute()
        gemini_count = sum(1 for item in response.data if item['collector_ai'] == 'Gemini')
        naver_count = sum(1 for item in response.data if item['collector_ai'] == 'Naver')
        print(f"  조정 완료: Gemini {gemini_count}개, Naver {naver_count}개")

        if gemini_count < 500 or naver_count < 500:
            print(f"  ⚠️ 재수집 필요: recollect_gemini_v40.py 또는 recollect_naver_v40.py 실행")

        # Phase 3: 데이터 평가
        evaluated_count = step_3_evaluate_data(politician_id, politician_name)

        # Phase 4: 점수 계산
        integrated_score = step_4_5_6_calculate_scores(politician_id)

        # Phase 5: 결과 보고
        print(f"\n" + "="*80)
        print(f"V40 평가 완료: {politician_name}")
        print(f"="*80)
        print(f"총 수집량: {collected_count}개 (Gemini 500 + Naver 500)")
        print(f"총 평가량: {evaluated_count}개 (4개 AI × 1,000개)")
        print(f"통합 점수: {integrated_score}점")
        print(f"="*80)

    except Exception as e:
        print(f"\n❌ 오류 발생: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
```

---

## 💡 피해야 할 실수 (Learning from Errors)

### 실수 1: Phase 0 누락

**잘못된 시작**:
```
Phase 1: 수집 시작 (이름만 가지고)
```

**올바른 시작**:
```
Phase 0: 정치인 정보 수집 (필수!)
  → 이름, 정당, 직종, 지역, 나이 등 확인

Phase 1: 수집 시작 (풍부한 컨텍스트로)
```

**원인**: 프롬프트에 필요한 상세 정보를 간과

---

### 실수 2: politician_id 타입 오류

**잘못된 처리**:
```python
politician_id = parseInt(params.id)  # ❌ NaN 발생
```

**올바른 처리**:
```python
politician_id = params.id  # ✅ 문자열 그대로
```

**원인**: politician_id는 **TEXT 타입** (8자리 hex), 숫자 아님!

---

### 실수 3: 배분 비율 무시

**잘못된 수집**:
```
구 버전의 배분 사용
```

**올바른 수집**:
```
Gemini 50% (OFFICIAL 30개 [30%] + PUBLIC 20개 [20%])
+ Naver 50% (OFFICIAL 10개 [10%] + PUBLIC 40개 [40%])
= 총 100개 (버퍼 20% 포함 최대 120개)
```

**원인**: V40 배분 비율 적용 안 함

---

## 📚 참조 문서

- `V40_기본방침.md` - V40 시스템 기본 방침
- `V40_전체_프로세스_가이드.md` - 전체 프로세스 가이드
- `scripts/workflow/collect_gemini_subprocess_parallel.py` - Gemini CLI 수집
- `scripts/workflow/collect_naver_v40_final.py` - Naver API 수집
- `scripts/helpers/*_eval_helper.py` - AI별 평가 스크립트
- `scripts/core/calculate_v40_scores.py` - 점수 계산 스크립트

---

## ✅ 체크리스트

### 시작 전
- [ ] 정치인 ID 확인 (8자리 hex TEXT)
- [ ] DB 연결 확인 (Supabase)
- [ ] API 키 설정 확인 (Gemini, Naver, Claude, ChatGPT, Grok)
- [ ] Phase 0 완료 (정치인 정보 수집)

### 수집 중
- [ ] 2개 채널 분담 확인 (Gemini 50% + Naver 50%)
- [ ] OFFICIAL vs PUBLIC 분담 확인
  - [ ] OFFICIAL 40개: Gemini 30개 (30%) + Naver 10개 (10%)
  - [ ] PUBLIC 60개: Gemini 20개 (20%) + Naver 40개 (40%)
- [ ] 기간 제한 적용 확인
- [ ] 카테고리당 100개 확인 (버퍼 20% 포함 최대 120개)
- [ ] 총 1,000개 수집 확인

### 평가 중
- [ ] 4개 AI 평가 확인 (Claude, ChatGPT, Gemini, Grok)
- [ ] Naver 평가 제외 확인
- [ ] 카테고리당 100개 평가 확인
- [ ] 총 4,000개 평가 확인

### 완료 후
- [ ] 통합 점수 200~1000 범위 확인
- [ ] DB 저장 확인
- [ ] 결과 보고 작성
- [ ] 사용자 승인

---

**작성자**: Claude Code
**최종 업데이트**: 2026-02-01
**버전**: V40 Final

---

## 🚨 핵심 기억 사항

1. **V40 배분**: Gemini 50% + Naver 50%
2. **OFFICIAL vs PUBLIC 분담 (카테고리당 100개)**:
   - OFFICIAL 40개: Gemini 30개 (30%) + Naver 10개 (10%)
   - PUBLIC 60개: Gemini 20개 (20%) + Naver 40개 (40%)
3. **소스 제한 원칙**: 제한은 딱 2개만 (OFFICIAL은 OFFICIAL만, PUBLIC은 PUBLIC만)
4. **Phase 0 필수**: 정치인 정보 먼저 수집!
5. **politician_id는 TEXT**: parseInt() 금지!
6. **평가 AI 4개**: Claude, ChatGPT, Gemini, Grok (Naver 제외)
7. **총 수집**: 1,000개 (Gemini 500 + Naver 500, 버퍼 20% 포함 최대 1,200개)
8. **총 평가**: 4,000개 (4개 AI × 1,000개)
9. **비용**: Naver 무료 ($0)

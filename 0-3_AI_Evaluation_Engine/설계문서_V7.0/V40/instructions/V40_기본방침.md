# V40 기본 방침

**작성일**: 2026-02-12
**최종 업데이트**: Codex CLI 추가
**버전**: V40
**목적**: 웹검색 기반 2개 채널 분담 수집 (Gemini + Naver) + 4개 AI 풀링 평가

---

## ⚠️ 필수 요구사항

### Google AI Pro 유료 계정 필수

**V40 시스템은 Gemini CLI를 사용하므로 Google AI Pro 유료 계정이 반드시 필요합니다.**

**무료 계정으로는 작동하지 않습니다:**
- ❌ API Quota 제한으로 수집 실패
- ❌ "You have exhausted your capacity on this model" 오류
- ❌ 불완전한 데이터 및 작업 중단

**유료 계정 혜택:**
- ✅ 일일 1,500 requests 쿼터
- ✅ 안정적인 대량 데이터 수집
- ✅ V40 전체 워크플로우 정상 작동

**인증 방법:**
자세한 내용은 `2_collect/GEMINI_CLI_수집_가이드.md` 섹션 2 참조

---

## 1. V40 핵심 변경사항

### V30 → V40 변경 요약

| 항목 | V40 |
|------|-----|
| 수집 채널 | **Gemini + Naver Search API** (2개 채널) |
| 카테고리당 수집 | **100개 (버퍼 20%, 최대 120개)** |
| 소스 제한 | **없음 (OFFICIAL/PUBLIC 구분만)** |
| 비용 | **$0 (전부 무료)** |

### V40 핵심 원리
- **글로벌 검색의 최강자 Google + 국내 검색의 최강자 Naver = 쌍두마차**
- **소스 제한 일체 없음**: OFFICIAL이냐 PUBLIC이냐, 이 2가지 구분만 존재
- **네이버 API 무료**: 일 25,000건, 카테고리별 분리 검색 가능

---

## 2. 수집 배분 (카테고리당 100개 + 20% 버퍼)

### 배분표

```
┌────────┬────────────┬────────────┬───────┬───────────┐
│   AI   │  OFFICIAL  │   PUBLIC   │ 합계  │ 버퍼 포함 │
├────────┼────────────┼────────────┼───────┼───────────┤
│ Gemini │ 30개       │ 20개       │ 50개  │ 60개      │
├────────┼────────────┼────────────┼───────┼───────────┤
│ Naver  │ 10개       │ 40개       │ 50개  │ 60개      │
├────────┼────────────┼────────────┼───────┼───────────┤
│ 합계   │ 40개 (40%) │ 60개 (60%) │ 100개 │ 120개     │
└────────┴────────────┴────────────┴───────┴───────────┘
```

### 비율 구조
- **OFFICIAL : PUBLIC = 40% : 60%**
- **Gemini : Naver = 50% : 50% (1:1)**
- **OFFICIAL 내 Gemini:Naver = 3:1** (Gemini가 .go.kr 인덱싱에 강함)
- **PUBLIC 내 Gemini:Naver = 1:2** (Naver가 블로그/카페/뉴스에 강함)
- **모든 개수에 20% 버퍼 적용**

### 수집 목표 체계 (2단계)

**⭐ 핵심 원칙: 처음부터 버퍼 목표(120개)로 수집! ⭐**

**Stage 1: 초기 수집**
- ✅ **권장 목표: 120개/카테고리 (100 + 20% 버퍼)**
- ❌ **비권장: 100개만 수집 → Phase 3-3 재수집 필요 (시간 낭비!)**
- 이유: 검증 과정에서 무효 데이터 발생 대비
- **AI별 분배:** Gemini 60개 + Naver 60개 = 120개 (50-50 유지)

**Stage 2: 검증 및 재수집**
- 검증 기준: 최소 목표 100개 달성 여부
- 재수집 목표: **100개까지만** (버퍼 제외!)

```
✅ 올바른 프로세스 (권장):
초기 수집 120개 (버퍼 포함) → 검증 삭제 → 100-120개 유지 → Phase 3-3 스킵!
                                                              ^^^^^^^^
                                          시간 절약: 2-3시간 단축!

❌ 비효율 프로세스 (비권장):
초기 수집 100개 → 검증 삭제 → 90개 남음 → Phase 3-3 재수집 (2-3시간)
                                              ^^^^^^^^^^^^^^^^^^^
                                              시간 낭비!
```

**왜 처음부터 120개(버퍼)를 수집해야 하는가?**
1. **검증 삭제 대비**: URL 오류, 중복, 기간 초과 등으로 10-20% 삭제됨
2. **재수집 방지**: 120개 수집 → 검증 후 100+ 유지 → 재수집 불필요
3. **시간 절약**: Phase 3-3 재수집 2-3시간 절약
4. **규칙 준수**: 50-50 분배 (Gemini 60 + Naver 60) 유지

**AI별 버퍼 목표 (Phase 2 초기 수집 시):**
- Gemini: 60개/카테고리 (OFFICIAL 36 + PUBLIC 24)
- Naver: 60개/카테고리 (OFFICIAL 12 + PUBLIC 48)
- 합계: 120개/카테고리

**재수집이 필요한 경우 (Phase 2-2):**
- 검증 후 50개 미만인 AI/카테고리만
- 재수집 목표: 최소 50개 (버퍼 60개 아님!)
- 이유: 부족분 보충 목적, 초과 수집 불필요

**재수집 포기 규칙 (Phase 2-2):**
- 재수집 최대 **4회** (MAX_ADJUSTMENT_ROUNDS = 4)
- 4회 재수집 후 AI/카테고리별 판정:
  - **50개 이상**: 정상 → 평가 진행
  - **25~49개**: 부족 허용 → 보유 데이터로 평가 진행
  - **25개 미만**: 포기 → leverage score 0 처리 (PRIOR만 적용, 60점)
- leverage score 0 = 평가 조정 영향력 없음
  - 공식: (PRIOR + 0 × COEFFICIENT) × 10 = 60점
  - PRIOR 값만 남으므로 하드코딩이 아닌 수식 기반

---

## 3. OFFICIAL / PUBLIC 정의

### 제한은 딱 2개뿐

1. **OFFICIAL 수집 시 → OFFICIAL 데이터만 수집**
2. **PUBLIC 수집 시 → PUBLIC 데이터만 수집**

**그 외 어떤 소스에서 가져올지, 어떤 도메인을 쓸지 - 일체 제한 없음.**
**각 AI가 알아서 자유롭게 수집.**

### OFFICIAL = 사실(fact) 기반 공식 기록
- 국회 의정활동, 법안 발의, 국정감사, 정부 발표, 공식 경력, 선거 기록
- 기간: **최근 4년**

### PUBLIC = 여론/평가/의견 기반 비공식 콘텐츠
- 뉴스 보도, 블로그, 유튜브, 위키, 커뮤니티, 카페, 시민단체, 학술자료
- 기간: **최근 2년**

---

## 4. OFFICIAL 소스 (참고용 - 제한 아님)

사실(fact) 기반 공식 기록만. 의견/평가 제외.

**[정부/공공기관]**
- 국회 (assembly.go.kr, likms.assembly.go.kr)
- 정부 대표 (korea.kr)
- 정보공개 (open.go.kr)
- 행안부 (mois.go.kr)
- 권익위 (acrc.go.kr)
- 감사원 (bai.go.kr)
- 선관위 (nec.go.kr)
- 인권위 (humanrights.go.kr)
- 헌법재판소 (ccourt.go.kr)

**[지방자치]**
- 서울 (seoul.go.kr), 경기 (gg.go.kr), 부산 (busan.go.kr)
- 인천, 대구, 대전, 광주, 울산, 세종 등 (.go.kr)

**[정당/선거]**
- 매니페스토 (manifesto.or.kr)
- 국민의힘 (peoplepowerparty.kr)
- 더불어민주당 (theminjoo.kr)

**[공식 활동 유형]**
- 법안 발의, 국정감사 질의, 위원회 활동
- 기자회견, 공식 성명, 정책 발표
- 경력, 학력, 수상, 공적 기록

---

## 5. PUBLIC 소스 (참고용 - 제한 아님)

여론/평가/의견 기반. 비공식 콘텐츠.

**[뉴스/언론]**
- 종합일간지, 방송사, 통신사, 경제지, 인터넷매체
- 지역언론, 해외언론

**[위키]**
- 나무위키 (namu.wiki)
- 위키백과 한글 (ko.wikipedia.org)
- 위키백과 영문 (en.wikipedia.org)

**[동영상]**
- YouTube, 네이버TV, 카카오TV, 아프리카TV, Vimeo

**[블로그]**
- 네이버 블로그 (blog.naver.com)
- 티스토리 (tistory.com)
- 브런치 (brunch.co.kr)
- 미디엄 (medium.com)
- 워드프레스, 다음 블로그, 개인 블로그

**[커뮤니티]**
- 디시인사이드, 클리앙, 더쿠, 펨코, 뽐뿌
- 오늘의유머, 루리웹, 보배드림, SLR클럽, MLB파크, 82cook

**[카페]**
- 네이버 카페 (cafe.naver.com)
- 다음 카페 (cafe.daum.net)

**[지식iN]**
- 네이버 지식iN (kin.naver.com)

**[시민단체/NGO]**
- 참여연대 (peoplepower21.org)
- 경실련 (ccej.or.kr)
- 환경운동연합 (kfem.or.kr)

**[학술/연구]**
- Google Scholar, KISS, DBpia, RISS

**[SNS]**
- Instagram, Facebook, Threads

---

## 6. 센티멘트 배분 (OFFICIAL 10-10-80 / PUBLIC 20-20-60)

### Sentiment 배분 (OFFICIAL 데이터와 PUBLIC 데이터 차등 적용)

```
┌────────────────────┬──────────┬──────────┬──────┬──────┬───────────────────────────┐
│                    │ negative │ positive │ free │ 합계 │ 버퍼 20% (neg/pos/free)   │
├────────────────────┼──────────┼──────────┼──────┼──────┼───────────────────────────┤
│ Gemini OFFICIAL 30 │ 3 (10%)  │ 3 (10%)  │ 24   │ 30   │ 36개 (4/4/28)             │
├────────────────────┼──────────┼──────────┼──────┼──────┼───────────────────────────┤
│ Gemini PUBLIC 20   │ 4 (20%)  │ 4 (20%)  │ 12   │ 20   │ 24개 (5/5/14)             │
├────────────────────┼──────────┼──────────┼──────┼──────┼───────────────────────────┤
│ Naver OFFICIAL 10  │ 1 (10%)  │ 1 (10%)  │ 8    │ 10   │ 12개 (1/1/10)             │
├────────────────────┼──────────┼──────────┼──────┼──────┼───────────────────────────┤
│ Naver PUBLIC 40    │ 8 (20%)  │ 8 (20%)  │ 24   │ 40   │ 48개 (10/10/28)           │
├────────────────────┼──────────┼──────────┼──────┼──────┼───────────────────────────┤
│ OFFICIAL 소계      │ 4 (10%)  │ 4 (10%)  │ 32   │ 40   │ 48개 (5/5/38)             │
├────────────────────┼──────────┼──────────┼──────┼──────┼───────────────────────────┤
│ PUBLIC 소계        │ 12 (20%) │ 12 (20%) │ 36   │ 60   │ 72개 (15/15/42)           │
├────────────────────┼──────────┼──────────┼──────┼──────┼───────────────────────────┤
│ 합계               │ 16 (16%) │ 16 (16%) │ 68   │ 100  │ 120개 (20/20/80)          │
└────────────────────┴──────────┴──────────┴──────┴──────┴───────────────────────────┘
```

**차등 비율 설명**:
- **OFFICIAL (40→48개)**: negative 10% (4→5개) / positive 10% (4→5개) / free 80% (32→38개)
  - 공식 데이터는 사실 기반이므로 자유 검색 비중 높임
- **PUBLIC (60→72개)**: negative 20% (12→15개) / positive 20% (12→15개) / free 60% (36→42개)
  - 여론 데이터는 긍정/부정 균형 있게 수집
- **버퍼 계산 방식 (bottom-up)**: 각 AI별 개수에 20%를 적용한 후 합산
  - 예: Gemini OFF neg 3×1.2≈4, Naver OFF neg 1×1.2≈1 → OFFICIAL neg 합계 = 5
  - top-down(OFFICIAL 40→48에 10% 적용)과 동일 결과: 총합 120개 (20/20/80)

---

## 7. 각 AI 웹검색 도구

### Gemini (50%) - Gemini CLI Direct Subprocess ✅ 무료

**방식**: Gemini CLI Direct Subprocess (재미나 CLI 다이렉트 서브프로세스)

**정의**:
- Python `subprocess.run()`으로 Gemini CLI를 직접 실행
- stdin을 통한 프롬프트 전달
- 구글 검색 자동 수행 (Google Search Grounding)

**스크립트**:
- `scripts/workflow/collect_gemini_subprocess.py` - 단일 카테고리
- `scripts/workflow/collect_gemini_subprocess_parallel.py` - 병렬 수집 (권장)

**비용**: 무료 (Google AI Pro: 1,500 requests/day)

**강점**:
- Google 검색 기반 (.go.kr 인덱싱 강함)
- 한국어 콘텐츠 특화
- JavaScript 렌더링 강함
- YouTube 검색 (Google 소유)

---

### Naver Search API (50%) - 네이버 검색 ✅ 무료

```python
import requests
headers = {
    "X-Naver-Client-Id": NAVER_CLIENT_ID,
    "X-Naver-Client-Secret": NAVER_CLIENT_SECRET
}
# 블로그, 뉴스, 카페, 지식iN, 웹문서, 전문정보, 백과사전
response = requests.get(
    f"https://openapi.naver.com/v1/search/{endpoint}.json",
    params={"query": query, "display": 100, "sort": "sim"},
    headers=headers
)
```

**비용**: 완전 무료 (일 25,000건)

**강점**:
- 국내 검색 최강자
- 카테고리별 분리 검색 (블로그, 뉴스, 카페, 지식iN 등)
- JSON 응답에 title, link, description, postdate 포함
- 한 번에 최대 100건 반환

**네이버 검색 API 엔드포인트**:

| # | 엔드포인트 | 용도 |
|---|-----------|------|
| 1 | blog.json | 네이버 블로그 검색 |
| 2 | news.json | 뉴스 검색 |
| 3 | cafearticle.json | 카페 글 검색 |
| 4 | kin.json | 지식iN 검색 |
| 5 | webkr.json | 웹문서 검색 |
| 6 | doc.json | 전문정보 검색 |
| 7 | encyc.json | 백과사전 검색 |

---

## 8. 평가 AI (4개)

### Claude (Haiku 4.5) - CLI Direct ⚠️ 평가만 (수집 제외)
**평가 방식**:
- CLI Direct: Claude CLI 세션에서 직접 평가 (API 아님, $0)
- Skill 자동화: `/evaluate-politician-v40` (50개 배치 자동 평가)
**배치 크기**: 25개 (API), 50개 (Skill)
**수집 제외 사유**: web_search 도구 검색당 $0.01 추가 과금

### Gemini (2.0 Flash) - CLI Subprocess ✅ 수집 + 평가
**평가 방식**: Gemini CLI Subprocess (`evaluate_gemini_subprocess.py`, $0)
**배치 크기**: 25개
**프로세스**: instruction 파일 로드 → Gemini CLI subprocess → DB 저장

### ChatGPT (gpt-5.1-codex-mini) - CLI Direct ⚠️ 평가만 (수집 제외)
**모델**: gpt-5.1-codex-mini (96% cheaper than gpt-5.1)
**비용**: $0.05/$0.40 per 1M tokens
**평가 방식**: Codex CLI (OpenAI ChatGPT CLI) stdin 방식 ($0)
**배치 크기**: 25개
**프로세스**: codex_eval_helper.py fetch → Codex CLI subprocess → codex_eval_helper.py save
**수집 제외 사유**: Bing 검색 별도 과금

### Grok (Grok 3) - xAI Agent Tools API ⚠️ 평가만 (수집 제외)
**평가 방식**: xAI Agent Tools API, curl subprocess (`grok_eval_helper.py`)
**배치 크기**: 25개
**수집 제외 사유**: X/Twitter 데이터 수집 불안정

---

## 9. 평가 시스템 (4개 AI 풀링)

### 풀링이란?

**풀링(Pooling) = "모두가 찾은 것을 각자가 평가"**

2개 채널(Gemini, Naver)이 각각 수집한 데이터를 **하나의 풀(Pool)**로 합친 후,
4개 AI(Claude, Codex/ChatGPT, Gemini, Grok)가 **각각 독립적으로 전체 풀을 평가**하는 방식입니다.

핵심 포인트:
- **수집 시점 ≠ 평가 시점**: 수집과 평가는 별도 세션에서 진행 (객관성 보장)
- **수집자 ≠ 평가자**: 수집은 2개 채널, 평가는 4개 AI (역할 분리)
- **중복 제거 안 함**: 같은 뉴스가 Gemini와 Naver 모두에서 수집되면 풀에 2번 포함

### 풀링 구조 (카테고리당)

```
[1단계: 수집 - 2개 채널]
Gemini CLI → 50개 (OFFICIAL 30 + PUBLIC 20)
Naver API  → 50개 (OFFICIAL 10 + PUBLIC 40)
                    ↓
            100개 풀 (Pool)
        (중복 제거 안 함, 그대로 합침)
                    ↓
[2단계: 평가 - 4개 AI, 각각 전체 100개 평가]
Claude       → 100개 평가 → 각 항목에 +4 ~ -4 등급
Codex/ChatGPT → 100개 평가 → 각 항목에 +4 ~ -4 등급
Gemini       → 100개 평가 → 각 항목에 +4 ~ -4 등급
Grok         → 100개 평가 → 각 항목에 +4 ~ -4 등급
                    ↓
            총 400개 평가 결과
                    ↓
[3단계: 점수 계산]
4개 AI 평균 → 카테고리 점수 → 최종 점수 (200~1000점)
```

### 평가 검증 기준

**평가 완료율 기준: 95% 이상**

```
기대 평가 수 = 수집 데이터 개수 × 4 (AI 수)
평가 완료율 = (실제 평가 수 / 기대 평가 수) × 100

예시) 수집 1,000개 → 기대 4,000개 평가
      → 95% 기준 = 3,800개 이상 평가 필요
      → 또는: 최소 950개 데이터 평가 완료 (1,000 × 95%)

95% 이상: ✅ 통과 → 점수 계산 진행
95% 미만: ⚠️ 미달 → 누락 평가 재실행
```

**왜 95%인가?**
- 통계적 신뢰도 확보 (Margin of Error ±3.18%)
- 5% 버퍼로 실무적 유연성 제공
- 재평가 리스크 감소 (평가 실패율 5% 허용)

### 점수 계산 공식

```python
PRIOR = 6.0
COEFFICIENT = 0.5

# 카테고리 점수 (20~100점)
category_score = (PRIOR + avg_rating * COEFFICIENT) * 10

# 최종 점수 (200~1000점)
final_score = round(min(sum(10개 카테고리), 1000))
```

### 최종 등급 (10단계)

| 등급 | 이름 | 점수 범위 | 설명 |
|------|------|-----------|------|
| M | Mugunghwa | 920~1000 | 최우수 |
| D | Diamond | 840~919 | 우수 |
| E | Emerald | 760~839 | 양호 |
| P | Platinum | 680~759 | 보통+ |
| G | Gold | 600~679 | 보통 |
| S | Silver | 520~599 | 보통- |
| B | Bronze | 440~519 | 미흡 |
| I | Iron | 360~439 | 부족 |
| Tn | Tin | 280~359 | 상당히 부족 |
| L | Lead | 200~279 | 매우 부족 |

### 자연 가중치
- 동일 뉴스를 Gemini와 Naver 모두 수집 → 풀에 2번 포함 → 4개 AI가 각각 2번 평가 → 자연스럽게 2배 영향력
- 별도 가중치 계산 불필요, 중요한 뉴스일수록 여러 채널에서 수집되므로 자동 가중

---

## 10. 비용 분석

### 수집 비용

| AI | 카테고리당 | 정치인당 (10개 카테고리) | 100명 |
|----|------------|--------------------------|-------|
| Gemini | $0 | $0 | **$0** |
| Naver | $0 | $0 | **$0** |
| **합계** | **$0** | **$0** | **$0** |

### 평가 비용

```
✅ Claude: $0 (CLI Direct)
✅ Codex/ChatGPT: $0 (CLI Direct)
✅ 나머지 AI: 별도 확인 필요

→ 수집 $0 + 평가 $0 = 총 $0/100명 (이상적)
```

---

## 11. 예상 작업량

### 1명 정치인 기준

```
수집:
- Gemini OFFICIAL: 300개 (10개 카테고리 × 30개)
- Gemini PUBLIC: 200개 (10개 카테고리 × 20개)
- Naver OFFICIAL: 100개 (10개 카테고리 × 10개)
- Naver PUBLIC: 400개 (10개 카테고리 × 40개)
- 총 카테고리: 10개 × 100개 = 1,000개
- 버퍼 포함 최대: 1,200개 (120%)

검증 후 최종:
- 1,000개 이상 → 패스 ✅
- 1,000개 미만 → 추가 수집 🔄

평가:
- Claude: 1,000개 (CLI Direct)
- Codex/ChatGPT: 1,000개 (CLI Direct)
- Gemini: 1,000개 (CLI Subprocess)
- Grok: 1,000개 (API)
- 총 4,000개 평가

점수 계산:
- 10개 카테고리 점수 산출
- 최종 종합 점수 산출
```

### 100명 기준

```
수집: 100,000개 (10만개)
버퍼 포함 최대: 120,000개 (12만개)
평가: 400,000개 (40만개)
비용: $0 (Gemini + Naver 모두 무료)
```

---

## 12. 실행 명령

### 수집

```bash
# Gemini + Naver 전체 수집
python collect_v40.py --politician_id=ID --politician_name="이름"

# 특정 AI만
python collect_v40.py --politician_id=ID --politician_name="이름" --ai=Gemini
python collect_v40.py --politician_id=ID --politician_name="이름" --ai=Naver

# 병렬 실행 (권장)
python collect_v40.py --politician_id=ID --politician_name="이름" --parallel
```

### 평가 (Claude CLI Direct)

```bash
# 1. 미평가 데이터 조회
python helpers/claude_eval_helper.py fetch \
  --politician_id=ID --politician_name="이름" --category=expertise

# 2. Claude CLI에서 평가 수행

# 3. 결과 DB 저장
python helpers/claude_eval_helper.py save \
  --politician_id=ID --politician_name="이름" --category=expertise --input=eval_result.json
```

---

## 13. URL 검증 기술

### URL 검증 방식

```python
# GET stream=True + User-Agent → 90%+ 성공률
headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
response = requests.get(url, timeout=5, allow_redirects=True, headers=headers, stream=True)
response.close()
return response.status_code < 400
```

### Gemini redirect URL 해결

```python
# Location 헤더에서 실제 URL 추출
response = requests.head(redirect_url, allow_redirects=False)
if response.status_code in [301, 302, 303, 307, 308]:
    real_url = response.headers['Location']
```

---

## 14. 최종 요약

### 배분표

| AI | OFFICIAL | PUBLIC | 합계 | 버퍼 포함 |
|----|----------|--------|------|-----------|
| **Gemini** | 30개 | 20개 | **50개** | **60개** |
| **Naver** | 10개 | 40개 | **50개** | **60개** |
| **합계** | **40개 (40%)** | **60개 (60%)** | **100개** | **120개** |

### 핵심 원칙

1. **제한은 딱 2개**: OFFICIAL은 OFFICIAL만, PUBLIC은 PUBLIC만
2. **그 외 소스 제한 일체 없음**: 각 AI가 자유롭게 수집
3. **센티멘트 배분**: OFFICIAL 10-10-80 / PUBLIC 20-20-60 (통합 16-16-68)
4. **모든 개수에 20% 버퍼**
5. **평가 AI 4개 동일**: Claude, Codex/ChatGPT, Gemini, Grok
6. **비용 $0**: Gemini 무료 + Naver 무료

---

**최종 업데이트**: 2026-02-01
**다음 단계**: collect_v40.py 구현

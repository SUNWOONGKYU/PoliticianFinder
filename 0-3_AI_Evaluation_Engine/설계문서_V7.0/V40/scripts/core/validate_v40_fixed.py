# -*- coding: utf-8 -*-
"""
V40 ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸ (ìˆ˜ì • ë²„ì „)

ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ê²€ì¦í•˜ê³  ë¬¸ì œê°€ ìˆëŠ” í•­ëª©ì„ ì‹ë³„í•©ë‹ˆë‹¤.

ìˆ˜ì • ì‚¬í•­:
1. URL timeout: 10ì´ˆ â†’ 30ì´ˆ
2. validate_event_date: ì™„ì „íˆ ì œê±° (ê³¼ë„í•œ ì˜¤íŒ)
3. ê¸°ê°„ ê²€ì¦: published_dateë§Œ ì‚¬ìš© (event_year ë¬´ì‹œ)
4. URL ê²€ì¦: 3íšŒ ì¬ì‹œë„ (ë„¤íŠ¸ì›Œí¬ ë¶ˆì•ˆì • ëŒ€ì‘)
5. ê²€ì¦ ëª¨ë“œ: ì‚­ì œí•˜ì§€ ì•Šê³  ë¡œê·¸ë§Œ ê¸°ë¡

í•µì‹¬ ì›ì¹™:
- ê²€ì¦ì€ "ì°¸ê³ ìš©"
- ì‚­ì œëŠ” ì‹ ì¤‘í•˜ê²Œ
- AI í‰ê°€ ë‹¨ê³„ì—ì„œ ìµœì¢… í’ˆì§ˆ íŒë‹¨ (4ê°œ AI: Claude Haiku 4.5, ChatGPT gpt-5.1-codex-mini, Gemini 2.0 Flash, Grok 3)

ì‚¬ìš©ë²•:
    python validate_v40_fixed.py --politician_id=62e7b453 --politician_name="ì˜¤ì„¸í›ˆ" --no-dry-run
"""

import sys
import io

# UTF-8 ì¶œë ¥ ì„¤ì • (ìµœìš°ì„  - ëª¨ë“  import ì „ì— ì‹¤í–‰)
if sys.platform == 'win32':
    try:
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', line_buffering=True)
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', line_buffering=True)
    except AttributeError:
        pass

import os
import json
import re
import argparse
import time
import requests
from datetime import datetime, timedelta
from urllib.parse import urlparse
from concurrent.futures import ThreadPoolExecutor, as_completed
from supabase import create_client
from dotenv import load_dotenv
from pathlib import Path

# Add helpers directory to path
SCRIPT_DIR = Path(__file__).resolve().parent
HELPERS_DIR = SCRIPT_DIR.parent / 'helpers'
sys.path.insert(0, str(HELPERS_DIR))

from duplicate_check_utils import normalize_url, normalize_title, is_duplicate_by_url, is_duplicate_by_title

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv(override=True)

# Supabase í´ë¼ì´ì–¸íŠ¸
supabase = create_client(
    os.getenv('SUPABASE_URL'),
    os.getenv('SUPABASE_SERVICE_ROLE_KEY')
)

# V40 í…Œì´ë¸”ëª…
TABLE_COLLECTED_DATA = "collected_data_v40"

# SNS ë„ë©”ì¸ (URL ê²€ì¦ ì œì™¸)
SNS_DOMAINS = [
    "twitter.com", "x.com", "facebook.com", "instagram.com",
    "youtube.com", "youtu.be", "tiktok.com"
]

# ê²€ì¦ ê²°ê³¼ ì½”ë“œ
VALIDATION_CODES = {
    "VALID": "ìœ íš¨",
    "INVALID_URL": "URL ì ‘ì† ë¶ˆê°€",
    "EMPTY_URL": "URL ë¹„ì–´ìˆìŒ",
    "FAKE_URL": "ê°€ì§œ URL íŒ¨í„´",
    "WRONG_SOURCE_TYPE": "source_type ë¶ˆì¼ì¹˜",
    "MISSING_FIELD": "í•„ìˆ˜ í•„ë“œ ëˆ„ë½",
    "DATE_OUT_OF_RANGE": "ê¸°ê°„ ì´ˆê³¼",
    "DUPLICATE": "ì¤‘ë³µ ë°ì´í„°",
    "NAMESAKE": "ë™ëª…ì´ì¸ ë°ì´í„°",
    "IRRELEVANT_CONTENT": "ë¬´ê´€ ë°ì´í„° (ì •ì¹˜ì¸ ì–¸ê¸‰ ì—†ìŒ)"
}

# Sentiment ë¹„ìœ¨ ìµœì†Œ ê¸°ì¤€ (V40_ê¸°ë³¸ë°©ì¹¨.md ì„¹ì…˜ 6)
# OFFICIAL 10-10-80: negative 10%, positive 10%, free 80%
# PUBLIC 20-20-60: negative 20%, positive 20%, free 60%
MIN_NEGATIVE_PCT_OFFICIAL = 10  # OFFICIAL negative ìµœì†Œ 10%
MIN_POSITIVE_PCT_OFFICIAL = 10  # OFFICIAL positive ìµœì†Œ 10%
MIN_NEGATIVE_PCT_PUBLIC = 20    # PUBLIC negative ìµœì†Œ 20%
MIN_POSITIVE_PCT_PUBLIC = 20    # PUBLIC positive ìµœì†Œ 20%

CATEGORIES_ALL = [
    'expertise', 'leadership', 'vision', 'integrity', 'ethics',
    'accountability', 'transparency', 'communication',
    'responsiveness', 'publicinterest'
]

CATEGORY_KOREAN = {
    'expertise': 'ì „ë¬¸ì„±', 'leadership': 'ë¦¬ë”ì‹­', 'vision': 'ë¹„ì „',
    'integrity': 'ì²­ë ´ì„±', 'ethics': 'ìœ¤ë¦¬ì„±', 'accountability': 'ì±…ì„ê°',
    'transparency': 'íˆ¬ëª…ì„±', 'communication': 'ì†Œí†µëŠ¥ë ¥',
    'responsiveness': 'ëŒ€ì‘ì„±', 'publicinterest': 'ê³µìµì„±'
}


def is_sns_url(url):
    """SNS URL ì—¬ë¶€ í™•ì¸"""
    if not url:
        return False
    domain = urlparse(url).netloc.lower()
    return any(sns in domain for sns in SNS_DOMAINS)


def is_fake_url_pattern(url):
    """ê°€ì§œ URL íŒ¨í„´ ì²´í¬"""
    if not url:
        return False

    fake_patterns = [
        r'example\.com',
        r'test\.com',
        r'placeholder',
        r'\[URL\]',
        r'http://www\.example',
    ]

    for pattern in fake_patterns:
        if re.search(pattern, url, re.IGNORECASE):
            return True

    return False


def check_url_exists(url, timeout=30, max_retries=3):
    """
    URL ì‹¤ì œ ì¡´ì¬ ì—¬ë¶€ í™•ì¸

    ìˆ˜ì • ì‚¬í•­:
    - timeout: 10ì´ˆ â†’ 30ì´ˆ
    - ì¬ì‹œë„: 3íšŒ
    """
    if not url or url.strip() == '':
        return False, "EMPTY_URL"

    # SNSëŠ” ê²€ì¦ ì œì™¸
    if is_sns_url(url):
        return True, "VALID"

    # ê°€ì§œ URL íŒ¨í„´
    if is_fake_url_pattern(url):
        return False, "FAKE_URL"

    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }

    # âš ï¸ URL ê²€ì¦ ë°©ì‹: collect_naver_v40_final.py validate_url()ê³¼ ë™ì¼ (GET stream=True)
    # instructions/2_collect/ì¤‘ë³µë°©ì§€ì „ëµ_ê³µí†µì„¹ì…˜.md Section 4 ì°¸ì¡°
    for attempt in range(max_retries):
        try:
            response = requests.get(url, headers=headers, timeout=timeout,
                                    allow_redirects=True, stream=True)
            response.close()
            if response.status_code < 400:
                return True, "VALID"
            else:
                if attempt < max_retries - 1:
                    time.sleep(2)
                    continue
                return False, "INVALID_URL"

        except requests.exceptions.Timeout:
            if attempt < max_retries - 1:
                time.sleep(2)
                continue
            return False, "INVALID_URL"
        except requests.exceptions.ConnectionError:
            if attempt < max_retries - 1:
                time.sleep(2)
                continue
            return False, "INVALID_URL"
        except Exception:
            if attempt < max_retries - 1:
                time.sleep(2)
                continue
            return False, "INVALID_URL"

    return False, "INVALID_URL"


def validate_required_fields(item):
    """í•„ìˆ˜ í•„ë“œ ê²€ì¦"""
    required = ['title', 'content', 'source_url']

    for field in required:
        if not item.get(field):
            return False, "MISSING_FIELD"

    return True, "VALID"


def validate_date_range(item):
    """
    ê¸°ê°„ ì œí•œ ê²€ì¦ (ìˆ˜ì§‘ì¼ ê¸°ì¤€)

    ìˆ˜ì • ì‚¬í•­:
    - created_at (ìˆ˜ì§‘ì¼) ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°
    - OFFICIAL: ìˆ˜ì§‘ì¼ - 4ë…„
    - PUBLIC: ìˆ˜ì§‘ì¼ - 2ë…„
    """
    data_type = item.get('data_type', 'public').lower()
    pub_date_str = item.get('published_date')
    created_at_str = item.get('created_at')

    if not pub_date_str or not created_at_str:
        return True, "VALID"  # ë‚ ì§œ ì—†ìœ¼ë©´ íŒ¨ìŠ¤

    try:
        # published_date íŒŒì‹±
        if isinstance(pub_date_str, str):
            pub_date = datetime.strptime(pub_date_str[:10], '%Y-%m-%d')
        else:
            pub_date = pub_date_str

        # created_at íŒŒì‹± (ìˆ˜ì§‘ì¼)
        if isinstance(created_at_str, str):
            created_at = datetime.strptime(created_at_str[:10], '%Y-%m-%d')
        else:
            created_at = created_at_str

        # ìˆ˜ì§‘ì¼ ê¸°ì¤€ìœ¼ë¡œ cutoff ê³„ì‚°
        if data_type == 'official':
            cutoff = created_at - timedelta(days=365*4)  # 4ë…„
        else:
            cutoff = created_at - timedelta(days=365*2)  # 2ë…„

        # published_dateê°€ cutoffë³´ë‹¤ ì´ì „ì´ë©´ ìœ„ë°˜
        if pub_date < cutoff:
            return False, "DATE_OUT_OF_RANGE"

        return True, "VALID"

    except:
        return True, "VALID"  # íŒŒì‹± ì‹¤íŒ¨ë©´ íŒ¨ìŠ¤


def check_duplicate(item):
    """ì¤‘ë³µ ê²€ì¦ (ê°„ì†Œí™”)"""
    politician_id = item.get('politician_id')
    collector_ai = item.get('collector_ai')
    url = item.get('source_url', '')

    if not url:
        return True, "VALID"

    # ê°™ì€ AIê°€ ê°™ì€ URL ìˆ˜ì§‘í–ˆëŠ”ì§€ë§Œ ì²´í¬
    try:
        result = supabase.table(TABLE_COLLECTED_DATA)\
            .select('id')\
            .eq('politician_id', politician_id)\
            .eq('collector_ai', collector_ai)\
            .eq('source_url', url)\
            .limit(2)\
            .execute()

        if len(result.data) > 1:
            return False, "DUPLICATE"
    except:
        pass

    return True, "VALID"


# ===== ë™ëª…ì´ì¸ í•„í„°ë§ =====

# Gemini X-rating ë¶„ì„ ê¸°ë°˜ ë™ëª…ì´ì¸ ì œì™¸/í™•ì¸ í‚¤ì›Œë“œ
NAMESAKE_CONFIG = {
    'ì •ì›ì˜¤': {
        'positive': ['ì„±ë™êµ¬', 'êµ¬ì²­ì¥', 'ì„±ìˆ˜ë™', 'ì  íŠ¸ë¦¬í”¼ì¼€ì´ì…˜', 'í•„ìˆ˜ë…¸ë™ì', 'ë§ˆìš©ì„±',
                      'ëª©ë¯¼ê´€', 'ë„ì‹œì¬ìƒ', 'ì™•ì‹­ë¦¬', 'ì‚¼í‘œ', 'GTX', 'ì„ì¢…ì„', 'ì–‘ì²œêµ¬',
                      'ì„œìš¸ì‹œì¥ í›„ë³´', 'ì„œìš¸ì‹œì¥ ì¶œë§ˆ', 'ë¯¼ì„  6ê¸°', 'ë¯¼ì„  7ê¸°', 'ë¯¼ì„  8ê¸°',
                      'ë”ë¶ˆì–´ë¯¼ì£¼ë‹¹'],
        'negative': ['ê¸°ì¬ë¶€', 'ê¸°íšì¬ì •ë¶€', 'ì°¨ê´€', 'ì˜ˆì‚°ì‹¤ì¥', 'ì„±ê³µíšŒëŒ€', 'ì§ì—…í›ˆë ¨',
                      'í•œêµ­ê¸°ìˆ êµìœ¡ëŒ€', 'ì½”ë¦¬ì•„í…', 'ê²½ê¸°ë„êµìœ¡ì²­', 'ê³ ìš©ë…¸ë™ë¶€',
                      'ì˜ˆì‚°ì •ì±…ì²˜', 'ì¡°ì„¸ì •ì±…ê´€'],
    },
    'ì¡°ì€í¬': {
        'positive': ['êµ­íšŒì˜ì›', 'ì„œì´ˆêµ¬', 'êµ­ë¯¼ì˜í˜', 'ì •ë¬´ë¶€ì‹œì¥', 'ì„œì´ˆêµ¬ì²­ì¥',
                      'ì¬ì„ ', 'ì´ì„ ', 'ê¸°ì ì¶œì‹ ', 'ë¬¸í™”ê´€ê´‘ë¹„ì„œê´€', 'ì„œìš¸ì‹œì¥ í›„ë³´',
                      'ì„œìš¸ì‹œì¥ ì¶œë§ˆ'],
        'negative': ['ì…°í”„', 'ìš”ë¦¬ì‚¬', 'ìš”ë¦¬', 'ì •ì‹ ê³¼', 'ì •ì‹ ê±´ê°•ì˜í•™', 'ì¸ì‚¼ì¹´ë¹™',
                      'ì¸ì‚¼', 'ì¹´ë¹™', 'ëª…ì¥', 'ë†ì—…ê¸°ìˆ ì›', 'ì¶©ë¶ë†ì—…', 'ì•½ì‚¬', 'ì•½êµ­',
                      'ì„œìš¸ë””ì§€í„¸ëŒ€', 'ë™ë‘ì²œ', 'í™”ê°€', 'ìº˜ë¦¬ê·¸ë¼í”¼', 'í•œì˜ì‚¬', 'í•œì˜ì›',
                      'ë¯¸ìˆ ', 'ì „ì‹œíšŒ', 'ì¶©ë¶', 'ì¶©ì²­ë¶ë„'],
    },
    'ì˜¤ì¤€í™˜': {
        'positive': ['ê³ ì–‘9', 'ê³ ì–‘ 9', 'ê³ ì–‘ì‹œ ì œ9ì„ ê±°êµ¬', 'êµ­ë¯¼ì˜í˜, ê³ ì–‘',
                      'Cal Poly', 'ë¡œì—´ ì•„ì´ë©•ìŠ¤', 'ëŒ€í†µë ¹ì§ì¸ìˆ˜ìœ„ì›íšŒ ìë¬¸ìœ„ì›',
                      'ê³ ì–‘ì‹œê´€ê´‘í˜‘ì˜íšŒ', 'K-ì»¬ì²˜ë°¸ë¦¬', 'K-ì•„ë ˆë‚˜',
                      'ë„ì‹¬í•­ê³µêµí†µ', 'UAM', 'ê²½ê¸°ë„ì˜íšŒ ë„ì‹œí™˜ê²½ìœ„ì›íšŒ',
                      'ê²½ê¸°ë„ì˜íšŒ ê±´ì„¤êµí†µìœ„ì›íšŒ', 'ê³ ì–‘ê°‘', 'ê³ ì–‘ì‹œì¥'],
        'negative': ['í•˜ë‚¨1', 'í•˜ë‚¨ 1', 'ìš¸ì‚°', 'ë‚¨êµ¬ì˜íšŒ', 'ëŒ€êµ¬ê´‘ì—­ì‹œì˜íšŒ', 'ëŒ€êµ¬ì‹œì˜íšŒ',
                      'ê²½ë¶ëŒ€', 'í•œì–‘ëŒ€ í–‰ì •', 'ì¤‘ì•™ëŒ€ í–‰ì •', 'ê²½ê¸°ëŒ€ í–‰ì •', 'ê²½í¬ëŒ€',
                      'êµ­ì œì‚¬ì´ë²„ëŒ€', 'ì˜¬í´ë¦°í•œë°ì´', 'ì´ì‚¬ì²­ì†Œ', 'ë¯¸í™”ì›', 'ê¸°ìˆ ì‚¬',
                      'ì¶•êµ¬í•™ê³¼', 'í˜¸ë‚¨ëŒ€', 'ì¶©ë‚¨í–¥êµì¬ë‹¨', 'êµ­ë¯¼ìƒí™œì²´ìœ¡íšŒ',
                      'êµ­ë¯¼ì˜ë‹¹ ì°½ë‹¹', 'ìš©ì¸ì •', 'ìš©ì¸ì‹ ë¬¸', 'ìš©ì¸ ë°˜ë„ì²´',
                      'êµ¬ë¦¬ì‹œ', 'ì†¡íŒŒ', 'ë™ì‘êµ¬ì˜íšŒ', 'ì˜¤ì„¸í›ˆê³¼', 'ë‹¨ì§', 'ë¹„ì„œì‹¤ì¥',
                      'ê³ ì–‘ì‹œì¥ ë¹„ì„œ', 'æ•… ì˜¤ì¤€í™˜ ì†Œë ¹', 'ê²½ë¶ëŒ€í•™êµ ëŒ€í•™ì›',
                      'ëŒ€êµ¬ê²½ë¶ì—°êµ¬ì›', 'ëŒ€êµ¬ëŒ€í•™êµ ê²¸ì„', 'ëŒ€êµ¬ë¬¸í™”ì˜ˆìˆ ',
                      'ëŒ€êµ¬í–‰ì • ì‹¬í¬ì§€ì—„', 'ëŒ€êµ¬í˜• ìŠ¤ë§ˆíŠ¸ì‹œí‹°',
                      'ê²½ê¸°ëŒ€í•™êµ í–‰ì •ëŒ€í•™ì›', 'WowColl', 'ì¸ë°”ì´íŠ¸',
                      'ì±„ìš©ì •ë³´', 'ë¯¸í™”ì› ëª¨ì§‘', 'ê°ì‚¬ì¸ì˜ ì‚°ì—…ì „ë¬¸ì„±', 'í•™ìˆ ë…¼ë¬¸'],
    },
}


def load_namesake_config(politician_name):
    """
    ì •ì¹˜ì¸ MD íŒŒì¼ + NAMESAKE_CONFIGì—ì„œ ë™ëª…ì´ì¸ í•„í„°ë§ ì„¤ì • ë¡œë“œ

    Returns:
        tuple: (positive_keywords, negative_keywords)
    """
    V40_DIR = SCRIPT_DIR.parent.parent  # scripts/core â†’ V40
    pol_file = V40_DIR / 'instructions' / '1_politicians' / f'{politician_name}.md'

    positive = set()
    negative = set()

    # 1. Hardcoded config ë¡œë“œ
    if politician_name in NAMESAKE_CONFIG:
        positive.update(NAMESAKE_CONFIG[politician_name]['positive'])
        negative.update(NAMESAKE_CONFIG[politician_name]['negative'])

    # 2. MD íŒŒì¼ì—ì„œ ì¶”ê°€ í‚¤ì›Œë“œ ì¶”ì¶œ
    if pol_file.exists():
        with open(pol_file, 'r', encoding='utf-8') as f:
            content = f.read()

        for line in content.split('\n'):
            # í˜„ ì§ì±…ì—ì„œ positive í‚¤ì›Œë“œ ì¶”ì¶œ
            if 'í˜„ ì§ì±…' in line and '|' in line:
                parts = line.split('|')
                if len(parts) >= 3:
                    pos_text = parts[-2].strip().replace('**', '')
                    for term in re.findall(r'[ê°€-í£]+(?:êµ¬|ì‹œ|ì¥|ì›)', pos_text):
                        if len(term) >= 2:
                            positive.add(term)

            # ì†Œì† ì •ë‹¹ì—ì„œ positive í‚¤ì›Œë“œ ì¶”ì¶œ
            if 'ì†Œì† ì •ë‹¹' in line and '|' in line:
                parts = line.split('|')
                if len(parts) >= 3:
                    party = parts[-2].strip().replace('**', '')
                    if party and len(party) >= 2:
                        positive.add(party)

    return list(positive), list(negative)


def check_namesake(item, positive_kw, negative_kw):
    """
    ë™ëª…ì´ì¸ ë°ì´í„° ê²€ì¦

    Logic:
    - negative í‚¤ì›Œë“œ ë°œê²¬ AND positive í‚¤ì›Œë“œ ë¯¸ë°œê²¬ â†’ NAMESAKE
    - negative í‚¤ì›Œë“œ ë°œê²¬ AND positive í‚¤ì›Œë“œ ë°œê²¬ â†’ VALID (ì˜¬ë°”ë¥¸ ì •ì¹˜ì¸)
    - negative í‚¤ì›Œë“œ ë¯¸ë°œê²¬ â†’ VALID

    Args:
        item: collected data item
        positive_kw: ì˜¬ë°”ë¥¸ ì •ì¹˜ì¸ ì‹ë³„ í‚¤ì›Œë“œ
        negative_kw: ë™ëª…ì´ì¸ ì‹ë³„ í‚¤ì›Œë“œ

    Returns:
        tuple: (is_valid, code)
    """
    if not negative_kw:
        return True, "VALID"

    title = (item.get('title') or '')
    content = (item.get('content') or '')
    text = f"{title} {content}"

    # negative í‚¤ì›Œë“œ ê²€ìƒ‰
    found_negative = [kw for kw in negative_kw if kw in text]
    if not found_negative:
        return True, "VALID"

    # negative ë°œê²¬ â†’ positive í™•ì¸
    found_positive = [kw for kw in positive_kw if kw in text]
    if found_positive:
        return True, "VALID"  # ì˜¬ë°”ë¥¸ ì •ì¹˜ì¸ í™•ì¸ë¨

    # negativeë§Œ ë°œê²¬, positive ì—†ìŒ â†’ ë™ëª…ì´ì¸
    return False, "NAMESAKE"


def check_content_relevance(item, politician_name, positive_kw):
    """
    ì½˜í…ì¸  ê¸°ë°˜ ê´€ë ¨ì„± í•„í„° (NEW)

    ì œëª©/ë‚´ìš©ì— ì •ì¹˜ì¸ ì´ë¦„ì´ë‚˜ ê´€ë ¨ í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
    - í¬í•¨ë˜ë©´ ìœ íš¨
    - í¬í•¨ë˜ì§€ ì•Šìœ¼ë©´ ë¬´ê´€ ë°ì´í„°ë¡œ ì œì™¸

    Args:
        item: collected data item
        politician_name: ì •ì¹˜ì¸ ì´ë¦„
        positive_kw: ê´€ë ¨ í‚¤ì›Œë“œ ëª©ë¡

    Returns:
        tuple: (is_valid, code)
    """
    title = (item.get('title') or '').lower()
    content = (item.get('content') or '').lower()
    text = f"{title} {content}"

    # ì •ì¹˜ì¸ ì´ë¦„ í¬í•¨ ì—¬ë¶€
    if politician_name.lower() in text:
        return True, "VALID"

    # ê´€ë ¨ í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€
    for kw in positive_kw:
        if kw.lower() in text:
            return True, "VALID"

    # ì–´ëŠ ê²ƒë„ í¬í•¨ë˜ì§€ ì•ŠìŒ â†’ ë¬´ê´€ ë°ì´í„°
    return False, "IRRELEVANT_CONTENT"


def validate_item_fixed(item):
    """
    ë‹¨ì¼ í•­ëª© ê²€ì¦ (ìˆ˜ì • ë²„ì „)

    ìˆ˜ì • ì‚¬í•­:
    1. validate_event_date ì œê±°
    2. URL ê²€ì¦ ì™„í™” (timeout 30ì´ˆ, 3íšŒ ì¬ì‹œë„)
    3. ê¸°ê°„ ê²€ì¦ë§Œ (event_year ë¬´ì‹œ)
    """
    # 1. í•„ìˆ˜ í•„ë“œ
    valid, code = validate_required_fields(item)
    if not valid:
        return False, code

    # 2. URL ì¡´ì¬ (SNSëŠ” ì œì™¸)
    url = item.get('source_url', '')
    if url and not is_sns_url(url):
        valid, code = check_url_exists(url, timeout=30, max_retries=3)
        if not valid:
            return False, code

    # 3. ê¸°ê°„ ê²€ì¦ (published_dateë§Œ)
    valid, code = validate_date_range(item)
    if not valid:
        return False, code

    # 4. ì¤‘ë³µ ê²€ì¦
    valid, code = check_duplicate(item)
    if not valid:
        return False, code

    return True, "VALID"


def check_sentiment_ratios(valid_items):
    """
    ìœ íš¨ ë°ì´í„°ì˜ sentiment/data_type ë¹„ìœ¨ ê²€ì¦

    V40 ê¸°ë³¸ë°©ì¹¨ ì„¹ì…˜ 6 ê·œì¹™:
    - OFFICIAL: negative 10%, positive 10%, free 80%
    - PUBLIC: negative 20%, positive 20%, free 60%

    Returns:
        list: ìœ„ë°˜ í•­ëª© ë¦¬ìŠ¤íŠ¸
    """
    from collections import defaultdict

    # ì¹´í…Œê³ ë¦¬ Ã— data_type Ã— sentiment ì§‘ê³„
    dist = defaultdict(lambda: defaultdict(lambda: defaultdict(int)))
    for item in valid_items:
        cat = (item.get('category') or '').lower()
        dtype = (item.get('data_type') or '').lower()
        sent = (item.get('sentiment') or 'free').lower()
        if cat and dtype:
            dist[cat][dtype][sent] += 1

    violations = []

    print(f"\n{'='*60}")
    print(f"[Sentiment ë¹„ìœ¨ ê²€ì¦] OFFICIAL 10-10-80 / PUBLIC 20-20-60")
    print(f"{'='*60}")

    for cat in CATEGORIES_ALL:
        cat_kr = CATEGORY_KOREAN.get(cat, cat)
        cat_violations = []

        for dtype, min_neg, min_pos in [
            ('official', MIN_NEGATIVE_PCT_OFFICIAL, MIN_POSITIVE_PCT_OFFICIAL),
            ('public', MIN_NEGATIVE_PCT_PUBLIC, MIN_POSITIVE_PCT_PUBLIC),
        ]:
            counts = dist[cat][dtype]
            total = sum(counts.values())
            if total == 0:
                continue

            neg_count = counts.get('negative', 0)
            pos_count = counts.get('positive', 0)
            neg_pct = neg_count / total * 100
            pos_pct = pos_count / total * 100

            dtype_upper = dtype.upper()

            if neg_pct < min_neg:
                msg = (f"  {cat_kr} {dtype_upper}: negative {neg_count}/{total} "
                       f"({neg_pct:.0f}%) < ìµœì†Œ {min_neg}%")
                cat_violations.append(msg)
                violations.append(msg.strip())

            if pos_pct < min_pos:
                msg = (f"  {cat_kr} {dtype_upper}: positive {pos_count}/{total} "
                       f"({pos_pct:.0f}%) < ìµœì†Œ {min_pos}%")
                cat_violations.append(msg)
                violations.append(msg.strip())

        if cat_violations:
            for v in cat_violations:
                print(f"  âš ï¸{v}")
        else:
            # ê°„ëµ ì¶œë ¥
            off_total = sum(dist[cat]['official'].values())
            pub_total = sum(dist[cat]['public'].values())
            if off_total > 0 or pub_total > 0:
                print(f"  âœ… {cat_kr}: OK (OFF {off_total}ê°œ, PUB {pub_total}ê°œ)")

    if violations:
        print(f"\n  âš ï¸ Sentiment ë¹„ìœ¨ ìœ„ë°˜: {len(violations)}ê±´")
        print(f"  âš ï¸ ì¬ìˆ˜ì§‘ìœ¼ë¡œ ë¶€ì¡±í•œ sentiment ë³´ì¶© í•„ìš”")
    else:
        print(f"\n  âœ… ëª¨ë“  ì¹´í…Œê³ ë¦¬ Sentiment ë¹„ìœ¨ ì¶©ì¡±")

    return violations


def validate_collected_data_fixed(politician_id, politician_name, dry_run=True):
    """
    ìˆ˜ì§‘ ë°ì´í„° ê²€ì¦ (ìˆ˜ì • ë²„ì „)

    dry_run=True: ë¡œê·¸ë§Œ ê¸°ë¡, ì‚­ì œ ì•ˆ í•¨ (ê¸°ë³¸ê°’)
    dry_run=False: ì‹¤ì œ ì‚­ì œ
    """
    print(f"\n{'='*60}")
    print(f"[ê²€ì¦] {politician_name} ({politician_id})")
    if dry_run:
        print(f"[ëª¨ë“œ] DRY RUN - ì‚­ì œí•˜ì§€ ì•ŠìŒ, ë¡œê·¸ë§Œ ê¸°ë¡")
    else:
        print(f"[ëª¨ë“œ] ì‹¤ì œ ì‚­ì œ ìˆ˜í–‰")
    print(f"{'='*60}")

    # ë°ì´í„° ì¡°íšŒ (í˜ì´ì§€ë„¤ì´ì…˜ - Supabase 1,000í–‰ ì œí•œ ëŒ€ì‘)
    items = []
    offset = 0
    page_size = 1000
    while True:
        result = supabase.table(TABLE_COLLECTED_DATA)\
            .select('*')\
            .eq('politician_id', politician_id)\
            .range(offset, offset + page_size - 1)\
            .execute()
        batch = result.data or []
        items.extend(batch)
        if len(batch) < page_size:
            break
        offset += page_size
    print(f"ì´ {len(items)}ê°œ í•­ëª© ê²€ì¦ ì‹œì‘...")

    # ë™ëª…ì´ì¸ í•„í„°ë§ ì„¤ì • ë¡œë“œ
    positive_kw, negative_kw = load_namesake_config(politician_name)
    namesake_enabled = len(negative_kw) > 0
    if namesake_enabled:
        print(f"  ë™ëª…ì´ì¸ í•„í„°ë§ í™œì„±í™”: ì œì™¸ í‚¤ì›Œë“œ {len(negative_kw)}ê°œ, í™•ì¸ í‚¤ì›Œë“œ {len(positive_kw)}ê°œ")

    valid_count = 0
    valid_items = []
    invalid_items = []

    for i, item in enumerate(items):
        valid, code = validate_item_fixed(item)

        # ë™ëª…ì´ì¸ ê²€ì¦ (ê¸°ë³¸ ê²€ì¦ í†µê³¼ í›„)
        if valid and namesake_enabled:
            valid, code = check_namesake(item, positive_kw, negative_kw)

        # ì½˜í…ì¸  ê¸°ë°˜ í•„í„°: ì •ì¹˜ì¸ ì´ë¦„/ê´€ë ¨ í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€ (NEW)
        if valid:
            valid, code = check_content_relevance(item, politician_name, positive_kw)

        if valid:
            valid_count += 1
            valid_items.append(item)
        else:
            invalid_items.append({
                'id': item.get('id'),
                'title': item.get('title', '')[:50],
                'code': code,
                'collector_ai': item.get('collector_ai'),
                'url': item.get('source_url', '')[:80]
            })

        if (i + 1) % 100 == 0:
            print(f"  ì§„í–‰: {i+1}/{len(items)} ({valid_count}ê°œ ìœ íš¨)")

    invalid_count = len(invalid_items)

    print(f"\nê²€ì¦ ì™„ë£Œ:")
    print(f"  [OK] ìœ íš¨: {valid_count}ê°œ ({valid_count/len(items)*100:.1f}%)")
    print(f"  [INVALID] ë¬´íš¨: {invalid_count}ê°œ ({invalid_count/len(items)*100:.1f}%)")

    # ë¬´íš¨ í•­ëª© ìƒì„¸
    if invalid_items:
        print(f"\në¬´íš¨ í•­ëª© ìƒì„¸:")
        code_counts = {}
        for item in invalid_items:
            code = item['code']
            code_counts[code] = code_counts.get(code, 0) + 1

        for code, count in sorted(code_counts.items(), key=lambda x: -x[1]):
            print(f"  - {VALIDATION_CODES.get(code, code)}: {count}ê°œ")

    # DRY RUN ëª¨ë“œ
    if dry_run:
        print(f"\nğŸ’¡ DRY RUN ëª¨ë“œ: ì‚­ì œí•˜ì§€ ì•ŠìŒ")
        print(f"   ì‹¤ì œ ì‚­ì œí•˜ë ¤ë©´ --no-dry-run ì˜µì…˜ ì‚¬ìš©")
    else:
        # ì‹¤ì œ ì‚­ì œ
        deleted = 0
        for item in invalid_items:
            try:
                supabase.table(TABLE_COLLECTED_DATA)\
                    .delete()\
                    .eq('id', item['id'])\
                    .execute()
                deleted += 1
            except:
                pass
        print(f"\nğŸ—‘ï¸ {deleted}ê°œ ë¬´íš¨ í•­ëª© ì‚­ì œ")

    # ===== Sentiment/DataType ë¹„ìœ¨ ê²€ì¦ =====
    sentiment_violations = check_sentiment_ratios(valid_items)

    return {
        'total': len(items),
        'valid': valid_count,
        'invalid': invalid_count,
        'invalid_rate': invalid_count / len(items) * 100 if len(items) > 0 else 0,
        'sentiment_violations': sentiment_violations
    }


def main():
    parser = argparse.ArgumentParser(description='V40 ê²€ì¦ (ìˆ˜ì • ë²„ì „)')
    parser.add_argument('--politician_id', required=True)
    parser.add_argument('--politician_name', required=True)
    parser.add_argument('--no-dry-run', action='store_true', help='ì‹¤ì œ ì‚­ì œ ìˆ˜í–‰ (ê¸°ë³¸: DRY RUN)')

    args = parser.parse_args()

    dry_run = not args.no_dry_run

    result = validate_collected_data_fixed(
        args.politician_id,
        args.politician_name,
        dry_run=dry_run
    )

    print(f"\n{'='*60}")
    print(f"ê²€ì¦ ê²°ê³¼ ìš”ì•½:")
    print(f"  ì „ì²´: {result['total']}ê°œ")
    print(f"  ìœ íš¨: {result['valid']}ê°œ")
    print(f"  ë¬´íš¨: {result['invalid']}ê°œ")
    print(f"  ë¬´íš¨ìœ¨: {result['invalid_rate']:.1f}%")
    sv = result.get('sentiment_violations', [])
    if sv:
        print(f"  Sentiment ë¹„ìœ¨ ìœ„ë°˜: {len(sv)}ê±´")
    else:
        print(f"  Sentiment ë¹„ìœ¨: ëª¨ë‘ ì¶©ì¡±")
    print(f"{'='*60}")

    # Phase 2 ì™„ë£Œ ê¸°ë¡ (ì‹¤ì œ ì‚­ì œ ëª¨ë“œì¼ ë•Œë§Œ)
    if not dry_run:
        try:
            from phase_tracker import mark_phase_done
            details = f"ìœ íš¨ {result['valid']}ê°œ, ë¬´íš¨ {result['invalid']}ê°œ ì‚­ì œ"
            if sv:
                details += f", sentiment ìœ„ë°˜ {len(sv)}ê±´"
            mark_phase_done(args.politician_id, '2', details, args.politician_name)
            print(f"\n  Phase 2 ì™„ë£Œ ê¸°ë¡ë¨")
        except ImportError:
            pass  # phase_tracker ì—†ì–´ë„ ê¸°ì¡´ ë™ì‘ ìœ ì§€


if __name__ == "__main__":
    main()

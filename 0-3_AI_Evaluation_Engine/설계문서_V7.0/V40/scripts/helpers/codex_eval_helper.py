# -*- coding: utf-8 -*-
"""
V40 OpenAI Codex CLI ë°°ì¹˜ í‰ê°€ í—¬í¼ (ìµœì í™” ë²„ì „)

Codex CLIë¥¼ ì‚¬ìš©í•˜ì—¬ ChatGPT í‰ê°€ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
ë°°ì¹˜ í‰ê°€ ë°©ì‹ìœ¼ë¡œ ì„±ëŠ¥ ìµœì í™” (Geminiì™€ ë™ì¼í•œ íŒ¨í„´)

ëª¨ë¸: ChatGPT gpt-5.1-codex-mini
ë¹„ìš©: $0.05 (input) / $0.40 (output) per 1M tokens
      - ChatGPT Plus êµ¬ë… ë°©ì‹ (ë³„ë„ API ìš”ê¸ˆ X, í† í° ìš”ê¸ˆë§Œ ë°œìƒ)
      - gpt-5.1 ëŒ€ë¹„ 96% ì €ë ´ (cost optimization)
ë°°ì¹˜ í¬ê¸°: 25ê°œ

ê°œì„  ì‚¬í•­:
    - ë°°ì¹˜ í‰ê°€: 25ê°œ â†’ 1ë²ˆ Codex CLI í˜¸ì¶œ (ì´ì „: 25ë²ˆ)
    - ë°°ì¹˜ ì €ì¥: 1ë²ˆ INSERT (ì´ì „: 25ë²ˆ)
    - common_eval_saver.py ì‚¬ìš© (Geminiì™€ ë™ì¼)
    - ìë™ ì¬ì‹œë„: Foreign key ì˜¤ë¥˜ ì‹œ ë°°ì¹˜ í¬ê¸° 5ê°œë¡œ ìë™ ì¬ì‹œë„

ì‚¬ìš©ë²•:
    python codex_eval_helper.py --politician_id=d0a5d6e1 --politician_name="ì¡°ì€í¬" --category=expertise
"""

import os
import sys
import json
import subprocess
import argparse
import html
from pathlib import Path
from datetime import datetime
from supabase import create_client
from dotenv import load_dotenv

# ê²½ë¡œ ì„¤ì •
SCRIPT_DIR = Path(__file__).resolve().parent
sys.path.insert(0, str(SCRIPT_DIR))

# ê³µí†µ ì €ì¥ í•¨ìˆ˜ import
from common_eval_saver import save_evaluations_batch_upsert

# UTF-8 ì¶œë ¥ ì„¤ì •
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv(override=True)

# Supabase í´ë¼ì´ì–¸íŠ¸
supabase = create_client(
    os.getenv('SUPABASE_URL'),
    os.getenv('SUPABASE_SERVICE_ROLE_KEY')
)

# í…Œì´ë¸”ëª…
TABLE_COLLECTED = "collected_data_v40"
TABLE_EVALUATIONS = "evaluations_v40"

# ì¹´í…Œê³ ë¦¬ ì •ì˜
CATEGORY_MAP = {
    "expertise": "ì „ë¬¸ì„±",
    "leadership": "ë¦¬ë”ì‹­",
    "vision": "ë¹„ì „",
    "integrity": "ì²­ë ´ì„±",
    "ethics": "ìœ¤ë¦¬ì„±",
    "accountability": "ì±…ì„ê°",
    "transparency": "íˆ¬ëª…ì„±",
    "communication": "ì†Œí†µëŠ¥ë ¥",
    "responsiveness": "ëŒ€ì‘ì„±",
    "publicinterest": "ê³µìµì„±"
}

# V40 ë“±ê¸‰ ì²´ê³„
VALID_RATINGS = ['+4', '+3', '+2', '+1', '-1', '-2', '-3', '-4', 'X']


def get_unevaluated_data(politician_id, category):
    """
    ë¯¸í‰ê°€ ë°ì´í„° ì¡°íšŒ (ìµœì í™”: ì´ë¯¸ í‰ê°€ëœ ë°ì´í„° ì‚¬ì „ í•„í„°ë§)

    Returns:
        ë¯¸í‰ê°€ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
    """
    cat_lower = category.lower()

    # 1. ì´ë¯¸ í‰ê°€ëœ collected_data_id
    eval_result = supabase.table(TABLE_EVALUATIONS)\
        .select('collected_data_id')\
        .eq('politician_id', politician_id)\
        .eq('evaluator_ai', 'ChatGPT')\
        .eq('category', cat_lower)\
        .execute()
    evaluated_ids = {item['collected_data_id'] for item in (eval_result.data or []) if item.get('collected_data_id')}

    # 2. ì „ì²´ ìˆ˜ì§‘ ë°ì´í„°
    collected_result = supabase.table(TABLE_COLLECTED)\
        .select('*')\
        .eq('politician_id', politician_id)\
        .eq('category', cat_lower)\
        .execute()

    all_items = collected_result.data or []

    # 3. ë¯¸í‰ê°€ í•„í„°ë§
    unevaluated = [item for item in all_items if item['id'] not in evaluated_ids]

    total = len(all_items)
    already_evaluated = len(evaluated_ids)
    to_evaluate = len(unevaluated)

    print(f'ğŸ“Š ì´ ë°ì´í„°: {total}ê°œ, ì´ë¯¸ í‰ê°€: {already_evaluated}ê°œ, í‰ê°€í•  ë°ì´í„°: {to_evaluate}ê°œ')

    return unevaluated


def evaluate_batch_with_codex(politician_name, category, data_items):
    """
    Codex CLIë¡œ ë°°ì¹˜ í‰ê°€ (Geminiì™€ ë™ì¼í•œ íŒ¨í„´)

    Args:
        politician_name: ì •ì¹˜ì¸ ì´ë¦„
        category: ì¹´í…Œê³ ë¦¬
        data_items: í‰ê°€í•  ë°ì´í„° ë¦¬ìŠ¤íŠ¸ (ë°°ì¹˜)

    Returns:
        í‰ê°€ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ [{"id": "...", "rating": "...", "rationale": "..."}, ...]
    """
    cat_kor = CATEGORY_MAP.get(category.lower(), category)

    # ë°°ì¹˜ ë°ì´í„° JSON í˜•ì‹ ì¤€ë¹„
    data_json = []
    for item in data_items:
        data_json.append({
            "id": item.get('id'),
            "title": html.unescape(item.get('title', '')),
            "content": html.unescape(item.get('content', ''))[:500],
            "source": html.unescape(item.get('source_name', '')),
            "date": item.get('published_date', '')
        })

    # ë°°ì¹˜ í‰ê°€ í”„ë¡¬í”„íŠ¸ (Geminiì™€ ìœ ì‚¬)
    prompt = f"""ì •ì¹˜ì¸ {politician_name}ì˜ {cat_kor} ê´€ë ¨ ë°ì´í„°ë¥¼ í‰ê°€í•˜ì„¸ìš”.

í‰ê°€ ê¸°ì¤€:
- +4 (íƒì›”): ëª¨ë²” ì‚¬ë¡€, ë²• ì œì •, ëŒ€í†µë ¹ í‘œì°½ ìˆ˜ì¤€
- +3 (ìš°ìˆ˜): êµ¬ì²´ì  ì„±ê³¼, ë‹¤ìˆ˜ ë²•ì•ˆ í†µê³¼
- +2 (ì–‘í˜¸): ì¼ë°˜ì  ê¸ì • í™œë™, ë²•ì•ˆ ë°œì˜
- +1 (ë³´í†µ): ë…¸ë ¥, ì¶œì„, ê¸°ë³¸ ì—­ëŸ‰
- -1 (ë¯¸í¡): ë¹„íŒ ë°›ìŒ, ì§€ì ë‹¹í•¨
- -2 (ë¶€ì¡±): ë…¼ë€, ì˜í˜¹ ì œê¸°
- -3 (ì‹¬ê°): ìˆ˜ì‚¬, ì¡°ì‚¬ ì°©ìˆ˜
- -4 (ìµœì•…): ìœ ì£„ í™•ì •, ë²•ì  ì²˜ë²Œ
- X (ì œì™¸): ë™ëª…ì´ì¸, 10ë…„ ì´ìƒ ê³¼ê±°, ê°€ì§œ ì •ë³´

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:

```json
{{
  "evaluations": [
    {{
      "id": "ë°ì´í„° ID",
      "rating": "+3",
      "rationale": "í‰ê°€ ê·¼ê±° (í•œêµ­ì–´ 1ë¬¸ì¥)"
    }}
  ]
}}
```

í‰ê°€í•  ë°ì´í„°:

{json.dumps(data_json, ensure_ascii=False, indent=2)}

ê° ë°ì´í„°ì— ëŒ€í•´ ratingê³¼ rationaleì„ ì œê³µí•˜ì„¸ìš”."""

    try:
        # Codex CLI ì‹¤í–‰ (ë°°ì¹˜ í‰ê°€)
        # gpt-5.1-codex-mini: ~1 credit per message (ê°€ì¥ ì €ë ´)
        result = subprocess.run(
            ['codex', 'exec', '-m', 'gpt-5.1-codex-mini'],
            input=prompt,
            capture_output=True,
            text=True,
            encoding='utf-8',
            timeout=300,  # 5ë¶„ (ë°°ì¹˜ í‰ê°€ëŠ” ì‹œê°„ì´ ë” ê±¸ë¦¼)
            shell=True
        )

        # Codex CLIëŠ” verbose ì¶œë ¥ì„ stderrë¡œ ë³´ëƒ„ (ì •ìƒ ë™ì‘)
        # returncodeì™€ stdoutë§Œ í™•ì¸
        if result.returncode != 0 and not result.stdout:
            print(f"âŒ Codex ì‹¤í–‰ ì˜¤ë¥˜: {result.stderr[:200]}", file=sys.stderr)
            return []

        # ì¶œë ¥ì—ì„œ JSON ì¶”ì¶œ (stdout ìš°ì„ , ì—†ìœ¼ë©´ stderr í™•ì¸)
        output = result.stdout if result.stdout else result.stderr
        if not output:
            print(f"âš ï¸ Codex ì¶œë ¥ ì—†ìŒ", file=sys.stderr)
            return []

        # Codexì˜ verbose í—¤ë” ì œê±° (assistant\n ì´í›„ë¶€í„°ê°€ ì‹¤ì œ ì‘ë‹µ)
        if 'assistant\n' in output:
            output = output.split('assistant\n', 1)[1]

        # JSON íŒŒì‹± (Geminiì™€ ë™ì¼í•œ ë¡œì§)
        try:
            # JSON ë¸”ë¡ ì¶”ì¶œ
            if '```json' in output:
                start = output.find('```json') + 7
                end = output.find('```', start)
                json_str = output[start:end].strip()
            elif '```' in output:
                start = output.find('```') + 3
                end = output.find('```', start)
                json_str = output[start:end].strip()
            else:
                # JSON ë¸”ë¡ ì—†ìœ¼ë©´ ì „ì²´ì—ì„œ { } ì°¾ê¸°
                json_str = output.strip()
                if '{' in json_str and '}' in json_str:
                    start_idx = json_str.find('{')
                    end_idx = json_str.rfind('}') + 1
                    json_str = json_str[start_idx:end_idx]

            data = json.loads(json_str)
            evaluations = data.get('evaluations', [])

            # ê° í‰ê°€ ê²€ì¦ ë° ì •ê·œí™”
            valid_evaluations = []
            for eval_item in evaluations:
                rating = str(eval_item.get('rating', '')).strip().upper()

                # ë“±ê¸‰ ì •ê·œí™” (4 â†’ +4)
                if rating in ['4', '3', '2', '1']:
                    rating = '+' + rating

                if rating not in VALID_RATINGS:
                    print(f"âš ï¸ ì˜ëª»ëœ ë“±ê¸‰: {rating}, Xë¡œ ë³€ê²½", file=sys.stderr)
                    rating = 'X'

                valid_evaluations.append({
                    "id": eval_item.get('id'),
                    "rating": rating,
                    "rationale": eval_item.get('rationale', eval_item.get('reasoning', ''))[:1000]
                })

            print(f"âœ… Codex í‰ê°€ ì™„ë£Œ: {len(valid_evaluations)}ê°œ")
            return valid_evaluations

        except json.JSONDecodeError as e:
            print(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {e}", file=sys.stderr)
            print(f"ì¶œë ¥: {output[:500]}...", file=sys.stderr)
            return []

    except subprocess.TimeoutExpired:
        print(f"â±ï¸ íƒ€ì„ì•„ì›ƒ (5ë¶„ ì´ˆê³¼)", file=sys.stderr)
        return []
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {e}", file=sys.stderr)
        return []


def main():
    parser = argparse.ArgumentParser(description='V40 Codex CLI ë°°ì¹˜ í‰ê°€ (ìµœì í™”)')
    parser.add_argument('--politician_id', required=True, help='ì •ì¹˜ì¸ ID')
    parser.add_argument('--politician_name', required=True, help='ì •ì¹˜ì¸ ì´ë¦„')
    parser.add_argument('--category', required=True, help='ì¹´í…Œê³ ë¦¬')
    parser.add_argument('--batch_size', type=int, default=25, help='ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸ 25)')

    args = parser.parse_args()

    print('=' * 80)
    print(f'Codex CLI ë°°ì¹˜ í‰ê°€: {args.politician_name} - {args.category}')
    print('=' * 80)
    print()

    # ë¯¸í‰ê°€ ë°ì´í„° ì¡°íšŒ
    unevaluated = get_unevaluated_data(args.politician_id, args.category)

    if not unevaluated:
        print('âœ… ëª¨ë“  ë°ì´í„° í‰ê°€ ì™„ë£Œ')
        return

    print(f'ë°°ì¹˜ í¬ê¸°: {args.batch_size}ê°œ')
    print()

    # ë°°ì¹˜ ì²˜ë¦¬
    total_saved = 0
    total_batches = (len(unevaluated) + args.batch_size - 1) // args.batch_size

    for batch_idx in range(0, len(unevaluated), args.batch_size):
        batch_data = unevaluated[batch_idx:batch_idx + args.batch_size]
        batch_num = (batch_idx // args.batch_size) + 1

        print(f'[ë°°ì¹˜ {batch_num}/{total_batches}] {len(batch_data)}ê°œ í‰ê°€ ì¤‘...')

        # Codexë¡œ ë°°ì¹˜ í‰ê°€
        evaluations = evaluate_batch_with_codex(args.politician_name, args.category, batch_data)

        if not evaluations:
            print(f'âŒ ë°°ì¹˜ {batch_num} í‰ê°€ ì‹¤íŒ¨')
            continue

        # ë°°ì¹˜ ì €ì¥ (common_eval_saver ì‚¬ìš©)
        result = save_evaluations_batch_upsert(
            politician_id=args.politician_id,
            politician_name=args.politician_name,
            category=args.category,
            evaluator_ai='ChatGPT',
            evaluations=evaluations,
            verbose=True
        )

        # Foreign key constraint ì˜¤ë¥˜ ë°œìƒ ì‹œ ë°°ì¹˜ í¬ê¸° 5ê°œë¡œ ì¬ì‹œë„
        if result.get('error') and 'foreign key constraint' in str(result.get('error', '')).lower():
            print(f'âš ï¸ Foreign key constraint ì˜¤ë¥˜ ë°œìƒ. ë°°ì¹˜ í¬ê¸°ë¥¼ 5ê°œë¡œ ì¤„ì—¬ì„œ ì¬ì‹œë„...')
            retry_saved = 0
            retry_size = 5

            for retry_idx in range(0, len(evaluations), retry_size):
                retry_batch = evaluations[retry_idx:retry_idx + retry_size]
                retry_num = (retry_idx // retry_size) + 1
                retry_total = (len(evaluations) + retry_size - 1) // retry_size

                print(f'  [ì¬ì‹œë„ {retry_num}/{retry_total}] {len(retry_batch)}ê°œ ì €ì¥ ì¤‘...')

                retry_result = save_evaluations_batch_upsert(
                    politician_id=args.politician_id,
                    politician_name=args.politician_name,
                    category=args.category,
                    evaluator_ai='ChatGPT',
                    evaluations=retry_batch,
                    verbose=False
                )

                retry_saved += retry_result['saved']

            print(f'âœ… ì¬ì‹œë„ ì™„ë£Œ: {retry_saved}/{len(evaluations)}ê°œ ì €ì¥')
            total_saved += retry_saved
            print(f'[ë°°ì¹˜ {batch_num}/{total_batches}] ìµœì¢…: {retry_saved}/{len(evaluations)}ê°œ')
        else:
            total_saved += result['saved']
            print(f'[ë°°ì¹˜ {batch_num}/{total_batches}] ì €ì¥: {result["saved"]}/{result["total"]}ê°œ')

        print()

    print('=' * 80)
    print(f'âœ… ì „ì²´ ì™„ë£Œ: {total_saved}/{len(unevaluated)}ê°œ ì €ì¥')
    print('=' * 80)


if __name__ == '__main__':
    main()

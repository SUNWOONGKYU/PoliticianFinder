#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import sys
import io
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

"""
Naver Webkr API ê¸´ê¸‰ ìˆ˜ì§‘ (ì›¹ ë¬¸ì„œ ì „ë¬¸)
======================================

ëª©í‘œ:
- integrity, ethics ë“± ë¶€ì¡±í•œ ì¹´í…Œê³ ë¦¬ì— ì›¹ ë¬¸ì„œ ë°ì´í„° ì¶”ê°€
- Webkr APIëŠ” ìœ„í‚¤, ë¸”ë¡œê·¸, ì»¤ë®¤ë‹ˆí‹° ë“± ë‹¤ì–‘í•œ ì›¹ í˜ì´ì§€ ìƒ‰ì¸
- news/blogë³´ë‹¤ í›¨ì”¬ ë§ì€ ê²°ê³¼ ì œê³µ

íŠ¹ì§•:
- ëª¨ë“  ì¹´í…Œê³ ë¦¬ì— Webkr ì¶”ê°€ í˜¸ì¶œ
- ê¸°ê°„ ì œí•œ ì—†ìŒ (ì›¹ ë°ì´í„°ëŠ” ì¼ë°˜ì ìœ¼ë¡œ ëª…í™•í•œ ë‚ ì§œ ì—†ìŒ)
- í•„í„°ë§ ì™„í™” (titleì— ì •ì¹˜ì¸ëª…ë§Œ í¬í•¨ë˜ë©´ ìˆ˜ì§‘)
"""

import os
import sys
import json
import requests
import time
from pathlib import Path
from datetime import datetime
from dotenv import load_dotenv

# ê²½ë¡œ ì„¤ì •
SCRIPT_DIR = Path(__file__).resolve().parent
V40_DIR = SCRIPT_DIR.parent.parent

ENV_PATH = V40_DIR.parent / '.env'
load_dotenv(ENV_PATH)

NAVER_CLIENT_ID = os.getenv('NAVER_CLIENT_ID')
NAVER_CLIENT_SECRET = os.getenv('NAVER_CLIENT_SECRET')
SUPABASE_URL = os.getenv('SUPABASE_URL')
SUPABASE_KEY = os.getenv('SUPABASE_SERVICE_ROLE_KEY')

sys.path.insert(0, str(V40_DIR / "scripts" / "core"))
from supabase import create_client

# Webkr ê²€ìƒ‰ ì¿¼ë¦¬ (ì¹´í…Œê³ ë¦¬ë³„)
WEBKR_QUERIES = {
    'integrity': ['ì˜¤ì¤€í™˜ ì²­ë ´', 'ì˜¤ì¤€í™˜ ì¬ì‚°', 'ì˜¤ì¤€í™˜ ë¹„ë¦¬', 'ì˜¤ì¤€í™˜ ìœ¤ë¦¬'],
    'ethics': ['ì˜¤ì¤€í™˜ ìœ¤ë¦¬', 'ì˜¤ì¤€í™˜ ë„ë•', 'ì˜¤ì¤€í™˜ í•™ë ¥', 'ì˜¤ì¤€í™˜ ê°€ì¡±'],
    'responsiveness': ['ì˜¤ì¤€í™˜ ëŒ€ì‘', 'ì˜¤ì¤€í™˜ í”¼ë“œë°±', 'ì˜¤ì¤€í™˜ ì†Œí†µ'],
    'publicinterest': ['ì˜¤ì¤€í™˜ ê³µìµ', 'ì˜¤ì¤€í™˜ ì‹œë¯¼', 'ì˜¤ì¤€í™˜ ì‚¬íšŒ']
}


def search_webkr(query: str, display: int = 50) -> list:
    """Naver Webkr API í˜¸ì¶œ"""
    url = "https://openapi.naver.com/v1/search/webkr.json"

    headers = {
        "X-Naver-Client-Id": NAVER_CLIENT_ID,
        "X-Naver-Client-Secret": NAVER_CLIENT_SECRET
    }

    params = {
        "query": query,
        "display": display,
        "sort": "date"
    }

    try:
        print(f"  ğŸ” Webkr ê²€ìƒ‰: {query}")
        response = requests.get(url, headers=headers, params=params, timeout=10)

        if response.status_code == 429:
            print(f"    âš ï¸  Rate Limit - ëŒ€ê¸° ì¤‘...")
            time.sleep(5)
            return search_webkr(query, display)

        if response.status_code != 200:
            print(f"    âŒ ì˜¤ë¥˜: {response.status_code}")
            return []

        data = response.json()
        items = []

        for item in data.get('items', []):
            items.append({
                'title': item['title'].replace('<b>', '').replace('</b>', ''),
                'link': item['link'],
                'description': item['description'].replace('<b>', '').replace('</b>', ''),
                'pub_date': item.get('pubdate', datetime.now().strftime('%Y-%m-%d'))
            })

        print(f"    âœ… {len(items)}ê°œ ë°œê²¬")
        return items

    except Exception as e:
        print(f"    âŒ ì˜¤ë¥˜: {e}")
        return []


def save_to_db(politician_id: str, politician_name: str, category: str, items: list) -> int:
    """Supabaseì— ì €ì¥"""
    if not items:
        return 0

    try:
        supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

        saved = 0

        for item in items:
            # ì œëª©ì´ ì •ì¹˜ì¸ëª… í¬í•¨ ì—¬ë¶€ í™•ì¸
            if politician_name not in item['title'] and politician_name not in item.get('description', ''):
                continue

            try:
                result = supabase.table('collected_data_v40').insert({
                    'politician_id': politician_id,
                    'politician_name': politician_name,
                    'category': category,
                    'title': item['title'][:300],
                    'content': item['description'][:1000],
                    'source_url': item['link'],
                    'source_name': 'webkr',
                    'data_type': 'PUBLIC',  # WebkrëŠ” ê³µê°œ ë°ì´í„°
                    'collector_ai': 'Naver',
                    'sentiment': 'free',  # ê¸°ë³¸ê°’
                    'published_date': item['pub_date']
                }).execute()

                if result.data:
                    saved += 1

            except Exception as e:
                if "duplicate" in str(e).lower():
                    pass  # ì¤‘ë³µ ë¬´ì‹œ
                else:
                    print(f"      âš ï¸  ì €ì¥ ì˜¤ë¥˜: {e}")

        return saved

    except Exception as e:
        print(f"  âŒ DB ì˜¤ë¥˜: {e}")
        return 0


def main():
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘          Naver Webkr API ê¸´ê¸‰ ìˆ˜ì§‘ (ì›¹ ë¬¸ì„œ ì „ë¬¸) ğŸš€                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")

    politician_id = '37e39502'
    politician_name = 'ì˜¤ì¤€í™˜'

    total_saved = 0

    for category, queries in WEBKR_QUERIES.items():
        print(f"\nğŸ“‚ {category} ìˆ˜ì§‘ ì‹œì‘")

        for query in queries:
            items = search_webkr(query)
            saved = save_to_db(politician_id, politician_name, category, items)

            total_saved += saved
            print(f"    ğŸ’¾ {saved}ê°œ ì €ì¥ë¨")

            time.sleep(1)  # Rate Limit íšŒí”¼

    print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                       ìˆ˜ì§‘ ì™„ë£Œ: {total_saved}ê°œ âœ…                        â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")


if __name__ == '__main__':
    main()

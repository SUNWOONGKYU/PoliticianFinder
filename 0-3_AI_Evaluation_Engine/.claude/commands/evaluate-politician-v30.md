# evaluate-politician-v30

**Command**: `/evaluate-politician-v30`

**Description**: V30 ì •ì¹˜ì¸ í‰ê°€ (Claude Code Subscription ëª¨ë“œ, API ë¹„ìš© $0)

**Usage**:
```
/evaluate-politician-v30 --politician_id=f9e00370 --politician_name=ê¹€ë¯¼ì„ --category=responsiveness
```

---

## ğŸ¯ ëª©ì 

V30 í’€ë§ í‰ê°€ ì‹œìŠ¤í…œì—ì„œ Claudeê°€ **subscription mode**ë¡œ í‰ê°€ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
- âœ… API ë¹„ìš© $0 (Claude Code subscription ì‚¬ìš©)
- âœ… Native Claude Code context (subprocess ì—†ìŒ)
- âœ… Database ì§ì ‘ ì¡°íšŒ ë° ì €ì¥
- âœ… V30 ë“±ê¸‰ ì²´ê³„ (+4 ~ -4) ì ìš©

---

## ğŸ“‹ ì‘ì—… í”„ë¡œì„¸ìŠ¤

### 1ë‹¨ê³„: í™˜ê²½ í™•ì¸
- Supabase ì—°ê²° í™•ì¸
- ì •ì¹˜ì¸ ì •ë³´ ì¡°íšŒ
- ì¹´í…Œê³ ë¦¬ ë°ì´í„° í™•ì¸

### 2ë‹¨ê³„: ë°ì´í„° ì¡°íšŒ
- `collected_data_v30` í…Œì´ë¸”ì—ì„œ ë¯¸í‰ê°€ ë°ì´í„° ì¡°íšŒ
- ì¤‘ë³µ ì œê±° (ê°™ì€ AIê°€ ê°™ì€ URL 2ë²ˆ ìˆ˜ì§‘í•œ ê²½ìš°ë§Œ)
- ë°°ì¹˜ í¬ê¸°: 10ê°œì”©

### 3ë‹¨ê³„: í‰ê°€ ìˆ˜í–‰
- V30 ë“±ê¸‰ ì²´ê³„ ì ìš© (+4 ~ -4)
- ì •ì¹˜ì¸ í”„ë¡œí•„ ì •ë³´ ì°¸ì¡°
- ê°ê´€ì  í‰ê°€ ìˆ˜í–‰

### 4ë‹¨ê³„: ê²°ê³¼ ì €ì¥
- `evaluations_v30` í…Œì´ë¸”ì— ì €ì¥
- ì¤‘ë³µ í‚¤ ì—ëŸ¬ ì²˜ë¦¬
- ì €ì¥ ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„

---

## ğŸ”§ Parameters

| Parameter | Required | Description | Example |
|-----------|----------|-------------|---------|
| `--politician_id` | âœ… Yes | ì •ì¹˜ì¸ ID (8ìë¦¬ hex) | `f9e00370` |
| `--politician_name` | âœ… Yes | ì •ì¹˜ì¸ ì´ë¦„ | `ê¹€ë¯¼ì„` |
| `--category` | âœ… Yes | ì¹´í…Œê³ ë¦¬ ì˜ë¬¸ëª… | `responsiveness` |
| `--batch_size` | âŒ No | ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸: 10) | `10` |

---

## ğŸ“Š V30 ë“±ê¸‰ ì²´ê³„ (+4 ~ -4)

| ë“±ê¸‰ | ì ìˆ˜(Ã—2) | íŒë‹¨ ê¸°ì¤€ |
|------|----------|-----------|
| +4 | +8ì  | íƒì›”í•¨ - í•´ë‹¹ ë¶„ì•¼ ëª¨ë²” ì‚¬ë¡€ |
| +3 | +6ì  | ìš°ìˆ˜í•¨ - ê¸ì •ì  í‰ê°€ |
| +2 | +4ì  | ì–‘í˜¸í•¨ - ê¸°ë³¸ ì¶©ì¡± |
| +1 | +2ì  | ë³´í†µ - í‰ê·  ìˆ˜ì¤€ |
| -1 | -2ì  | ë¯¸í¡í•¨ - ê°œì„  í•„ìš” |
| -2 | -4ì  | ë¶€ì¡±í•¨ - ë¬¸ì œ ìˆìŒ |
| -3 | -6ì  | ë§¤ìš° ë¶€ì¡± - ì‹¬ê°í•œ ë¬¸ì œ |
| -4 | -8ì  | ê·¹íˆ ë¶€ì¡± - ì •ì¹˜ì¸ ë¶€ì í•© |

---

## ğŸ¤– Implementation Instructions

When this command is invoked, you MUST:

### Step 1: Parse Arguments
```python
import argparse
parser = argparse.ArgumentParser()
parser.add_argument('--politician_id', required=True)
parser.add_argument('--politician_name', required=True)
parser.add_argument('--category', required=True)
parser.add_argument('--batch_size', type=int, default=10)
args = parser.parse_args()
```

### Step 2: Connect to Database
```python
import os
from supabase import create_client
from dotenv import load_dotenv

load_dotenv(override=True)
supabase = create_client(
    os.getenv('SUPABASE_URL'),
    os.getenv('SUPABASE_SERVICE_ROLE_KEY')
)
```

### Step 3: Query Unevaluated Data
```python
# 1. ì´ë¯¸ í‰ê°€ëœ ë°ì´í„° ID ì¡°íšŒ
evaluated_result = supabase.table('evaluations_v30')\
    .select('collected_data_id')\
    .eq('politician_id', args.politician_id)\
    .eq('evaluator_ai', 'Claude')\
    .eq('category', args.category.lower())\
    .execute()

evaluated_ids = {item['collected_data_id'] for item in evaluated_result.data if item.get('collected_data_id')}

# 2. ìˆ˜ì§‘ëœ ë°ì´í„° ì¡°íšŒ (í’€ë§: 4ê°œ AI ìˆ˜ì§‘ ë°ì´í„° í†µí•©)
collected_result = supabase.table('collected_data_v30')\
    .select('*')\
    .eq('politician_id', args.politician_id)\
    .eq('category', args.category.lower())\
    .execute()

# 3. ë¯¸í‰ê°€ ë°ì´í„° í•„í„°ë§
unevaluated_items = [
    item for item in collected_result.data
    if item['id'] not in evaluated_ids
]

# 4. AIë³„ URL ì¤‘ë³µ ì œê±°
seen_by_ai = {}
unique_items = []
for item in unevaluated_items:
    ai_name = item.get('collector_ai', 'unknown')
    url = item.get('source_url', '')

    if ai_name not in seen_by_ai:
        seen_by_ai[ai_name] = set()

    if url and url in seen_by_ai[ai_name]:
        continue  # ê°™ì€ AIê°€ ê°™ì€ URL ì¤‘ë³µ â†’ ì œê±°

    if url:
        seen_by_ai[ai_name].add(url)
    unique_items.append(item)

print(f"ğŸ“Š ë¯¸í‰ê°€ ë°ì´í„°: {len(unique_items)}ê°œ")
```

### Step 4: Get Politician Profile
```python
# ì •ì¹˜ì¸ í”„ë¡œí•„ ì¡°íšŒ
profile_result = supabase.table('politicians')\
    .select('*')\
    .eq('id', args.politician_id)\
    .execute()

profile = profile_result.data[0] if profile_result.data else {}

profile_text = f"""**ëŒ€ìƒ ì •ì¹˜ì¸**: {args.politician_name}

**ì •ì¹˜ì¸ ê¸°ë³¸ ì •ë³´**:
- ì´ë¦„: {profile.get('name', args.politician_name)}
- ì‹ ë¶„: {profile.get('identity', 'N/A')}
- ì§ì±…: {profile.get('title', 'N/A')}
- ì •ë‹¹: {profile.get('party', 'N/A')}
- ì§€ì—­: {profile.get('region', 'N/A')}

âš ï¸ **ì¤‘ìš”**: ë°˜ë“œì‹œ ìœ„ ì •ë³´ì™€ ì¼ì¹˜í•˜ëŠ” "{args.politician_name}"ì— ëŒ€í•´ í‰ê°€í•˜ì„¸ìš”."""
```

### Step 5: Batch Evaluation (10ê°œì”©)
```python
from datetime import datetime

CATEGORY_MAP = {
    "expertise": "ì „ë¬¸ì„±",
    "leadership": "ë¦¬ë”ì‹­",
    "vision": "ë¹„ì „",
    "integrity": "ì²­ë ´ì„±",
    "ethics": "ìœ¤ë¦¬ì„±",
    "accountability": "ì±…ì„ê°",
    "transparency": "íˆ¬ëª…ì„±",
    "communication": "ì†Œí†µëŠ¥ë ¥",
    "responsiveness": "ëŒ€ì‘ì„±",
    "publicinterest": "ê³µìµì„±"
}

RATING_TO_SCORE = {
    '+4': 8, '+3': 6, '+2': 4, '+1': 2,
    '-1': -2, '-2': -4, '-3': -6, '-4': -8
}

cat_kor = CATEGORY_MAP.get(args.category.lower(), args.category)
batch_size = args.batch_size
total_saved = 0

for i in range(0, len(unique_items), batch_size):
    batch = unique_items[i:i+batch_size]

    # ë°°ì¹˜ ë°ì´í„° í¬ë§·
    items_text = ""
    for idx, item in enumerate(batch, 1):
        items_text += f"""
[í•­ëª© {idx}]
- ID: {item.get('id', '')}
- ì œëª©: {item.get('title', 'N/A')}
- ë‚´ìš©: {item.get('content', 'N/A')[:300]}...
- ì¶œì²˜: {item.get('source_name', item.get('source_url', 'N/A'))}
- ë‚ ì§œ: {item.get('published_date', 'N/A')}
- ìˆ˜ì§‘AI: {item.get('collector_ai', 'N/A')}
"""

    # ===== ğŸ¯ í•µì‹¬: Claude Code Native í‰ê°€ (Subscription Mode) =====
    # subprocess ì—†ìŒ, API í˜¸ì¶œ ì—†ìŒ, Claudeê°€ ì§ì ‘ í‰ê°€!
    prompt = f"""ë‹¹ì‹ ì€ ì •ì¹˜ì¸ í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

{profile_text}

**í‰ê°€ ì¹´í…Œê³ ë¦¬**: {cat_kor} ({args.category})

ì•„ë˜ ë°ì´í„°ë¥¼ **ê°ê´€ì ìœ¼ë¡œ í‰ê°€**í•˜ì—¬ ë“±ê¸‰ì„ ë¶€ì—¬í•˜ì„¸ìš”.

**ë“±ê¸‰ ì²´ê³„** (+4 ~ -4):
| ë“±ê¸‰ | íŒë‹¨ ê¸°ì¤€ | ì ìˆ˜ |
|------|-----------|------|
| +4 | íƒì›”í•¨ - í•´ë‹¹ ë¶„ì•¼ ëª¨ë²” ì‚¬ë¡€ | +8 |
| +3 | ìš°ìˆ˜í•¨ - ê¸ì •ì  í‰ê°€ | +6 |
| +2 | ì–‘í˜¸í•¨ - ê¸°ë³¸ ì¶©ì¡± | +4 |
| +1 | ë³´í†µ - í‰ê·  ìˆ˜ì¤€ | +2 |
| -1 | ë¯¸í¡í•¨ - ê°œì„  í•„ìš” | -2 |
| -2 | ë¶€ì¡±í•¨ - ë¬¸ì œ ìˆìŒ | -4 |
| -3 | ë§¤ìš° ë¶€ì¡± - ì‹¬ê°í•œ ë¬¸ì œ | -6 |
| -4 | ê·¹íˆ ë¶€ì¡± - ì •ì¹˜ì¸ ë¶€ì í•© | -8 |

**í‰ê°€ ê¸°ì¤€**:
- ê¸ì •ì  ë‚´ìš© (ì„±ê³¼, ì—…ì , ì¹­ì°¬) â†’ +4, +3, +2
- ê²½ë¯¸í•œ ê¸ì • (ë³´í†µ, í‰ë²”) â†’ +1
- ë¶€ì •ì  ë‚´ìš© (ë…¼ë€, ë¹„íŒ, ë¬¸ì œ) â†’ -1, -2, -3, -4 (ì‹¬ê°ë„ì— ë”°ë¼)

**í‰ê°€í•  ë°ì´í„°**:
{items_text}

**ë°˜ë“œì‹œ ëª¨ë“  í•­ëª©ì— ëŒ€í•´ í‰ê°€í•˜ì„¸ìš”.**

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜:
```json
{{
  "evaluations": [
    {{
      "id": "ë°ì´í„° ID ê°’",
      "rating": "+4, +3, +2, +1, -1, -2, -3, -4 ì¤‘ í•˜ë‚˜",
      "rationale": "í‰ê°€ ê·¼ê±° (1ë¬¸ì¥)"
    }}
  ]
}}
```"""

    # ğŸ¯ YOU (Claude) evaluate directly here in this context!
    # This is native Claude Code execution, NOT API call!
    print(f"\n[ë°°ì¹˜ {i//batch_size + 1}] {len(batch)}ê°œ í•­ëª© í‰ê°€ ì¤‘...")
    print(prompt)
    print("\nğŸ‘† ìœ„ í”„ë¡¬í”„íŠ¸ì— ë”°ë¼ í‰ê°€ë¥¼ ìˆ˜í–‰í•˜ê³  JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”.")
    print("âš ï¸ ì´ í‰ê°€ëŠ” Claude Code subscription modeë¡œ ì‹¤í–‰ë˜ë¯€ë¡œ API ë¹„ìš©ì´ ì²­êµ¬ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

    # Wait for YOUR evaluation response...
    # (User will provide the evaluation result, or you generate it directly)

    # ===== Parse evaluation result =====
    # After you generate the evaluation, parse it:
    import json
    import re

    # Extract JSON from response
    # (Implementation note: In actual execution, YOU will generate the evaluation
    #  and then parse your own response here)

    # Example parsing (to be filled with actual evaluation result):
    """
    evaluation_response = YOUR_EVALUATION_RESPONSE_HERE

    json_match = re.search(r'```(?:json)?\s*([\s\S]*?)\s*```', evaluation_response)
    if json_match:
        json_str = json_match.group(1)
    else:
        json_str = evaluation_response

    data = json.loads(json_str)
    evaluations = data.get('evaluations', [])

    # Validate and save
    records = []
    for idx, ev in enumerate(evaluations):
        rating = str(ev.get('rating', '')).strip()
        if rating in ['4', '3', '2', '1']:
            rating = '+' + rating

        if rating in ['+4', '+3', '+2', '+1', '-1', '-2', '-3', '-4']:
            # Match evaluation to batch item by index
            if idx < len(batch):
                record = {
                    'politician_id': args.politician_id,
                    'politician_name': args.politician_name,
                    'category': args.category.lower(),
                    'evaluator_ai': 'Claude',
                    'collected_data_id': batch[idx]['id'],
                    'rating': rating,
                    'score': RATING_TO_SCORE[rating],
                    'reasoning': ev.get('rationale', '')[:1000],
                    'evaluated_at': datetime.now().isoformat()
                }
                records.append(record)

    # Save to database
    if records:
        try:
            result = supabase.table('evaluations_v30').insert(records).execute()
            saved_count = len(result.data) if result.data else 0
            total_saved += saved_count
            print(f"  âœ… {saved_count}ê°œ í‰ê°€ ì €ì¥ ì™„ë£Œ")
        except Exception as e:
            if 'duplicate key' in str(e).lower():
                print(f"  âš ï¸ ì¤‘ë³µ í‰ê°€ ê±´ë„ˆë›°ê¸°")
            else:
                print(f"  âŒ ì €ì¥ ì‹¤íŒ¨: {e}")
    """

print(f"\n{'='*60}")
print(f"âœ… í‰ê°€ ì™„ë£Œ: {args.politician_name} - {cat_kor}")
print(f"   ì´ ì €ì¥: {total_saved}ê±´")
print(f"{'='*60}")
```

---

## âš ï¸ CRITICAL: Subscription Mode ë³´ì¥

This command MUST run natively within Claude Code session:
- âœ… **NO** `subprocess.run()` or `claude.cmd` calls
- âœ… **NO** API client initialization
- âœ… **YES** Direct evaluation by YOU (Claude) in current context
- âœ… **YES** Database operations only (Supabase client)

**How this works**:
1. Command loads data from database
2. Formats evaluation prompt
3. **YOU (Claude) read the prompt and generate evaluation directly in this session**
4. Parse your own evaluation response
5. Save to database

**No external process = No API charges = Subscription mode only! âœ…**

---

## ğŸ“ Example Usage

```bash
# Evaluate responsiveness category (23 missing items)
python -c "
from commands.evaluate_politician_v30 import evaluate_politician_v30
evaluate_politician_v30(
    politician_id='f9e00370',
    politician_name='ê¹€ë¯¼ì„',
    category='responsiveness',
    batch_size=10
)
"
```

Or invoke via Claude Code:
```
/evaluate-politician-v30 --politician_id=f9e00370 --politician_name=ê¹€ë¯¼ì„ --category=responsiveness
```

---

## ğŸ”„ Integration with evaluate_v30.py

To use this command in the existing workflow:

1. **Replace** `call_claude_cli()` function
2. **Use** Task tool with this command:
   ```python
   from claude_code import Task

   Task(
       subagent_type="general-purpose",
       description=f"Evaluate {category}",
       prompt=f"/evaluate-politician-v30 --politician_id={politician_id} --politician_name={politician_name} --category={category}"
   )
   ```

3. **Benefit**: No API charges, subscription mode only!

---

**ìµœì¢… ì—…ë°ì´íŠ¸**: 2026-01-21
**ë²„ì „**: V30 Subscription Mode
